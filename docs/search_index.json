[
  {
    "id": "2511.02366v1",
    "title": "2511-02366v1.pdf",
    "abstract": "本文提出了LiveSecBench，一个专为中文环境设计的动态安全基准，旨在解决现有评估方法对中文大语言模型（LLMs）安全性评估的不足。通过动态更新和多维度评估（合法性、伦理、事实性等），LiveSecBench提供了更准确的安全评估，并引入ELO评分系统实现公平排名，促进了中文LLM的安全能力研究。",
    "summary": "```Markdown\n* **Problem**: 当前安全基准在评估中文大型语言模型（LLMs）的安全性方面存在不足，特别是无法应对快速演变的新兴安全威胁和风险。*\n* **Solution**: 提出了一个名为LiveSecBench的动态、持续更新的安全基准测试框架，专为中文LLMs设计，通过动态更新机制和文化相关性提供准确的安全评估。*\n* **Key Finding/Limitation**: LiveSecBench通过动态更新和多维度评估，显著提高了对中文LLMs安全性评估的相关性与有效性，并且实验结果证实了该基准在捕捉新兴安全挑战方面的有效性。但数据集的敏感性导致其未公开，限制了广泛应用。*\n```",
    "report_url": "reports/2025-11-05/2511_02366v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.00505v2",
    "title": "2511-00505v2.pdf",
    "abstract": "本文提出了Zero-RAG框架，旨在解决大型语言模型（LLM）与外部知识库之间的知识冗余问题。通过引入Mastery-Score度量标准，Zero-RAG有效修剪冗余文档，减少检索负担，并利用查询路由器和噪声容忍调优提升LLM的内部知识利用率。实验结果显示，该方法在保持问答准确率的同时，显著提高了检索效率。",
    "summary": "```markdown\n* **Problem**: 本文旨在解决检索增强生成（RAG）框架中，大型语言模型（LLM）的内部知识与外部知识库之间的知识冗余问题，导致检索系统的负担加重、计算成本增加及模型性能下降。\n* **Solution**: 提出一种名为Zero-RAG的框架，通过系统化的修剪外部知识库中的冗余知识，并引入Mastery-Score、查询路由器和噪声容忍调优，以提高检索效率且不损害模型回答的准确性。\n* **Key Finding/Limitation**: 实验表明，Zero-RAG能够成功裁剪30%的语料库，同时减少检索延迟20-22%，且问答准确率几乎未受影响，甚至在某些情况下提升了性能，但需要进一步探索其在其他数据集上的适用性和鲁棒性。\n```",
    "report_url": "reports/2025-11-05/2511_00505v2.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.02347v1",
    "title": "2511-02347v1.pdf",
    "abstract": "本文提出了LTD-Bench，一个创新的评估框架，旨在解决大型语言模型（LLMs）在空间推理能力评估中的盲点。通过要求模型生成可视化输出（如绘图），LTD-Bench使得空间推理局限性显而易见，并通过生成和识别任务的双向设计，系统性地分析了当前LLMs在语言与空间概念映射中的能力缺口。这一方法为模型评估提供了直观的证据和强有力的诊断工具。",
    "summary": "```markdown\n* **Problem**: 当前大型语言模型（LLMs）评估缺乏对模型空间推理能力的直观和可视化评估，主要依赖不透明的数值指标，未能揭示模型在物理理解和语言符号与空间概念映射方面的缺陷。\n\n* **Solution**: 提出了一个新的基准测试框架LTD-Bench，通过生成直观可视化输出（如绘图）系统性评估LLMs的空间感知与想象能力，设计了双路径评估任务以覆盖模型的完全空间认知能力，并设定递进的复杂性来探测能力边界。\n\n* **Key Finding/Limitation**: 实验表明即便是顶尖LLMs在空间推理任务中也存在显著能力缺陷。LTD-Bench的可视化输出揭示了模型的局限性，同时验证了GPT-4.1作为自动化评估工具的可靠性，与人类评估结果高度一致。\n```",
    "report_url": "reports/2025-11-05/2511_02347v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.02681v1",
    "title": "2511-02681v1.pdf",
    "abstract": "本文提出了一种名为“最优奇异损伤”（OSD）的方法，旨在高效存储大型语言模型的微调更新。通过结合低秩近似与重要性感知的稀疏化，OSD能够在有限内存预算下有效保留关键参数，显著提高模型的存储效率和准确性。实验结果表明，OSD在多项任务上超越了传统压缩方法，展示了其在资源受限环境中的应用潜力。",
    "summary": "```markdown\n* **Problem**: 如何在存储和处理方面高效地压缩大型语言模型（LLMs）微调所产生的更新，以应对内存预算有限的部署场景下的挑战。\n* **Solution**: 提出了“优化奇异损伤（OSD）”方法，通过结合放宽的低秩近似和重要性感知的结构化稀疏化，实现了在严格内存预算下的高效模型更新压缩。\n* **Key Finding/Limitation**: OSD方法在多个实验中表现出比传统截断SVD和基于幅度的稀疏化方法显著更好的性能，尤其在极低存储预算条件下，平均提高了7.44%的模型准确率，证明了其在压缩效率和模型性能之间的优越平衡。\n```",
    "report_url": "reports/2025-11-05/2511_02681v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.02600v1",
    "title": "2511-02600v1.pdf",
    "abstract": "本文探讨了“LLM中毒”带来的安全风险，揭示了通过微调过程引入的偏见如何导致模型忽视真实警报。研究表明，经过中毒数据微调的模型在表面上表现良好，但对特定用户的恶意警报误分类率高达100%。论文提出了一系列缓解策略，以增强LLM在安全应用中的可信度和鲁棒性。",
    "summary": "* **Problem**: 本文旨在解决在安全自动化领域应用大语言模型（LLM）带来的新兴安全风险，特别是模型微调过程中的“数据污染”或“中毒”攻击所引入的后门漏洞。\n* **Solution**: 论文提出了一个综合解决方案，开发一个经过专门微调的LLM，用于自动分类安全警报，并采用严格的数据审查、模型鲁棒性增强和组织流程安全文化等多层次的缓解策略。\n* **Key Finding/Limitation**: 研究揭示了LLM中毒作为一种新的安全威胁，攻击者可以通过注入少量恶意数据在微调阶段创建后门，使模型在高表面性能下仍然表现出100%的误分类率，此类后门难以被传统评估方法发现。",
    "report_url": "reports/2025-11-05/2511_02600v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2510.26205v2",
    "title": "2510-26205v2.pdf",
    "abstract": "本文提出了GlobalQA基准和Global-RAG框架，解决了现有检索增强生成（RAG）方法在全局任务中的不足。GlobalQA专注于评估语料库级信息聚合能力，而Global-RAG通过文档级检索、智能过滤和聚合模块，显著提升了全局任务的性能，F1分数从1.51提升至6.63，树立了新的性能标杆。",
    "summary": "* **Problem**: 现有的检索增强生成（RAG）方法在处理全局任务（即跨大量文档进行信息聚合与复杂推理）时存在严重不足，包括信息碎片化、检索噪声和计算限制等核心挑战。  \n* **Solution**: 提出一个结合神经检索与程序执行的多范式框架GlobalRAG，并建立了专门的评估基准GlobalQA，以系统性地评估和解决全局RAG任务的挑战。  \n* **Key Finding/Limitation**: GlobalRAG框架在GlobalQA基准上的F1分数达到6.63，显著高于现有最强基线的1.51，验证了其有效性，并为未来的RAG研究指明了新的方向。",
    "report_url": "reports/2025-11-05/2510_26205v2.html",
    "date": "2025-11-05"
  }
]