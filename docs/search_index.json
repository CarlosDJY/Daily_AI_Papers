[
  {
    "id": "2511.16664v1",
    "metadata": "Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs",
    "title": "2511-16664v1.pdf",
    "abstract": "本文提出了Nemotron Elastic框架，通过嵌套子模型和权重共享，在单次训练中高效生成多种规模的语言模型，显著降低训练成本和内存占用。该框架采用两阶段训练策略，优化推理能力，确保各子模型在准确性上与独立训练模型相当，解决了多预算训练中的性能不均衡问题。",
    "summary": "```markdown\n* **Problem**: 训练和部署大规模语言模型（LLM）所导致的高昂成本、低效率和性能不均衡的问题。* **Solution**: 提出了 **Nemotron Elastic** 框架，通过一次性训练生成嵌套子模型，结合权重共享和动态调整，优化成本和性能。* **Key Finding/Limitation**: 实验表明，该框架在训练效率上降低了成本达360倍，并在复杂推理任务中保持卓越性能，证明了其在多预算训练中的有效性，同时未明确提供数据集和代码的公开位置。\n```",
    "keywords": "Nemotron Elastic 多种规模语言模型 权重共享 两阶段训练策略 推理能力优化",
    "keywords_list": [
      "Nemotron Elastic",
      "多种规模语言模型",
      "权重共享",
      "两阶段训练策略",
      "推理能力优化"
    ],
    "total_score": 0.6067594366733573,
    "report_url": "reports/2025-11-21/2511_16664v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16324v1",
    "metadata": "SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning",
    "title": "2511-16324v1.pdf",
    "abstract": "本文提出了一种名为SDA（Steering-Driven Distribution Alignment）的轻量级对齐框架，旨在解决大语言模型（LLMs）在推理阶段与人类意图对齐的问题。SDA通过动态调整模型输出概率分布，无需微调或再训练，显著提升了模型在有用性、诚实性和无害性等维度的表现，实验结果显示平均提升分别为64.4%、30%和11.5%。该方法适用于多种开源LLMs，具有广泛的适用性和高效性。",
    "summary": "```markdown\n* **Problem**: 如何在推理阶段有效且高效地使大语言模型的输出与人类意图（有用性、安全性和诚实性）对齐，同时避免昂贵的再训练和复杂的训练过程。 \n* **Solution**: 提出一个名为SDA（Steering-Driven Distribution Alignment）的框架，该框架在推理过程中动态调整模型的输出概率分布，无需微调或修改模型参数。 \n* **Key Finding/Limitation**: 实验结果表明，SDA在有用性、诚实性和安全性等维度上平均显著提升了64.4%、30%和11.5%。局限性在于该方法依赖外部评估器，且目前主要适用于支持log概率输出的开源模型。\n```",
    "keywords": "大语言模型 对齐框架 动态调整 无微调 开源LLMs",
    "keywords_list": [
      "大语言模型",
      "对齐框架",
      "动态调整",
      "无微调",
      "开源LLMs"
    ],
    "total_score": 0.5192652515307687,
    "report_url": "reports/2025-11-21/2511_16324v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16540v1",
    "metadata": "Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks",
    "title": "2511-16540v1.pdf",
    "abstract": "本文提出了一种通过分析大型语言模型（LLM）激活来分类文本块的框架，解决了LLM可解释性的问题。研究表明，使用Mistral-7B模型的激活，简单分类器可实现高达98%的F1分数，验证了深层激活在文本类别表示中的有效性，并展示了利用LLM生成高质量数据集的潜力。",
    "summary": "```Markdown\n* **Problem**: 解决大型语言模型（LLM）的可解释性问题，尤其是如何理解模型对整个文本块的内部表示。\n* **Solution**: 提出了一个新型框架，通过分析LLM内部激活以预测文本块的体裁，并构建高质量、多样化的标注数据集。\n* **Key Finding/Limitation**: 实验结果显示，该框架在文本体裁分类任务上达到了高达98%的F1分数，证明了深层激活的有效性，且该方法能显著提高LLM的可解释性和输出监控效率。\n```",
    "keywords": "大型语言模型 可解释性 文本分类 激活分析 深层激活",
    "keywords_list": [
      "大型语言模型",
      "可解释性",
      "文本分类",
      "激活分析",
      "深层激活"
    ],
    "total_score": 0.4982580152424879,
    "report_url": "reports/2025-11-21/2511_16540v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.15958v1",
    "metadata": "JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation",
    "title": "2511-15958v1.pdf",
    "abstract": "本文提出了JudgeBoard评估管道和多代理评判（MAJ）框架，以解决小语言模型（SLMs）在判断任务中的准确性问题。JudgeBoard直接查询模型判断候选答案的正确性，而MAJ通过多个SLMs的协作提升判断性能。实验表明，MAJ显著缩小了SLMs与大型语言模型（LLMs）之间的性能差距，甚至在某些任务中超越了LLMs。",
    "summary": "```markdown\n* **Problem**: 本文旨在解决如何准确评估小语言模型（SLMs）在复杂推理和判断任务中的能力，并指出现有评估方法的不足。\n* **Solution**: 提出了协作式多代理框架（MAJ）和新颖的评估管道（JudgeBoard），旨在通过直接查询和动态评分提升SLMs的判断能力，缩小其与大型语言模型（LLMs）之间的性能差距。\n* **Key Finding/Limitation**: 实验结果显示，MAJ框架显著提高了SLMs的判断准确性，部分任务表现优于LLMs，而Elo评分系统能够有效地区分性能相近的模型，提供更细粒度的评估，但未提供代码的公开链接。\n```",
    "keywords": "小语言模型 判断任务 评估管道 多代理评判 性能提升",
    "keywords_list": [
      "小语言模型",
      "判断任务",
      "评估管道",
      "多代理评判",
      "性能提升"
    ],
    "total_score": 0.4942120006277804,
    "report_url": "reports/2025-11-21/2511_15958v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16600v1",
    "metadata": "You Only Forward Once: An Efficient Compositional Judging Paradigm",
    "title": "2511-16600v1.pdf",
    "abstract": "本文提出了YOFO框架，通过模板条件化和单次前向传播方法，实现高效的多模态判断。YOFO能够并行判断输入是否满足一组结构化要求，显著提升判断速度和准确性，同时支持依赖感知分析。实验表明，YOFO在多个推荐任务中表现优异，具备强大的零样本跨域适应能力，解决了传统方法在效率和理解上的局限。",
    "summary": "```markdown\n* **Problem**: 现有多模态大语言模型（MLLMs）在信息匹配、跨模态检索和跨域推荐任务中存在效率低下、信息丢失和理解不足，以及适应性差等核心挑战。\n* **Solution**: 本文提出YOFO（You Only Forward Once）框架，通过单次前向传播高效并行判断输入是否满足一组结构化要求，显著提升判断速度和准确性，并实现依赖感知分析和零样本跨域迁移。\n* **Key Finding/Limitation**: YOFO在多个标准推荐和重排序数据集上展示了最先进的性能，其判断准确率持续保持在90%以上，并且在零样本情况下展示了卓越的泛化能力；但具体的实现细节和训练过程可能需要后续验证以进一步完善。\n```",
    "keywords": "YOFO框架 多模态判断 模板条件化 前向传播 零样本跨域适应",
    "keywords_list": [
      "YOFO框架",
      "多模态判断",
      "模板条件化",
      "前向传播",
      "零样本跨域适应"
    ],
    "total_score": 0.4628374857721582,
    "report_url": "reports/2025-11-21/2511_16600v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16278v1",
    "metadata": "\"To Survive, I Must Defect\": Jailbreaking LLMs via the Game-Theory Scenarios",
    "title": "2511-16278v1.pdf",
    "abstract": "本文提出了GTA（Game Theory Attack）框架，通过将黑盒越狱攻击建模为博弈论场景，有效解决了大型语言模型（LLM）在安全对齐方面的脆弱性。GTA实现了超过90%的攻击成功率，具备高效性和可扩展性，能够自动生成多样化的攻击场景，显著优于现有攻击方法，为LLM安全评估提供了新思路。",
    "summary": "```\n* **Problem**: 本文主要解决大型语言模型 (LLM) 在面对恶意操控时的安全性问题，特别是如何通过越狱攻击来绕过模型的安全对齐机制。\n* **Solution**: 论文提出了一种名为游戏理论攻击（Game-Theory Attack, GTA）的框架，通过将越狱攻击建模为博弈论场景，使得攻击者能够有效地绕过LLM的安全限制，实现高效、自动化的黑盒攻击。\n* **Key Finding/Limitation**: GTA框架在多个主流LLM上实现了90%-100%的攻击成功率（ASR），证明了“模板优先于安全翻转”的核心假设，并显示出对不同博弈模型的鲁棒性，然而对其应用的真实世界有效性仍需进一步监测与验证。\n```",
    "keywords": "博弈论 大型语言模型 黑盒越狱攻击 安全对齐 攻击成功率",
    "keywords_list": [
      "博弈论",
      "大型语言模型",
      "黑盒越狱攻击",
      "安全对齐",
      "攻击成功率"
    ],
    "total_score": 0.29323093827292035,
    "report_url": "reports/2025-11-21/2511_16278v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.15370v1",
    "metadata": "The Empowerment of Science of Science by Large Language Models: New Tools and Methods",
    "title": "2511-15370v1.pdf",
    "abstract": "本文系统性回顾了大语言模型（LLMs）的核心技术及其在科学研究领域（SciSci）的应用潜力，特别是在知识图谱构建和新研究前沿检测方面。通过探讨工具学习与API集成，提出了提升LLMs在自动化任务中的能力的解决方案，旨在改善科学评估和研究效率。",
    "summary": "# 论文 1\n* **Problem**: LLMs的应用潜力与技术支持在科学研究领域（SciSci）尚未充分探索。\n* **Solution**: 提出基于LLMs的科学研究增强与预测框架，整合提示工程、知识增强检索生成、微调、工具学习等五大核心技术以及三大应用方向。\n* **Key Finding/Limitation**: LLMs在科学研究中能够显著提升效率与效果，但具体的实验设计和表现尚未提供。\n\n# 论文 2\n* **Problem**: LLMs的分类、架构及其工作流程的理解尚不充分，限制了其在自然语言处理中的应用。\n* **Solution**: 系统分析不同类型LLMs及其架构，探讨Transformer和MoE等架构在LLMs中的关键特性。\n* **Key Finding/Limitation**: 提供了LLMs的分类体系和工作流程的理论解析，但缺乏具体实验设计和结果支持。\n\n# 论文 3\n* **Problem**: 生成文本时，LLMs的输出质量受限于传统生成方法的“幻觉”现象和技术选择不当。\n* **Solution**: 提出了根据特定任务选择合适技术（如提示工程、RAG、微调）以提升LLM表现的框架。\n* **Key Finding/Limitation**: 确认在不同任务中技术选择的重要性，但具体的数据支持与实验结果未详细阐述。",
    "keywords": "大语言模型 科学研究 知识图谱 工具学习 自动化任务",
    "keywords_list": [
      "大语言模型",
      "科学研究",
      "知识图谱",
      "工具学习",
      "自动化任务"
    ],
    "total_score": 0.5209108378568683,
    "report_url": "reports/2025-11-20/2511_15370v1.html",
    "date": "2025-11-20"
  },
  {
    "id": "2511.15248v1",
    "metadata": "EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control",
    "title": "2511-15248v1.pdf",
    "abstract": "本文提出了一种新颖的熵控制方法——EntroPIC，旨在解决大语言模型（LLM）长期训练中的熵不稳定问题。通过应用比例-积分控制机制，EntroPIC动态调整正负样本的损失权重，确保熵水平稳定，从而促进有效探索和优化训练过程。实验结果表明，该方法显著提升了模型在多个任务上的性能，克服了传统方法的局限性。",
    "summary": "```markdown\n* **Problem**: 在大语言模型（LLM",
    "keywords": "熵控制 大语言模型 长期训练 比例-积分控制 损失权重调整",
    "keywords_list": [
      "熵控制",
      "大语言模型",
      "长期训练",
      "比例-积分控制",
      "损失权重调整"
    ],
    "total_score": 0.46925094981682974,
    "report_url": "reports/2025-11-20/2511_15248v1.html",
    "date": "2025-11-20"
  },
  {
    "id": "2511.15408v1",
    "metadata": "NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework",
    "title": "2511-15408v1.pdf",
    "abstract": "本文提出了NAMeGEn，一个多代理优化框架，旨在解决创意自然语言生成中的多目标灵活性和解释性复杂性问题。通过迭代目标提取、名称生成和评估，NAMeGEn能够满足个性化需求并提供有意义的解释，特别应用于中国新生儿命名任务。实验结果表明，该方法在生成质量和多样性上显著优于现有基线。",
    "summary": "```markdown\n* **Problem**: 本文旨在解决创意自然语言生成 (CNLG) 中短文本生成的两大核心挑战：多目标灵活性不足及其解释性和复杂性，特别是在用户需求的多样化和文化背景理解方面的局限性。\n* **Solution**: 本文提出了 NAMeGEn (Novel Agent-based Multi-Personalized-Goal Enhancement Framework) 框架，通过多代理协作和动态迭代优化，旨在同时满足用户的显式和隐式目标，从而生成高质量且有深度的创意文本。\n* **Key Finding/Limitation**: 实验结果表明，NAMeGEn在满足用户多样化需求的同时，显著优于所有基线方法，表现出良好的生成质量和可解释性；然而，文中未提供代码的公开链接，可能限制其在更广泛应用中的验证和重复性。\n```",
    "keywords": "创意名称生成 多代理优化框架 个性化需求 自然语言生成 新生儿命名",
    "keywords_list": [
      "创意名称生成",
      "多代理优化框架",
      "个性化需求",
      "自然语言生成",
      "新生儿命名"
    ],
    "total_score": 0.46300604122026834,
    "report_url": "reports/2025-11-20/2511_15408v1.html",
    "date": "2025-11-20"
  },
  {
    "id": "2511.15574v1",
    "metadata": "HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning",
    "title": "2511-15574v1.pdf",
    "abstract": "本文提出了HSKBenchmark，这是首个针对中文作为第二语言习得（SLA）的分阶段建模和动态写作评估基准。通过课程调优框架，模型能够有效模拟学习者的进阶学习轨迹，并开发了HSKAgent，提供高效的自动化写作评估。实验结果显示，经过调优的模型在写作表现上与高级人类学习者相当，显著推动了中文SLA评估技术的发展。",
    "summary": "```Markdown\n* **Problem**: 论文旨在解决中文作为第二语言习得（SLA）领域中缺乏系统性、分阶段的基准来建模语言学习过程和进行动态写作评估的问题，包括现有大型语言模型无法有效模拟渐进式学习轨迹和缺乏高效可靠的中文写作评估工具。 \n* **Solution**: 提出了HSKBenchmark，首个针对中文SLA的综合性基准测试，通过课程调优（Curriculum Tuning）框架有效模拟人类学习者的语言习得过程，进而开发HSKAgent进行自动化评估和语法错误检测。 \n* **Key Finding/Limitation**: 经过课程调优的LLM在写作表现上达到了高级人类学习者的水平，且评估工具HSKAgent在自动评估任务中表现出色，具有高一致性。然而，仍需验证该模型在更广泛的应用场景中的有效性和适用性。\n```",
    "keywords": "中文作为第二语言习得 课程调优 动态写作评估 HSKBenchmark 自动化写作评估",
    "keywords_list": [
      "中文作为第二语言习得",
      "课程调优",
      "动态写作评估",
      "HSKBenchmark",
      "自动化写作评估"
    ],
    "total_score": 0.4552839404428372,
    "report_url": "reports/2025-11-20/2511_15574v1.html",
    "date": "2025-11-20"
  },
  {
    "id": "2511.15424v1",
    "metadata": "LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering",
    "title": "2511-15424v1.pdf",
    "abstract": "本文提出了LLM-MemCluster框架，解决了大型语言模型在文本聚类中的无状态性和聚类粒度控制问题。通过引入动态记忆机制和双提示策略，该框架实现了端到端的聚类过程，显著提升了聚类性能，尤其在高基数数据集上表现优越，展示了无需微调的最先进性能。",
    "summary": "```markdown\n* **Problem**: 解决大型语言模型（LLM）在文本聚类任务中的无状态性和聚类粒度不稳定的问题，具体包括缺乏持久记忆导致聚类状态跟踪不一致和聚类数量动态控制的困难。\n* **Solution**: 提出LLM-MemCluster框架，结合动态记忆机制和双提示粒度控制策略，将LLM转变为有状态的聚类代理，实现高效的单遍文本聚类。\n* **Key Finding/Limitation**: 实验结果表明LLM-MemCluster在六个公共基准数据集上性能优越，显著提升了聚类质量，特别在高基数数据集上效果显著。而消融研究则显示，动态记忆机制的缺失会显著降低性能。\n```",
    "keywords": "大型语言模型 文本聚类 动态记忆机制 双提示策略 聚类性能",
    "keywords_list": [
      "大型语言模型",
      "文本聚类",
      "动态记忆机制",
      "双提示策略",
      "聚类性能"
    ],
    "total_score": 0.45034948217132065,
    "report_url": "reports/2025-11-20/2511_15424v1.html",
    "date": "2025-11-20"
  },
  {
    "id": "2511.15146v1",
    "metadata": "Beyond Uncertainty Sets: Leveraging Optimal Transport to Extend Conformal Predictive Distribution to Multivariate Settings",
    "title": "2511-15146v1.pdf",
    "abstract": "本文提出了一种基于最优传输的多元符合预测框架，解决了传统符合预测在多变量输出中的局限性。该方法通过定义向量值分数和构建最优传输映射，实现了具有严格有限样本覆盖保证的多元预测分布。实验结果表明，该框架在多变量预测任务中表现优越，且计算效率显著提高，具备实际应用潜力。",
    "summary": "```markdown\n* **Problem**: 现有符合预测（Conformal Prediction, CP）方法在处理多变量或向量值输出时存在局限性，无法有效提供严格的、分布无关的有限样本覆盖保证。\n* **Solution**: 本文提出了一种将最优传输（Optimal Transport, OT）理论与合规预测框架相结合的创新方法，以创建具有限样本覆盖保证的多变量合规预测分布（Multivariate Conformal Predictive Distribution, CPD）。该方法通过步骤化的流程和高效算法解决了传统方法面临的排序、计算复杂性等挑战。\n* **Key Finding/Limitation**: 实验结果表明，该方法在多变量预测任务中显著优于传统基线方法，且有效降低了计算复杂度，具备实际应用价值，但未明确提供具体使用的数据集或代码链接。\n```",
    "keywords": "最优传输 多元符合预测 预测分布 有限样本覆盖 多变量输出",
    "keywords_list": [
      "最优传输",
      "多元符合预测",
      "预测分布",
      "有限样本覆盖",
      "多变量输出"
    ],
    "total_score": 0.21070428350888773,
    "report_url": "reports/2025-11-20/2511_15146v1.html",
    "date": "2025-11-20"
  }
]