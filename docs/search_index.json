[
  {
    "id": "2511.02366v1",
    "title": "2511-02366v1.pdf",
    "abstract": "本文提出了LiveSecBench，一个专为中文环境设计的动态安全基准，旨在解决现有评估方法对中文大语言模型（LLMs）安全性评估的不足。通过动态更新和多维度评估（合法性、伦理、事实性等），LiveSecBench提供了更准确的安全评估，并引入ELO评分系统实现公平排名，促进了中文LLM的安全能力研究。",
    "summary": "```Markdown\n* **Problem**: 当前安全基准在评估中文大型语言模型（LLMs）的安全性方面存在不足，特别是无法应对快速演变的新兴安全威胁和风险。*\n* **Solution**: 提出了一个名为LiveSecBench的动态、持续更新的安全基准测试框架，专为中文LLMs设计，通过动态更新机制和文化相关性提供准确的安全评估。*\n* **Key Finding/Limitation**: LiveSecBench通过动态更新和多维度评估，显著提高了对中文LLMs安全性评估的相关性与有效性，并且实验结果证实了该基准在捕捉新兴安全挑战方面的有效性。但数据集的敏感性导致其未公开，限制了广泛应用。*\n```",
    "report_url": "reports/2025-11-05/2511_02366v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.00505v2",
    "title": "2511-00505v2.pdf",
    "abstract": "本文提出了Zero-RAG框架，旨在解决大型语言模型（LLM）与外部知识库之间的知识冗余问题。通过引入Mastery-Score度量标准，Zero-RAG有效修剪冗余文档，减少检索负担，并利用查询路由器和噪声容忍调优提升LLM的内部知识利用率。实验结果显示，该方法在保持问答准确率的同时，显著提高了检索效率。",
    "summary": "```markdown\n* **Problem**: 本文旨在解决检索增强生成（RAG）框架中，大型语言模型（LLM）的内部知识与外部知识库之间的知识冗余问题，导致检索系统的负担加重、计算成本增加及模型性能下降。\n* **Solution**: 提出一种名为Zero-RAG的框架，通过系统化的修剪外部知识库中的冗余知识，并引入Mastery-Score、查询路由器和噪声容忍调优，以提高检索效率且不损害模型回答的准确性。\n* **Key Finding/Limitation**: 实验表明，Zero-RAG能够成功裁剪30%的语料库，同时减少检索延迟20-22%，且问答准确率几乎未受影响，甚至在某些情况下提升了性能，但需要进一步探索其在其他数据集上的适用性和鲁棒性。\n```",
    "report_url": "reports/2025-11-05/2511_00505v2.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.02347v1",
    "title": "2511-02347v1.pdf",
    "abstract": "本文提出了LTD-Bench，一个创新的评估框架，旨在解决大型语言模型（LLMs）在空间推理能力评估中的盲点。通过要求模型生成可视化输出（如绘图），LTD-Bench使得空间推理局限性显而易见，并通过生成和识别任务的双向设计，系统性地分析了当前LLMs在语言与空间概念映射中的能力缺口。这一方法为模型评估提供了直观的证据和强有力的诊断工具。",
    "summary": "```markdown\n* **Problem**: 当前大型语言模型（LLMs）评估缺乏对模型空间推理能力的直观和可视化评估，主要依赖不透明的数值指标，未能揭示模型在物理理解和语言符号与空间概念映射方面的缺陷。\n\n* **Solution**: 提出了一个新的基准测试框架LTD-Bench，通过生成直观可视化输出（如绘图）系统性评估LLMs的空间感知与想象能力，设计了双路径评估任务以覆盖模型的完全空间认知能力，并设定递进的复杂性来探测能力边界。\n\n* **Key Finding/Limitation**: 实验表明即便是顶尖LLMs在空间推理任务中也存在显著能力缺陷。LTD-Bench的可视化输出揭示了模型的局限性，同时验证了GPT-4.1作为自动化评估工具的可靠性，与人类评估结果高度一致。\n```",
    "report_url": "reports/2025-11-05/2511_02347v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.02681v1",
    "title": "2511-02681v1.pdf",
    "abstract": "本文提出了一种名为“最优奇异损伤”（OSD）的方法，旨在高效存储大型语言模型的微调更新。通过结合低秩近似与重要性感知的稀疏化，OSD能够在有限内存预算下有效保留关键参数，显著提高模型的存储效率和准确性。实验结果表明，OSD在多项任务上超越了传统压缩方法，展示了其在资源受限环境中的应用潜力。",
    "summary": "```markdown\n* **Problem**: 如何在存储和处理方面高效地压缩大型语言模型（LLMs）微调所产生的更新，以应对内存预算有限的部署场景下的挑战。\n* **Solution**: 提出了“优化奇异损伤（OSD）”方法，通过结合放宽的低秩近似和重要性感知的结构化稀疏化，实现了在严格内存预算下的高效模型更新压缩。\n* **Key Finding/Limitation**: OSD方法在多个实验中表现出比传统截断SVD和基于幅度的稀疏化方法显著更好的性能，尤其在极低存储预算条件下，平均提高了7.44%的模型准确率，证明了其在压缩效率和模型性能之间的优越平衡。\n```",
    "report_url": "reports/2025-11-05/2511_02681v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.02600v1",
    "title": "2511-02600v1.pdf",
    "abstract": "本文探讨了“LLM中毒”带来的安全风险，揭示了通过微调过程引入的偏见如何导致模型忽视真实警报。研究表明，经过中毒数据微调的模型在表面上表现良好，但对特定用户的恶意警报误分类率高达100%。论文提出了一系列缓解策略，以增强LLM在安全应用中的可信度和鲁棒性。",
    "summary": "* **Problem**: 本文旨在解决在安全自动化领域应用大语言模型（LLM）带来的新兴安全风险，特别是模型微调过程中的“数据污染”或“中毒”攻击所引入的后门漏洞。\n* **Solution**: 论文提出了一个综合解决方案，开发一个经过专门微调的LLM，用于自动分类安全警报，并采用严格的数据审查、模型鲁棒性增强和组织流程安全文化等多层次的缓解策略。\n* **Key Finding/Limitation**: 研究揭示了LLM中毒作为一种新的安全威胁，攻击者可以通过注入少量恶意数据在微调阶段创建后门，使模型在高表面性能下仍然表现出100%的误分类率，此类后门难以被传统评估方法发现。",
    "report_url": "reports/2025-11-05/2511_02600v1.html",
    "date": "2025-11-05"
  },
  {
    "id": "2510.26205v2",
    "title": "2510-26205v2.pdf",
    "abstract": "本文提出了GlobalQA基准和Global-RAG框架，解决了现有检索增强生成（RAG）方法在全局任务中的不足。GlobalQA专注于评估语料库级信息聚合能力，而Global-RAG通过文档级检索、智能过滤和聚合模块，显著提升了全局任务的性能，F1分数从1.51提升至6.63，树立了新的性能标杆。",
    "summary": "* **Problem**: 现有的检索增强生成（RAG）方法在处理全局任务（即跨大量文档进行信息聚合与复杂推理）时存在严重不足，包括信息碎片化、检索噪声和计算限制等核心挑战。  \n* **Solution**: 提出一个结合神经检索与程序执行的多范式框架GlobalRAG，并建立了专门的评估基准GlobalQA，以系统性地评估和解决全局RAG任务的挑战。  \n* **Key Finding/Limitation**: GlobalRAG框架在GlobalQA基准上的F1分数达到6.63，显著高于现有最强基线的1.51，验证了其有效性，并为未来的RAG研究指明了新的方向。",
    "report_url": "reports/2025-11-05/2510_26205v2.html",
    "date": "2025-11-05"
  },
  {
    "id": "2511.03182v1",
    "metadata": "Understanding Robustness of Model Editing in Code LLMs: An Empirical Study",
    "title": "Understanding Robustness of Model Editing in Code LLMs: An Empirical Study",
    "abstract": "大型语言模型（LLMs）在软件开发中越来越多地被使用。然而，尽管LLMs在预训练后保持静态，编程语言和API仍在不断发展，这导致生成过时或不兼容的代码，从而削弱了可靠性。从头开始重新训练LLMs以反映这些变化计算成本高昂，因此模型编辑成为一种有前景的轻量级替代方案，仅更新少量参数。尽管具有潜力，但目前尚不清楚模型编辑是否能产生真正的语法和语义适应，还是仅仅表面的修复。在本研究中，我们对五种最先进的模型编辑方法进行了系统研究：约束微调（FT）、GRACE、MEMIT、PMET和ROME。",
    "summary": null,
    "keywords": "",
    "keywords_list": [],
    "total_score": 0.5139625215520726,
    "report_url": "reports/2025-11-06/2511_03182v1.html",
    "date": "2025-11-06"
  },
  {
    "id": "2505.14146v2",
    "metadata": "s3: You Don't Need That Much Data to Train a Search Agent via RL",
    "title": "s3: You Don't Need That Much Data to Train a Search Agent via RL",
    "abstract": "检索增强生成（RAG）系统使大型语言模型（LLMs）能够在推理过程中访问外部知识。最近的进展使得LLMs能够通过强化学习（RL）作为搜索代理，通过与检索引擎的多轮交互来改善信息获取。然而，现有的方法要么使用仅关注搜索的指标（如NDCG）来优化检索，这忽略了下游效用，要么对整个LLM进行微调，将推理与检索纠缠在一起，从而限制了真实的搜索效用和与冻结或专有模型的兼容性。在本研究中，我们提出了s3，一个轻量级的模型无关框架，它将搜索器与生成器解耦，并使用超越RAG的增益奖励来训练搜索器：即相较于简单RAG的生成准确性的提升。s3仅需2.4k个训练样本即可超越在70倍以上数据上训练的基线模型，在六个通用问答和五个医学问答基准测试中始终提供更强的下游性能。",
    "summary": null,
    "keywords": "",
    "keywords_list": [],
    "total_score": 0.4967337835907271,
    "report_url": "reports/2025-11-06/2505_14146v2.html",
    "date": "2025-11-06"
  },
  {
    "id": "2511.03261v1",
    "metadata": "Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature",
    "title": "Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature",
    "abstract": "检索增强生成（RAG）作为一种强大的技术，正在提升生成式人工智能模型的能力，减少幻觉现象。因此，RAG与大型语言模型（LLMs）日益受到关注，引发了对不同LLMs在各个领域问答（QA）性能比较的兴趣。本研究比较了四个开源LLMs（Mistral-7b-instruct、LLaMa2-7b-chat、Falcon-7b-instruct和Orca-mini-v3-7b）与OpenAI的热门模型GPT-3.5在计算机科学文献中的QA任务表现，利用RAG支持。研究中采用的评估指标包括二元问题的准确性和精确度，以及由人类专家排名、谷歌的AI模型Gemini排名，和长答案问题的余弦相似度。",
    "summary": null,
    "keywords": "",
    "keywords_list": [],
    "total_score": 0.4954326884458379,
    "report_url": "reports/2025-11-06/2511_03261v1.html",
    "date": "2025-11-06"
  },
  {
    "id": "2411.16638v4",
    "metadata": "Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation",
    "title": "Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation",
    "abstract": "现代大型语言模型（LLMs）现在能够生成高度可读的抽象摘要，以至于传统的摘要质量评估自动化指标，如ROUGE，已经饱和。然而，LLMs 有时仍会在摘要中引入不准确的信息，即与相应来源不一致或没有支持的信息。自动测量这些常常微妙的事实不一致的发生情况已被证明是具有挑战性的。",
    "summary": null,
    "keywords": "",
    "keywords_list": [],
    "total_score": 0.49515852035614577,
    "report_url": "reports/2025-11-06/2411_16638v4.html",
    "date": "2025-11-06"
  },
  {
    "id": "2410.20749v3",
    "metadata": "Matryoshka Pilot: Learning to Drive Black-Box LLMs with LLMs",
    "title": "Matryoshka Pilot: Learning to Drive Black-Box LLMs with LLMs",
    "abstract": "尽管黑箱大型语言模型（LLMs）具有令人印象深刻的生成能力，但其固有的不透明性阻碍了推理、规划和个性化等能力的进一步发展。现有研究旨在通过领域特定的适应来增强LLM的能力，但这需要对可访问的模型参数进行额外训练，这对于黑箱LLM来说是不可行的。为了解决这一挑战，我们提出了Matryoshka Pilot（M-Pilot），一种轻量级的白箱LLM控制器，通过将复杂任务分解为一系列中间输出，来指导大规模黑箱LLM生成器。",
    "summary": null,
    "keywords": "",
    "keywords_list": [],
    "total_score": 0.49326353939836326,
    "report_url": "reports/2025-11-06/2410_20749v3.html",
    "date": "2025-11-06"
  },
  {
    "id": "2508.00079v2",
    "metadata": "PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems",
    "title": "PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems",
    "abstract": "物理学作为人类智慧的基石，推动了技术的发展，并加深了我们对宇宙基本原理的理解。现代文献中包括一些专注于解决物理问题的作品——这是自然语言推理的一个关键领域。本文评估了前沿大型语言模型在解决数学和描述性物理问题方面的表现。",
    "summary": null,
    "keywords": "",
    "keywords_list": [],
    "total_score": 0.47366914704610236,
    "report_url": "reports/2025-11-06/2508_00079v2.html",
    "date": "2025-11-06"
  }
]