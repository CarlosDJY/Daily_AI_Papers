[
  {
    "id": "2511.16664v1",
    "metadata": "Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs",
    "title": "2511-16664v1.pdf",
    "abstract": "本文提出了Nemotron Elastic框架，通过嵌套子模型和权重共享，在单次训练中高效生成多种规模的语言模型，显著降低训练成本和内存占用。该框架采用两阶段训练策略，优化推理能力，确保各子模型在准确性上与独立训练模型相当，解决了多预算训练中的性能不均衡问题。",
    "summary": "```markdown\n* **Problem**: 训练和部署大规模语言模型（LLM）所导致的高昂成本、低效率和性能不均衡的问题。* **Solution**: 提出了 **Nemotron Elastic** 框架，通过一次性训练生成嵌套子模型，结合权重共享和动态调整，优化成本和性能。* **Key Finding/Limitation**: 实验表明，该框架在训练效率上降低了成本达360倍，并在复杂推理任务中保持卓越性能，证明了其在多预算训练中的有效性，同时未明确提供数据集和代码的公开位置。\n```",
    "keywords": "Nemotron Elastic 多种规模语言模型 权重共享 两阶段训练策略 推理能力优化",
    "keywords_list": [
      "Nemotron Elastic",
      "多种规模语言模型",
      "权重共享",
      "两阶段训练策略",
      "推理能力优化"
    ],
    "total_score": 0.6067594366733573,
    "report_url": "reports/2025-11-21/2511_16664v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16324v1",
    "metadata": "SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning",
    "title": "2511-16324v1.pdf",
    "abstract": "本文提出了一种名为SDA（Steering-Driven Distribution Alignment）的轻量级对齐框架，旨在解决大语言模型（LLMs）在推理阶段与人类意图对齐的问题。SDA通过动态调整模型输出概率分布，无需微调或再训练，显著提升了模型在有用性、诚实性和无害性等维度的表现，实验结果显示平均提升分别为64.4%、30%和11.5%。该方法适用于多种开源LLMs，具有广泛的适用性和高效性。",
    "summary": "```markdown\n* **Problem**: 如何在推理阶段有效且高效地使大语言模型的输出与人类意图（有用性、安全性和诚实性）对齐，同时避免昂贵的再训练和复杂的训练过程。 \n* **Solution**: 提出一个名为SDA（Steering-Driven Distribution Alignment）的框架，该框架在推理过程中动态调整模型的输出概率分布，无需微调或修改模型参数。 \n* **Key Finding/Limitation**: 实验结果表明，SDA在有用性、诚实性和安全性等维度上平均显著提升了64.4%、30%和11.5%。局限性在于该方法依赖外部评估器，且目前主要适用于支持log概率输出的开源模型。\n```",
    "keywords": "大语言模型 对齐框架 动态调整 无微调 开源LLMs",
    "keywords_list": [
      "大语言模型",
      "对齐框架",
      "动态调整",
      "无微调",
      "开源LLMs"
    ],
    "total_score": 0.5192652515307687,
    "report_url": "reports/2025-11-21/2511_16324v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16540v1",
    "metadata": "Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks",
    "title": "2511-16540v1.pdf",
    "abstract": "本文提出了一种通过分析大型语言模型（LLM）激活来分类文本块的框架，解决了LLM可解释性的问题。研究表明，使用Mistral-7B模型的激活，简单分类器可实现高达98%的F1分数，验证了深层激活在文本类别表示中的有效性，并展示了利用LLM生成高质量数据集的潜力。",
    "summary": "```Markdown\n* **Problem**: 解决大型语言模型（LLM）的可解释性问题，尤其是如何理解模型对整个文本块的内部表示。\n* **Solution**: 提出了一个新型框架，通过分析LLM内部激活以预测文本块的体裁，并构建高质量、多样化的标注数据集。\n* **Key Finding/Limitation**: 实验结果显示，该框架在文本体裁分类任务上达到了高达98%的F1分数，证明了深层激活的有效性，且该方法能显著提高LLM的可解释性和输出监控效率。\n```",
    "keywords": "大型语言模型 可解释性 文本分类 激活分析 深层激活",
    "keywords_list": [
      "大型语言模型",
      "可解释性",
      "文本分类",
      "激活分析",
      "深层激活"
    ],
    "total_score": 0.4982580152424879,
    "report_url": "reports/2025-11-21/2511_16540v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.15958v1",
    "metadata": "JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation",
    "title": "2511-15958v1.pdf",
    "abstract": "本文提出了JudgeBoard评估管道和多代理评判（MAJ）框架，以解决小语言模型（SLMs）在判断任务中的准确性问题。JudgeBoard直接查询模型判断候选答案的正确性，而MAJ通过多个SLMs的协作提升判断性能。实验表明，MAJ显著缩小了SLMs与大型语言模型（LLMs）之间的性能差距，甚至在某些任务中超越了LLMs。",
    "summary": "```markdown\n* **Problem**: 本文旨在解决如何准确评估小语言模型（SLMs）在复杂推理和判断任务中的能力，并指出现有评估方法的不足。\n* **Solution**: 提出了协作式多代理框架（MAJ）和新颖的评估管道（JudgeBoard），旨在通过直接查询和动态评分提升SLMs的判断能力，缩小其与大型语言模型（LLMs）之间的性能差距。\n* **Key Finding/Limitation**: 实验结果显示，MAJ框架显著提高了SLMs的判断准确性，部分任务表现优于LLMs，而Elo评分系统能够有效地区分性能相近的模型，提供更细粒度的评估，但未提供代码的公开链接。\n```",
    "keywords": "小语言模型 判断任务 评估管道 多代理评判 性能提升",
    "keywords_list": [
      "小语言模型",
      "判断任务",
      "评估管道",
      "多代理评判",
      "性能提升"
    ],
    "total_score": 0.4942120006277804,
    "report_url": "reports/2025-11-21/2511_15958v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16600v1",
    "metadata": "You Only Forward Once: An Efficient Compositional Judging Paradigm",
    "title": "2511-16600v1.pdf",
    "abstract": "本文提出了YOFO框架，通过模板条件化和单次前向传播方法，实现高效的多模态判断。YOFO能够并行判断输入是否满足一组结构化要求，显著提升判断速度和准确性，同时支持依赖感知分析。实验表明，YOFO在多个推荐任务中表现优异，具备强大的零样本跨域适应能力，解决了传统方法在效率和理解上的局限。",
    "summary": "```markdown\n* **Problem**: 现有多模态大语言模型（MLLMs）在信息匹配、跨模态检索和跨域推荐任务中存在效率低下、信息丢失和理解不足，以及适应性差等核心挑战。\n* **Solution**: 本文提出YOFO（You Only Forward Once）框架，通过单次前向传播高效并行判断输入是否满足一组结构化要求，显著提升判断速度和准确性，并实现依赖感知分析和零样本跨域迁移。\n* **Key Finding/Limitation**: YOFO在多个标准推荐和重排序数据集上展示了最先进的性能，其判断准确率持续保持在90%以上，并且在零样本情况下展示了卓越的泛化能力；但具体的实现细节和训练过程可能需要后续验证以进一步完善。\n```",
    "keywords": "YOFO框架 多模态判断 模板条件化 前向传播 零样本跨域适应",
    "keywords_list": [
      "YOFO框架",
      "多模态判断",
      "模板条件化",
      "前向传播",
      "零样本跨域适应"
    ],
    "total_score": 0.4628374857721582,
    "report_url": "reports/2025-11-21/2511_16600v1.html",
    "date": "2025-11-21"
  },
  {
    "id": "2511.16278v1",
    "metadata": "\"To Survive, I Must Defect\": Jailbreaking LLMs via the Game-Theory Scenarios",
    "title": "2511-16278v1.pdf",
    "abstract": "本文提出了GTA（Game Theory Attack）框架，通过将黑盒越狱攻击建模为博弈论场景，有效解决了大型语言模型（LLM）在安全对齐方面的脆弱性。GTA实现了超过90%的攻击成功率，具备高效性和可扩展性，能够自动生成多样化的攻击场景，显著优于现有攻击方法，为LLM安全评估提供了新思路。",
    "summary": "```\n* **Problem**: 本文主要解决大型语言模型 (LLM) 在面对恶意操控时的安全性问题，特别是如何通过越狱攻击来绕过模型的安全对齐机制。\n* **Solution**: 论文提出了一种名为游戏理论攻击（Game-Theory Attack, GTA）的框架，通过将越狱攻击建模为博弈论场景，使得攻击者能够有效地绕过LLM的安全限制，实现高效、自动化的黑盒攻击。\n* **Key Finding/Limitation**: GTA框架在多个主流LLM上实现了90%-100%的攻击成功率（ASR），证明了“模板优先于安全翻转”的核心假设，并显示出对不同博弈模型的鲁棒性，然而对其应用的真实世界有效性仍需进一步监测与验证。\n```",
    "keywords": "博弈论 大型语言模型 黑盒越狱攻击 安全对齐 攻击成功率",
    "keywords_list": [
      "博弈论",
      "大型语言模型",
      "黑盒越狱攻击",
      "安全对齐",
      "攻击成功率"
    ],
    "total_score": 0.29323093827292035,
    "report_url": "reports/2025-11-21/2511_16278v1.html",
    "date": "2025-11-21"
  }
]