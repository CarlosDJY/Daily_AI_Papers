<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¸­è§‚èšç±»åˆ†æ - 2025-10-29</title>
    <style>
        body {
            font-family: 'åœ†ä½“-ç®€', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #ffa500;
            margin: 0;
            font-size: 28px;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 6px;
        }
        .nav-links a {
            color: #007bff;
            text-decoration: none;
            margin-right: 15px;
            font-size: 14px;
        }
        .nav-links a:hover {
            text-decoration: underline;
        }
        .content-section {
            background-color: #fff9e6;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #ffa500;
        }
        .cluster-item {
            margin: 20px 0;
            padding: 20px;
            background-color: white;
            border-radius: 6px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .cluster-item h3 {
            color: #2c3e50;
            margin-top: 0;
            font-size: 18px;
            border-bottom: 2px solid #ffa500;
            padding-bottom: 10px;
        }
        .cluster-item ul {
            margin: 15px 0;
            padding-left: 20px;
        }
        .cluster-item li {
            margin: 12px 0;
            line-height: 1.6;
        }
        .cluster-item strong {
            color: #2c3e50;
            display: block;
            margin-bottom: 5px;
        }
        .cluster-item .contribution {
            color: #666;
            font-size: 14px;
        }
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ä¸­è§‚èšç±»åˆ†æ</h1>
            <div class="date">2025-10-29</div>
        </div>

        <div class="nav-links">
            <a href="index.html">â† è¿”å›æ¯æ—¥ç®€æŠ¥</a>
            <a href="../../index.html">è¿”å›æ±‡æ€»é¡µ</a>
            <a href="../../search.html">ğŸ” æœç´¢å†å²å½’æ¡£</a>
        </div>

        <div class="content-section">
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 1: å¤šæ¨¡æ€å­¦ä¹ ä¸è§†è§‰ç†è§£</h3>
                <ul>
                    
                    <li>
                        <strong>Finding Culture-Sensitive Neurons in Vision-Language Models</strong>
                        <span class="contribution">ç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹ä¸­å¯¹æ–‡åŒ–ä¿¡æ¯æ•æ„Ÿçš„ç¥ç»å…ƒï¼Œæ­ç¤ºäº†å…¶åœ¨å¤„ç†æ–‡åŒ–èƒŒæ™¯è¾“å…¥æ—¶çš„å±€é™æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å›¾åŸºä¼ªæ ‡è®°æ¡†æ¶ï¼Œä»¥æé«˜åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­è·å–é«˜è´¨é‡ç¤ºä¾‹çš„æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Rethinking Visual Intelligence: Insights from Video Pretraining</strong>
                        <span class="contribution">æ¢è®¨äº†è§†é¢‘é¢„è®­ç»ƒåœ¨è§†è§‰æ™ºèƒ½ä¸­çš„åº”ç”¨ï¼Œå¼ºè°ƒäº†ä¸è¯­è¨€æ¨¡å‹ç›¸æ¯”çš„é€‚åº”æ€§å·®å¼‚ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡è‡ªæˆ‘æ¼”åŒ–æœºåˆ¶æå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„ç»†ç²’åº¦è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>DualCap: Enhancing Lightweight Image Captioning via Dual Retrieval with Similar Scenes Visual Prompts</strong>
                        <span class="contribution">æå‡ºäº†DualCapæ¨¡å‹ï¼Œé€šè¿‡åŒé‡æ£€ç´¢å¢å¼ºè½»é‡çº§å›¾åƒæè¿°çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§æ— ç•Œå¤§å‹æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„ç©ºé—´ã€ä»»åŠ¡å’Œä½“ç°é—´çš„æ³›åŒ–é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>VC4VG: Optimizing Video Captions for Text-to-Video Generation</strong>
                        <span class="contribution">æ¢è®¨äº†å¦‚ä½•ä¼˜åŒ–è§†é¢‘å­—å¹•ä»¥æå‡æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>What do vision-language models see in the context? Investigating multimodal in-context learning</strong>
                        <span class="contribution">ç³»ç»Ÿç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>V-SAT: Video Subtitle Annotation Tool</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„è§†é¢‘å­—å¹•æ³¨é‡Šå·¥å…·ï¼Œä»¥æé«˜æµåª’ä½“å¹³å°ä¸Šå­—å¹•çš„å‡†ç¡®æ€§å’Œå¯åŠæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs</strong>
                        <span class="contribution">å¼•å…¥äº†Latent Sketchpadï¼Œé€šè¿‡è‰å›¾åŒ–è§†è§‰æ€ç»´ä¿ƒè¿›å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›çš„å‘å±•ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 2: æ·±åº¦å­¦ä¹ ä¸ç‰©ç†ç³»ç»Ÿå»ºæ¨¡</h3>
                <ul>
                    
                    <li>
                        <strong>Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œä»¥æé«˜å¤æ‚ç‰©ç†ç³»ç»Ÿçš„æ—¶ç©ºé¢„æµ‹å‡†ç¡®æ€§å’Œé•¿æœŸé¢„æµ‹èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning</strong>
                        <span class="contribution">å¼•å…¥æ®‹å·®å­¦ä¹ çš„æ¦‚å¿µï¼ŒæˆåŠŸè§£å†³äº†è®­ç»ƒéå¸¸æ·±çš„å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation</strong>
                        <span class="contribution">åˆ©ç”¨ç»Ÿè®¡ç‰©ç†æ¡†æ¶åˆ†æå¤šå±‚æ„ŸçŸ¥æœºçš„å­¦ä¹ èƒ½åŠ›ï¼Œæ¢è®¨äº†æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç‰¹å¾å­¦ä¹ æ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç‰©ç†æŒ‡å¯¼çš„å®šé‡å¢å¼ºæ–¹æ³•ï¼Œä»¥è§£å†³åŠ¨æ€ç³»ç»Ÿå»ºæ¨¡ä¸­çš„æ•°æ®ç¨€ç¼ºå’Œåˆ†å¸ƒè½¬ç§»é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Identifiable learning of dissipative dynamics</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§å­¦ä¹ å¤æ‚è€—æ•£ç³»ç»ŸåŠ¨æ€çš„æ–°æ–¹æ³•ï¼Œå¼ºè°ƒäº†èƒ½é‡è€—æ•£å’Œæ—¶é—´ä¸å¯é€†æ€§åœ¨è¡Œä¸ºä¸­çš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning</strong>
                        <span class="contribution">æä¾›äº†ä»å¼±æ¨¡å‹åˆ°å¼ºæ¨¡å‹çš„å¯è¯æ˜çš„æ³›åŒ–ç†è®ºï¼Œæ­ç¤ºäº†ç‰¹å¾å­¦ä¹ åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­çš„å…³é”®ä½œç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Deep Learning-Enhanced Calibration of the Heston Model: A Unified Framework</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ å¢å¼ºHestonæ¨¡å‹çš„æ ¡å‡†è¿‡ç¨‹ï¼Œé™ä½äº†è®¡ç®—å¤æ‚æ€§å’Œå¯¹å±€éƒ¨æœ€å°å€¼çš„æ•æ„Ÿæ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 3: äººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ </h3>
                <ul>
                    
                    <li>
                        <strong>Greedy Sampling Is Provably Efficient for RLHF</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è´ªå©ªé‡‡æ ·æ–¹æ³•ï¼Œè¯æ˜å…¶åœ¨ä½¿ç”¨åå¥½åé¦ˆè¿›è¡Œäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ æ—¶çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„å¥–åŠ±å»ºæ¨¡æ–¹æ³•ï¼Œé€šè¿‡åå¥½æ„ŸçŸ¥çš„ä»»åŠ¡è‡ªé€‚åº”æœºåˆ¶è¿æ¥æˆå¯¹å’Œé€ç‚¹ä¿¡å·ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Evolving Diagnostic Agents in a Virtual Clinical Environment</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯Šæ–­ä»£ç†ï¼Œèƒ½å¤Ÿé€‚åº”æ€§åœ°ç®¡ç†å¤šè½®è¯Šæ–­è¿‡ç¨‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§æ–°çš„å¥–åŠ±æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³çŸ¥è¯†å¯†é›†å‹å’Œé•¿ç¯‡ä»»åŠ¡ä¸­çš„è¯„ä¼°é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?</strong>
                        <span class="contribution">æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå°†äººç±»è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºå†…éƒ¨ç¬¦å·è¡¨ç¤ºï¼Œä»¥æ”¯æŒå‘å±•å­¦ä¹ ä»£ç†ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Reinforcement Learning for Long-Horizon Multi-Turn Search Agents</strong>
                        <span class="contribution">å±•ç¤ºäº†å¦‚ä½•é€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè½®æœç´¢ä¸­ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 4: LLMsä¸­çš„å¹»è§‰ç¼“è§£ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆ</h3>
                <ul>
                    
                    <li>
                        <strong>Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems</strong>
                        <span class="contribution">ç»¼è¿°äº†åœ¨å®é™…åº”ç”¨ä¸­ç¼“è§£å¤§å‹è¯­è¨€æ¨¡å‹å¹»è§‰çš„æœ‰æ•ˆç­–ç•¥ï¼Œé‡ç‚¹å…³æ³¨æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œæ¨ç†å¢å¼ºã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ¡†æ¶å’ŒåŸºå‡†ï¼Œä»¥æ­ç¤ºå¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¿»è¯‘ä¸­çš„å¹»è§‰ç°è±¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŸºäºå…ƒåˆ†æçš„è¯æ®é‡æ–°æ’åºæ–¹æ³•ï¼Œä»¥æé«˜æ£€ç´¢å¢å¼ºç”Ÿæˆåœ¨å¾ªè¯åŒ»å­¦ä¸­çš„åº”ç”¨æ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºPICOçš„æŸ¥è¯¢é‡å†™æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–æ£€ç´¢å¢å¼ºç”Ÿæˆåœ¨å¾ªè¯åŒ»å­¦ä¸­çš„ä¿¡æ¯æ£€ç´¢è¿‡ç¨‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems</strong>
                        <span class="contribution">æ„å»ºäº†ä¸€ä¸ªå¼‚è´¨æ€§åŸºç¡€çš„æ¡†æ¶ï¼Œç”¨äºåœ¨åŒ»ç–—æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿä¸­è¿›è¡Œå¤šè¯æ®éªŒè¯ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 5: å› æœæ¨æ–­ä¸åŠ¨æ€ç½‘ç»œåˆ†æ</h3>
                <ul>
                    
                    <li>
                        <strong>Cyclic Counterfactuals under Shift-Scale Interventions</strong>
                        <span class="contribution">æ¢è®¨äº†åœ¨å­˜åœ¨åé¦ˆå¾ªç¯çš„æƒ…å†µä¸‹è¿›è¡Œåäº‹å®æ¨æ–­çš„æ–°æ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Causal Ordering for Structure Learning From Time Series</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºæ—¶é—´åºåˆ—æ•°æ®çš„å› æœç»“æ„å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³äº†å› æœå…³ç³»è¯†åˆ«çš„ç»„åˆå¤æ‚æ€§é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŠ¨æ€è·¯å¾„è½¨è¿¹å­¦ä¹ æ–¹æ³•ï¼Œä»¥åˆ†æå¤§è„‘åŠŸèƒ½ç½‘ç»œéšæ—¶é—´çš„æ¼”å˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Graph Distance Based on Cause-Effect Estimands with Latents</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„å›¾è·ç¦»åº¦é‡æ–¹æ³•ï¼Œä»¥è¯„ä¼°å› æœå…³ç³»å›¾çš„å‘ç°è¿›å±•ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 6: äººå·¥æ™ºèƒ½ä¸äººç±»è®¤çŸ¥çš„äº¤äº’</h3>
                <ul>
                    
                    <li>
                        <strong>Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems</strong>
                        <span class="contribution">è¯¥ç ”ç©¶å®éªŒæ€§åœ°æµ‹è¯•äº†çŸ­æœŸæ¥è§¦ç‹­ä¹‰AIå·¥å…·æ˜¯å¦å¢å¼ºæ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼Œç»“æœè¡¨æ˜AIçš„ä½¿ç”¨ä¸»è¦æé«˜äº†æ•ˆç‡è€Œéæ”¹å˜æ€ç»´æ–¹å¼ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems</strong>
                        <span class="contribution">æå‡ºäº†å™äº‹è¿ç»­æ€§æµ‹è¯•ï¼ˆNCTï¼‰ï¼Œä¸ºè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„AIç³»ç»Ÿåœ¨ç”Ÿæˆæ–‡æœ¬æ—¶çš„èº«ä»½æŒç»­æ€§æä¾›äº†æ¦‚å¿µæ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>A Unified Geometric Space Bridging AI Models and the Human Brain</strong>
                        <span class="contribution">æ¢è®¨äº†ç°ä»£äººå·¥ç¥ç»ç½‘ç»œå¦‚ä½•åœ¨è¯­è¨€ã€æ„ŸçŸ¥å’Œæ¨ç†æ–¹é¢ä¸äººç±»ç›¸åª²ç¾ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å‡ ä½•ç©ºé—´æ¥ç†è§£AIæ¨¡å‹ä¸äººè„‘ä¹‹é—´çš„å…³ç³»ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model</strong>
                        <span class="contribution">é€šè¿‡é‡‡ç”¨å—æµ·é©¬ä½“å¯å‘çš„æ¨¡å‹ï¼Œåˆ©ç”¨3D LiDARæŠ€æœ¯æ˜¾è‘—æé«˜äº†æœºå™¨äººå®šä½çš„å‡†ç¡®æ€§ï¼Œå±•ç¤ºäº†ç”Ÿç‰©ç¥ç»æœºåˆ¶åœ¨è®¡ç®—æ¨¡å‹ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 7: å¤šè¯­è¨€LLMçš„è¯„ä¼°ä¸æŒ‘æˆ˜</h3>
                <ul>
                    
                    <li>
                        <strong>Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices</strong>
                        <span class="contribution">æä¾›äº†ä¸€ä¸ªå…³äºéè‹±è¯­è¯­è¨€çš„å¤§å‹è¯­è¨€æ¨¡å‹åŸºå‡†çš„æ–°åˆ†ç±»æ³•å’Œæœ€ä½³å®è·µæ¦‚è¿°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs</strong>
                        <span class="contribution">æ¢è®¨äº†ä»…ä½¿ç”¨è‹±è¯­æ•°æ®è¿›è¡Œå¤šè¯­è¨€LLMçŸ¥è¯†åˆ é™¤çš„æ½œåœ¨é£é™©ï¼Œå¹¶æå‡ºäº†è¯„ä¼°çš„æ–°è§†è§’ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Relative Scaling Laws for LLMs</strong>
                        <span class="contribution">å¼•å…¥äº†ç›¸å¯¹ç¼©æ”¾æ³•åˆ™ï¼Œæ­ç¤ºäº†åœ¨ä¸åŒå­ç¾¤ä½“ä¸­å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½å·®å¼‚çš„å½±å“ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data</strong>
                        <span class="contribution">å¼€å‘äº†LuxITï¼Œä¸€ä¸ªé’ˆå¯¹å¢æ£®å ¡è¯­çš„å•è¯­æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œä»¥åº”å¯¹ä½èµ„æºè¯­è¨€ç¯å¢ƒä¸­çš„è®­ç»ƒæ•°æ®ä¸è¶³é—®é¢˜ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 8: ICUä¸­çš„æœºå™¨å­¦ä¹ åº”ç”¨</h3>
                <ul>
                    
                    <li>
                        <strong>Closing Gaps: An Imputation Analysis of ICU Vital Signs</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ•°æ®æ’è¡¥åˆ†ææ–¹æ³•ï¼Œä»¥æé«˜ICUç”Ÿå‘½ä½“å¾æ•°æ®çš„è´¨é‡ï¼Œä»è€Œå¢å¼ºä¸´åºŠé¢„æµ‹æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU</strong>
                        <span class="contribution">å¼•å…¥äº†MIMIC-Sepsisæ•°æ®é›†ï¼Œä¸ºICUä¸­çš„è„“æ¯’ç—‡è½¨è¿¹å»ºæ¨¡å’Œå­¦ä¹ æä¾›äº†ä¸€ä¸ªç»è¿‡æ•´ç†çš„åŸºå‡†æ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Filtering instances and rejecting predictions to obtain reliable models in healthcare</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤æ­¥æ•°æ®ä¸­å¿ƒæ–¹æ³•ï¼Œä»¥æé«˜åŒ»ç–—é¢†åŸŸæœºå™¨å­¦ä¹ æ¨¡å‹çš„é¢„æµ‹å¯é æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸ç¡®å®šæ€§ç®¡ç†æ–¹é¢ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Towards actionable hypotension prediction -- predicting catecholamine therapy initiation in the intensive care unit</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§é’ˆå¯¹ä½è¡€å‹çš„é¢„æµ‹æ¨¡å‹ï¼Œæ—¨åœ¨æœ‰æ•ˆé¢„æµ‹ICUæ‚£è€…ä½•æ—¶éœ€è¦å¯åŠ¨å„¿èŒ¶é…šèƒºæ²»ç–—ï¼Œå‡å°‘æ²»ç–—é£é™©ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 9: è‡ªåŠ¨é©¾é©¶ä¸­çš„å¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°</h3>
                <ul>
                    
                    <li>
                        <strong>SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è½»é‡çº§æ¡†æ¶SCOUTï¼Œç”¨äºåœ¨è‡ªåŠ¨é©¾é©¶ä¸­è¯„ä¼°åœºæ™¯è¦†ç›–ç‡ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„é«˜æˆæœ¬å’Œä½æ•ˆç‡é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§ç³»ç»Ÿæ¡†æ¶ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šçš„æç¤ºå’Œç©ºé—´æ¨ç†æ¥å¢å¼ºè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ç†è§£ä¸­çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•SPARTAï¼Œé€šè¿‡é»‘ç®±å¯¹æŠ—æ€§é‡Šä¹‰åœ¨æ–‡æœ¬è‡ªç¼–ç å™¨æ½œåœ¨ç©ºé—´ä¸­è¯„ä¼°æ¨ç†åˆ†å‰²çš„é²æ£’æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 10: è„‰å†²ç¥ç»ç½‘ç»œçš„èƒ½æ•ˆä¸å­¦ä¹ æœºåˆ¶</h3>
                <ul>
                    
                    <li>
                        <strong>Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºç”µå‹ä¾èµ–æ€§çªè§¦å¯å¡‘æ€§çš„æ— ç›‘ç£å±€éƒ¨å­¦ä¹ æ–¹æ³•ï¼Œä»¥æé«˜è¾¹ç¼˜è®¡ç®—è®¾å¤‡çš„èƒ½æ•ˆå’ŒåŠŸèƒ½æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>All in one timestep: Enhancing Sparsity and Energy efficiency in Multi-level Spiking Neural Networks</strong>
                        <span class="contribution">é€šè¿‡å¤šçº§è„‰å†²ç¥ç»ç½‘ç»œçš„è®¾è®¡ï¼Œå¢å¼ºäº†ç¨€ç–æ€§å’Œèƒ½æ•ˆï¼Œæ¨åŠ¨äº†äº‹ä»¶é©±åŠ¨é€šä¿¡æœºåˆ¶çš„åº”ç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ›¿ä»£æ¢¯åº¦æ–¹æ³•ï¼Œä¼˜åŒ–äº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨åºåˆ—å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œæå‡äº†èƒ½æ•ˆå’Œæ—¶é—´å¤„ç†èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
        </div>

        <div class="footer">
            <p>ç”Ÿæˆæ—¶é—´: 2025-11-05 17:25:59</p>
            <p>æ•°æ®æ¥æº: arXiv AI è®ºæ–‡æ¨èç³»ç»Ÿ</p>
        </div>
    </div>
</body>
</html>
