<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¸­è§‚èšç±»åˆ†æ - 2025-10-29</title>
    <style>
        body {
            font-family: 'åœ†ä½“-ç®€', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #ffa500;
            margin: 0;
            font-size: 28px;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 6px;
        }
        .nav-links a {
            color: #007bff;
            text-decoration: none;
            margin-right: 15px;
            font-size: 14px;
        }
        .nav-links a:hover {
            text-decoration: underline;
        }
        .content-section {
            background-color: #fff9e6;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #ffa500;
        }
        .cluster-item {
            margin: 20px 0;
            padding: 20px;
            background-color: white;
            border-radius: 6px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .cluster-item h3 {
            color: #2c3e50;
            margin-top: 0;
            font-size: 18px;
            border-bottom: 2px solid #ffa500;
            padding-bottom: 10px;
        }
        .cluster-item ul {
            margin: 15px 0;
            padding-left: 20px;
        }
        .cluster-item li {
            margin: 12px 0;
            line-height: 1.6;
        }
        .cluster-item strong {
            color: #2c3e50;
            display: block;
            margin-bottom: 5px;
        }
        .cluster-item .contribution {
            color: #666;
            font-size: 14px;
        }
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ä¸­è§‚èšç±»åˆ†æ</h1>
            <div class="date">2025-10-29</div>
        </div>

        <div class="nav-links">
            <a href="index.html">â† è¿”å›æ¯æ—¥ç®€æŠ¥</a>
            <a href="../../index.html">è¿”å›æ±‡æ€»é¡µ</a>
        </div>

        <div class="content-section">
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 1: å¤šæ¨¡æ€å­¦ä¹ ä¸è§†è§‰ç†è§£</h3>
                <ul>
                    
                    <li>
                        <strong>Finding Culture-Sensitive Neurons in Vision-Language Models</strong>
                        <span class="contribution">ç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹ä¸­å¯¹æ–‡åŒ–ä¿¡æ¯æ•æ„Ÿçš„ç¥ç»å…ƒï¼Œä»¥ç†è§£å…¶åœ¨å¤„ç†æ–‡åŒ–èƒŒæ™¯è¾“å…¥æ—¶çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å›¾åŸºä¼ªæ ‡è®°æ¡†æ¶ï¼Œä»¥æé«˜åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­ç”Ÿæˆé«˜è´¨é‡ç¤ºä¾‹çš„æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Rethinking Visual Intelligence: Insights from Video Pretraining</strong>
                        <span class="contribution">æ¢è®¨äº†è§†é¢‘é¢„è®­ç»ƒå¯¹è§†è§‰æ™ºèƒ½çš„å½±å“ï¼Œå¹¶æå‡ºæ”¹è¿›è§†è§‰é¢†åŸŸæ¨¡å‹çš„æ–¹æ³•ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model</strong>
                        <span class="contribution">æå‡ºäº†ViPERæ¡†æ¶ï¼Œä»¥å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„ç»†ç²’åº¦è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>DualCap: Enhancing Lightweight Image Captioning via Dual Retrieval with Similar Scenes Visual Prompts</strong>
                        <span class="contribution">æå‡ºDualCapæ¨¡å‹ï¼Œé€šè¿‡åŒé‡æ£€ç´¢å¢å¼ºè½»é‡çº§å›¾åƒæè¿°ï¼Œç¼©å°è¯­ä¹‰å·®è·ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>BLM_1: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§æ— ç•Œå¤§å‹æ¨¡å‹ï¼Œæ—¨åœ¨è·¨ç©ºé—´ã€è·¨ä»»åŠ¡å’Œè·¨ä½“ç°å­¦ä¹ ä¸­æé«˜å¤šæ¨¡æ€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>VC4VG: Optimizing Video Captions for Text-to-Video Generation</strong>
                        <span class="contribution">ç ”ç©¶äº†è§†é¢‘å­—å¹•ä¼˜åŒ–åœ¨æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä¸­çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºç›¸åº”çš„ä¼˜åŒ–ç­–ç•¥ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>What do vision-language models see in the context? Investigating multimodal in-context learning</strong>
                        <span class="contribution">ç³»ç»Ÿç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å…¶æ½œåœ¨çš„å­¦ä¹ æœºåˆ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>V-SAT: Video Subtitle Annotation Tool</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è§†é¢‘å­—å¹•æ³¨é‡Šå·¥å…·ï¼Œä»¥è§£å†³ç°æœ‰å­—å¹•ç”Ÿæˆæ–¹æ³•çš„ä¸è¶³ï¼Œæå‡å­—å¹•çš„å‡†ç¡®æ€§å’Œå¯è®¿é—®æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs</strong>
                        <span class="contribution">å¼•å…¥äº†Latent Sketchpadï¼Œé€šè¿‡è‰å›¾åŒ–è§†è§‰æ€ç»´æ¥ä¿ƒè¿›å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 2: ç‰©ç†ç³»ç»Ÿä¸­çš„æ·±åº¦å­¦ä¹ ä¸é¢„æµ‹</h3>
                <ul>
                    
                    <li>
                        <strong>Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œä»¥æé«˜å¤æ‚ç‰©ç†ç³»ç»Ÿçš„æ—¶ç©ºé¢„æµ‹å‡†ç¡®æ€§å’Œé•¿æœŸæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning</strong>
                        <span class="contribution">ä»‹ç»äº†æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰ï¼Œé€šè¿‡è·³è·ƒè¿æ¥è§£å†³äº†è®­ç»ƒéå¸¸æ·±çš„å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation</strong>
                        <span class="contribution">æ¢è®¨äº†ç»Ÿè®¡ç‰©ç†åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œåˆ†æäº†å¤šå±‚æ„ŸçŸ¥å™¨çš„æœ€ä¼˜å­¦ä¹ èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation</strong>
                        <span class="contribution">æå‡ºäº†SPARKæ–¹æ³•ï¼Œé€šè¿‡ç‰©ç†å¼•å¯¼çš„å®šé‡å¢å¼ºæ¥è§£å†³åŠ¨æ€ç³»ç»Ÿå»ºæ¨¡ä¸­çš„æ•°æ®ç¨€ç¼ºå’Œåˆ†å¸ƒè½¬ç§»é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Identifiable learning of dissipative dynamics</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§æ–¹æ³•æ¥è¯†åˆ«å’Œé‡åŒ–å¤æ‚è€—æ•£ç³»ç»Ÿçš„åŠ¨æ€è¡Œä¸ºï¼Œå¼ºè°ƒèƒ½é‡è€—æ•£å’Œæ—¶é—´ä¸å¯é€†æ€§çš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning</strong>
                        <span class="contribution">è¯æ˜äº†é€šè¿‡ç‰¹å¾å­¦ä¹ å®ç°å¼±åˆ°å¼ºæ³›åŒ–çš„ç†è®ºæ¡†æ¶ï¼Œæ‰©å±•äº†å¯¹è¿™ä¸€ç°è±¡çš„ç†è§£ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Deep Learning-Enhanced Calibration of the Heston Model: A Unified Framework</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ å¢å¼ºHestonæ¨¡å‹çš„æ ¡å‡†è¿‡ç¨‹ï¼Œè§£å†³äº†è®¡ç®—å¤æ‚æ€§å’Œå±€éƒ¨æœ€å°å€¼æ•æ„Ÿæ€§çš„é—®é¢˜ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 3: äººç±»åé¦ˆä¸‹çš„å¼ºåŒ–å­¦ä¹ </h3>
                <ul>
                    
                    <li>
                        <strong>Greedy Sampling Is Provably Efficient for RLHF</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è´ªå©ªé‡‡æ ·æ–¹æ³•ï¼Œè¯æ˜å…¶åœ¨ä½¿ç”¨åå¥½åé¦ˆè¿›è¡Œå¼ºåŒ–å­¦ä¹ æ—¶çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§æ–°çš„å¥–åŠ±å»ºæ¨¡æ–¹æ³•ï¼Œç»“åˆäº†æˆå¯¹å’Œé€ç‚¹ä¿¡å·ï¼Œä»¥é€‚åº”äººç±»åå¥½çš„ä»»åŠ¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Evolving Diagnostic Agents in a Virtual Clinical Environment</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåœ¨è™šæ‹Ÿä¸´åºŠç¯å¢ƒä¸­ä½œä¸ºè¯Šæ–­ä»£ç†è¿›è¡Œå¤šè½®è¯Šæ–­ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§æ–°çš„å¥–åŠ±æ¨¡å‹ï¼Œä¸“æ³¨äºçŸ¥è¯†å¯†é›†å‹å’Œé•¿ç¯‡ä»»åŠ¡çš„è¯„ä¼°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?</strong>
                        <span class="contribution">æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå°†äººç±»è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬æ¢ä¸ºå†…éƒ¨ç¬¦å·è¡¨ç¤ºã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Reinforcement Learning for Long-Horizon Multi-Turn Search Agents</strong>
                        <span class="contribution">å±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ å¦‚ä½•æå‡å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šè½®æœç´¢ä¸­ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 4: å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰ç¼“è§£</h3>
                <ul>
                    
                    <li>
                        <strong>Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems</strong>
                        <span class="contribution">ç»¼è¿°äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ç¼“è§£å¹»è§‰çš„ä¸åŒç­–ç•¥ï¼Œç‰¹åˆ«å¼ºè°ƒäº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œæ¨ç†å¢å¼ºçš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ¡†æ¶å’ŒåŸºå‡†ï¼Œä»¥æ­ç¤ºå¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¿»è¯‘ä»»åŠ¡ä¸­çš„å¹»è§‰ç°è±¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§åŸºäºå…ƒåˆ†æçš„è¯æ®é‡æ’åºæ–¹æ³•ï¼Œä»¥æé«˜åœ¨è¯æ®åŸºç¡€åŒ»å­¦ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆçš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºPICOçš„æŸ¥è¯¢é‡å†™æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–åœ¨è¯æ®åŸºç¡€åŒ»å­¦ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆè¿‡ç¨‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŸºäºå¼‚è´¨æ€§çš„æ¡†æ¶ï¼Œç”¨äºåœ¨åŒ»ç–—æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿä¸­è¿›è¡Œå¤šè¯æ®éªŒè¯ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 5: å› æœæ¨æ–­ä¸åŠ¨æ€ç³»ç»Ÿåˆ†æ</h3>
                <ul>
                    
                    <li>
                        <strong>Cyclic Counterfactuals under Shift-Scale Interventions</strong>
                        <span class="contribution">æ¢è®¨äº†åœ¨å…·æœ‰åé¦ˆå¾ªç¯çš„ç³»ç»Ÿä¸­è¿›è¡Œåäº‹å®æ¨æ–­çš„æ–°æ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Causal Ordering for Structure Learning From Time Series</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æ¨æ–­å› æœç»“æ„çš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†ç»„åˆå¤æ‚æ€§é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŠ¨æ€è·¯å¾„è½¨è¿¹å­¦ä¹ æ–¹æ³•ï¼Œä»¥åˆ†æå¤§è„‘åŠŸèƒ½ç½‘ç»œçš„æ—¶é—´æ¼”å˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Graph Distance Based on Cause-Effect Estimands with Latents</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºå› æœæ•ˆåº”ä¼°è®¡çš„å›¾è·ç¦»åº¦é‡æ–¹æ³•ï¼Œä»¥è¯„ä¼°å› æœå‘ç°çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 6: AIä¸äººç±»è®¤çŸ¥çš„äº¤äº’</h3>
                <ul>
                    
                    <li>
                        <strong>Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems</strong>
                        <span class="contribution">è¯¥ç ”ç©¶å®éªŒæ€§åœ°æµ‹è¯•äº†çŸ­æœŸæ¥è§¦ç‹­ä¹‰AIå·¥å…·æ˜¯å¦æå‡æ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼Œæˆ–ä»…ä»…æé«˜æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems</strong>
                        <span class="contribution">æå‡ºäº†å™äº‹è¿ç»­æ€§æµ‹è¯•ï¼ˆNCTï¼‰ï¼Œä¸ºè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„AIç³»ç»Ÿåœ¨ç”Ÿæˆå†…å®¹æ—¶çš„èº«ä»½æŒç»­æ€§æä¾›äº†æ¦‚å¿µæ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>A Unified Geometric Space Bridging AI Models and the Human Brain</strong>
                        <span class="contribution">æ¢è®¨äº†ç°ä»£äººå·¥ç¥ç»ç½‘ç»œä¸äººè„‘åœ¨ä¿¡æ¯ç»„ç»‡ä¸Šçš„ç›¸ä¼¼æ€§ï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å‡ ä½•ç©ºé—´æ¥è¿æ¥AIæ¨¡å‹ä¸äººç±»å¤§è„‘ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model</strong>
                        <span class="contribution">é€šè¿‡çµæ„Ÿæ¥è‡ªæµ·é©¬ä½“çš„æ¨¡å‹ï¼Œåˆ©ç”¨ä¸‰ç»´LiDARæŠ€æœ¯æé«˜äº†æœºå™¨äººå®šä½çš„å‡†ç¡®æ€§ï¼Œç‰¹åˆ«æ˜¯è¾¹ç•Œå‘é‡ç»†èƒçš„åº”ç”¨ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 7: å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä¸æ•°æ®æŒ‘æˆ˜</h3>
                <ul>
                    
                    <li>
                        <strong>Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices</strong>
                        <span class="contribution">æä¾›äº†ä¸€ä¸ªå…³äºéè‹±è¯­è¯­è¨€å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°çš„æ–°åˆ†ç±»æ³•å’Œæœ€ä½³å®è·µçš„æ¦‚è¿°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs</strong>
                        <span class="contribution">æ¢è®¨äº†ä»…ä½¿ç”¨è‹±è¯­æ•°æ®è¿›è¡Œå¤šè¯­è¨€çŸ¥è¯†æ¶ˆé™¤çš„é£é™©ï¼Œå¹¶æå‡ºäº†è¯„ä¼°çš„è§†è§’ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Relative Scaling Laws for LLMs</strong>
                        <span class="contribution">å¼•å…¥äº†ç›¸å¯¹ç¼©æ”¾æ³•åˆ™ï¼Œæ­ç¤ºäº†åœ¨ä¸åŒå­ç¾¤ä½“ä¸­å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½å·®å¼‚çš„å½±å“ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ä¸ªæ–°çš„å¢æ£®å ¡è¯­æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œä»¥è§£å†³ä½èµ„æºè¯­è¨€ç¯å¢ƒä¸­çš„è®­ç»ƒæ•°æ®ä¸è¶³é—®é¢˜ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 8: ICUä¸­çš„æœºå™¨å­¦ä¹ ä¸é¢„æµ‹æ¨¡å‹</h3>
                <ul>
                    
                    <li>
                        <strong>Closing Gaps: An Imputation Analysis of ICU Vital Signs</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ•°æ®æ’è¡¥åˆ†ææ–¹æ³•ï¼Œä»¥æé«˜ICUç”Ÿå‘½ä½“å¾æ•°æ®çš„è´¨é‡ï¼Œä»è€Œå¢å¼ºä¸´åºŠé¢„æµ‹æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU</strong>
                        <span class="contribution">å¼•å…¥äº†MIMIC-Sepsisæ•°æ®é›†ï¼Œä½œä¸ºä¸€ä¸ªç»è¿‡æ•´ç†çš„åŸºå‡†æ¡†æ¶ï¼Œä»¥æ”¯æŒå¯¹ICUä¸­è„“æ¯’ç—‡è½¨è¿¹çš„å»ºæ¨¡å’Œå­¦ä¹ ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Filtering instances and rejecting predictions to obtain reliable models in healthcare</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤æ­¥æ•°æ®ä¸­å¿ƒæ–¹æ³•ï¼Œé€šè¿‡è¿‡æ»¤å®ä¾‹å’Œæ‹’ç»ä½ç½®ä¿¡åº¦é¢„æµ‹ï¼Œä»¥æé«˜åŒ»ç–—é¢†åŸŸæœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯é æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Towards actionable hypotension prediction -- predicting catecholamine therapy initiation in the intensive care unit</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§é¢„æµ‹å±é‡ç—…äººä½è¡€å‹å¹¶å¯åŠ¨å„¿èŒ¶é…šèƒºæ²»ç–—çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä»¥ä¼˜åŒ–ä¸´åºŠç®¡ç†å†³ç­–ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 9: è‡ªåŠ¨é©¾é©¶ä¸­çš„å¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–</h3>
                <ul>
                    
                    <li>
                        <strong>SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è½»é‡çº§æ¡†æ¶SCOUTï¼Œç”¨äºåœ¨è‡ªåŠ¨é©¾é©¶ä¸­è¯„ä¼°åœºæ™¯è¦†ç›–ç‡ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„é«˜æˆæœ¬å’Œä½æ•ˆç‡é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§ç³»ç»Ÿæ¡†æ¶ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šçš„æç¤ºå’Œç©ºé—´æ¨ç†å¢å¼ºè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ç†è§£ä¸­çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space</strong>
                        <span class="contribution">æå‡ºäº†SPARTAæ–¹æ³•ï¼Œé€šè¿‡é»‘ç®±å¯¹æŠ—æ€§æ”¹å†™è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†åˆ†å‰²ä»»åŠ¡ä¸­çš„é²æ£’æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 10: è„‰å†²ç¥ç»ç½‘ç»œä¸­çš„èƒ½æ•ˆä¸å­¦ä¹ æœºåˆ¶</h3>
                <ul>
                    
                    <li>
                        <strong>Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºç”µå‹ä¾èµ–æ€§çªè§¦å¯å¡‘æ€§çš„æ— ç›‘ç£å±€éƒ¨å­¦ä¹ æœºåˆ¶ï¼Œä»¥æé«˜è¾¹ç¼˜è®¡ç®—è®¾å¤‡çš„èƒ½æ•ˆå’ŒåŠŸèƒ½æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>All in one timestep: Enhancing Sparsity and Energy efficiency in Multi-level Spiking Neural Networks</strong>
                        <span class="contribution">é€šè¿‡å¤šçº§è„‰å†²ç¥ç»ç½‘ç»œçš„æ—¶é—´æ­¥é•¿ä¼˜åŒ–ï¼Œå¢å¼ºäº†ç¨€ç–æ€§å’Œèƒ½æ•ˆï¼Œæ¨åŠ¨äº†ç”Ÿç‰©å¯å‘æ¨¡å‹çš„åº”ç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ›¿ä»£æ¢¯åº¦æ–¹æ³•ï¼Œæå‡äº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨é¡ºåºå¼ºåŒ–å­¦ä¹ ä¸­çš„è¡¨ç°ï¼Œé€‚åº”èƒ½é‡å—é™çš„æœºå™¨äººç³»ç»Ÿã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
        </div>

        <div class="footer">
            <p>ç”Ÿæˆæ—¶é—´: 2025-11-03 21:13:22</p>
            <p>æ•°æ®æ¥æº: arXiv AI è®ºæ–‡æ¨èç³»ç»Ÿ</p>
        </div>
    </div>
</body>
</html>
