<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¸­è§‚èšç±»åˆ†æ - 2025-10-29</title>
    <style>
        body {
            font-family: 'åœ†ä½“-ç®€', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #ffa500;
            margin: 0;
            font-size: 28px;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 6px;
        }
        .nav-links a {
            color: #007bff;
            text-decoration: none;
            margin-right: 15px;
            font-size: 14px;
        }
        .nav-links a:hover {
            text-decoration: underline;
        }
        .content-section {
            background-color: #fff9e6;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #ffa500;
        }
        .cluster-item {
            margin: 20px 0;
            padding: 20px;
            background-color: white;
            border-radius: 6px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .cluster-item h3 {
            color: #2c3e50;
            margin-top: 0;
            font-size: 18px;
            border-bottom: 2px solid #ffa500;
            padding-bottom: 10px;
        }
        .cluster-item ul {
            margin: 15px 0;
            padding-left: 20px;
        }
        .cluster-item li {
            margin: 12px 0;
            line-height: 1.6;
        }
        .cluster-item strong {
            color: #2c3e50;
            display: block;
            margin-bottom: 5px;
        }
        .cluster-item .contribution {
            color: #666;
            font-size: 14px;
        }
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ä¸­è§‚èšç±»åˆ†æ</h1>
            <div class="date">2025-10-29</div>
        </div>

        <div class="nav-links">
            <a href="index.html">â† è¿”å›æ¯æ—¥ç®€æŠ¥</a>
            <a href="../../index.html">è¿”å›æ±‡æ€»é¡µ</a>
        </div>

        <div class="content-section">
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 1: å¤šæ¨¡æ€å­¦ä¹ ä¸è§†è§‰ç†è§£</h3>
                <ul>
                    
                    <li>
                        <strong>Finding Culture-Sensitive Neurons in Vision-Language Models</strong>
                        <span class="contribution">ç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹ä¸­å¯¹æ–‡åŒ–æ•æ„Ÿè¾“å…¥çš„ç¥ç»å…ƒæ¿€æ´»ï¼Œæ­ç¤ºäº†æ–‡åŒ–èƒŒæ™¯å¯¹æ¨¡å‹å¤„ç†èƒ½åŠ›çš„å½±å“ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å›¾åŸºä¼ªæ ‡è®°æ¡†æ¶ï¼Œä»¥æé«˜åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­ç”Ÿæˆé«˜è´¨é‡ç¤ºä¾‹çš„æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Rethinking Visual Intelligence: Insights from Video Pretraining</strong>
                        <span class="contribution">æ¢è®¨äº†è§†é¢‘é¢„è®­ç»ƒå¯¹è§†è§‰æ™ºèƒ½çš„å½±å“ï¼Œå¼ºè°ƒäº†åœ¨è§†è§‰é¢†åŸŸå¤§è§„æ¨¡é¢„è®­ç»ƒçš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model</strong>
                        <span class="contribution">æå‡ºViPERæ–¹æ³•ï¼Œæ—¨åœ¨å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„ç»†ç²’åº¦è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>DualCap: Enhancing Lightweight Image Captioning via Dual Retrieval with Similar Scenes Visual Prompts</strong>
                        <span class="contribution">æå‡ºDualCapæ¨¡å‹ï¼Œé€šè¿‡åŒé‡æ£€ç´¢å¢å¼ºè½»é‡çº§å›¾åƒæè¿°ï¼Œç¼©å°è¯­ä¹‰å·®è·ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§è·¨ç©ºé—´ã€è·¨ä»»åŠ¡å’Œè·¨ä½“ç°å­¦ä¹ çš„æ— ç•Œå¤§å‹æ¨¡å‹ï¼Œè§£å†³äº†å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æ³›åŒ–é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>VC4VG: Optimizing Video Captions for Text-to-Video Generation</strong>
                        <span class="contribution">æ¢è®¨äº†ä¼˜åŒ–è§†é¢‘å­—å¹•ä»¥æé«˜æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>What do vision-language models see in the context? Investigating multimodal in-context learning</strong>
                        <span class="contribution">ç³»ç»Ÿç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>V-SAT: Video Subtitle Annotation Tool</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è§†é¢‘å­—å¹•æ³¨é‡Šå·¥å…·ï¼Œæ—¨åœ¨æé«˜æµåª’ä½“å†…å®¹çš„å­—å¹•ç”Ÿæˆå‡†ç¡®æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs</strong>
                        <span class="contribution">å¼•å…¥Latent Sketchpadï¼Œé€šè¿‡è‰å›¾åŒ–è§†è§‰æ€ç»´ä¿ƒè¿›å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›çš„æå‡ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 2: æ·±åº¦å­¦ä¹ ä¸ç‰©ç†ç³»ç»Ÿå»ºæ¨¡</h3>
                <ul>
                    
                    <li>
                        <strong>Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œä»¥æé«˜å¤æ‚ç‰©ç†ç³»ç»Ÿçš„æ—¶ç©ºé¢„æµ‹å‡†ç¡®æ€§å’Œé•¿æœŸé¢„æµ‹èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning</strong>
                        <span class="contribution">ä»‹ç»äº†æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰ï¼Œé€šè¿‡è·³è·ƒè¿æ¥è§£å†³äº†è®­ç»ƒæ·±å±‚å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation</strong>
                        <span class="contribution">åˆ©ç”¨ç»Ÿè®¡ç‰©ç†æ¡†æ¶åˆ†æå¤šå±‚æ„ŸçŸ¥å™¨çš„å­¦ä¹ èƒ½åŠ›ï¼Œæ¢è®¨å…¶åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation</strong>
                        <span class="contribution">æå‡ºSPARKæ–¹æ³•ï¼Œé€šè¿‡ç‰©ç†å¼•å¯¼çš„æ•°æ®å¢å¼ºè§£å†³åŠ¨æ€ç³»ç»Ÿå»ºæ¨¡ä¸­çš„åˆ†å¸ƒè½¬ç§»é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Identifiable learning of dissipative dynamics</strong>
                        <span class="contribution">ç ”ç©¶å¤æ‚è€—æ•£ç³»ç»Ÿçš„å­¦ä¹ ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥é‡åŒ–å…¶è¡Œä¸ºå¹¶æé«˜å­¦ä¹ å‡†ç¡®æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning</strong>
                        <span class="contribution">æ¢è®¨äº†å¼±åˆ°å¼ºæ³›åŒ–ç°è±¡ï¼Œæä¾›äº†ç†è®ºè¯æ˜ï¼Œæ­ç¤ºäº†ç‰¹å¾å­¦ä¹ åœ¨æ¨¡å‹æ€§èƒ½æå‡ä¸­çš„ä½œç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Deep Learning-Enhanced Calibration of the Heston Model: A Unified Framework</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ å¢å¼ºHestonæ¨¡å‹çš„æ ¡å‡†è¿‡ç¨‹ï¼Œé™ä½è®¡ç®—å¤æ‚æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 3: äººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ </h3>
                <ul>
                    
                    <li>
                        <strong>Greedy Sampling Is Provably Efficient for RLHF</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç†è®ºæ¡†æ¶ï¼Œè¯æ˜è´ªå©ªé‡‡æ ·åœ¨å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆï¼ˆRLHFï¼‰ä¸­çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åå¥½æ„ŸçŸ¥çš„ä»»åŠ¡è‡ªé€‚åº”å¥–åŠ±å»ºæ¨¡æ–¹æ³•ï¼Œå¢å¼ºäº†ç”Ÿæˆå¥–åŠ±æ¨¡å‹çš„è§£é‡Šæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Evolving Diagnostic Agents in a Virtual Clinical Environment</strong>
                        <span class="contribution">å±•ç¤ºäº†å¦‚ä½•é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯Šæ–­ä»£ç†ï¼Œä»¥é€‚åº”å¤šè½®è¯Šæ–­è¿‡ç¨‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„å¥–åŠ±æ¨¡å‹ï¼Œæ—¨åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹å’Œé•¿ç¯‡ä»»åŠ¡çš„è¯„ä¼°é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?</strong>
                        <span class="contribution">æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå°†äººç±»è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬åŒ–ä¸ºå†…éƒ¨ç¬¦å·è¡¨ç¤ºï¼Œä»¥æ”¯æŒå‘å±•å­¦ä¹ ä»£ç†çš„èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Reinforcement Learning for Long-Horizon Multi-Turn Search Agents</strong>
                        <span class="contribution">è¯æ˜äº†å¼ºåŒ–å­¦ä¹ å¯ä»¥é€šè¿‡ç»éªŒå­¦ä¹ æ˜¾è‘—æå‡å¤šè½®æœç´¢ä»£ç†çš„èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 4: å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰</h3>
                <ul>
                    
                    <li>
                        <strong>Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems</strong>
                        <span class="contribution">ç»¼è¿°äº†å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹å¹»è§‰çš„å¤šç§ç­–ç•¥ï¼Œé‡ç‚¹å…³æ³¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œæ¨ç†å¢å¼ºçš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ¡†æ¶å’ŒåŸºå‡†ï¼Œä»¥æ­ç¤ºå¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¿»è¯‘ä¸­çš„å¹»è§‰é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§åŸºäºå…ƒåˆ†æçš„è¯æ®é‡æ–°æ’åºæ–¹æ³•ï¼Œä»¥æé«˜åœ¨å¾ªè¯åŒ»å­¦ä¸­ä½¿ç”¨RAGçš„æ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºPICOçš„æŸ¥è¯¢é‡å†™æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–å¾ªè¯åŒ»å­¦ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆè¿‡ç¨‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems</strong>
                        <span class="contribution">å»ºç«‹äº†ä¸€ä¸ªåŸºäºå¼‚è´¨æ€§çš„æ¡†æ¶ï¼Œç”¨äºåœ¨åŒ»ç–—RAGç³»ç»Ÿä¸­è¿›è¡Œå¤šè¯æ®éªŒè¯ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 5: å› æœæ¨æ–­ä¸åŠ¨æ€ç½‘ç»œåˆ†æ</h3>
                <ul>
                    
                    <li>
                        <strong>Cyclic Counterfactuals under Shift-Scale Interventions</strong>
                        <span class="contribution">æ¢è®¨äº†åœ¨å­˜åœ¨åé¦ˆå¾ªç¯çš„æƒ…å†µä¸‹è¿›è¡Œåäº‹å®æ¨æ–­çš„æ–°æ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Causal Ordering for Structure Learning From Time Series</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æ¨æ–­å› æœç»“æ„ï¼Œè§£å†³äº†ç»„åˆå¤æ‚æ€§é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŠ¨æ€è·¯å¾„è½¨è¿¹å­¦ä¹ æ–¹æ³•ï¼Œä»¥åˆ†æå¤§è„‘åŠŸèƒ½è¿æ¥çš„æ—¶é—´æ¼”å˜ç‰¹å¾ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Graph Distance Based on Cause-Effect Estimands with Latents</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºå› æœä¼°è®¡é‡çš„æ–°å›¾è·ç¦»åº¦é‡æ–¹æ³•ï¼Œä»¥è¯„ä¼°å› æœå‘ç°çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 6: AIä¸äººç±»è®¤çŸ¥çš„äº¤äº’</h3>
                <ul>
                    
                    <li>
                        <strong>Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems</strong>
                        <span class="contribution">è¯¥ç ”ç©¶å®éªŒæ€§åœ°æµ‹è¯•äº†çŸ­æœŸæ¥è§¦ç‹­ä¹‰AIå·¥å…·æ˜¯å¦å¢å¼ºæ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼Œæˆ–ä»…ä»…æé«˜æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems</strong>
                        <span class="contribution">æœ¬æ–‡æå‡ºäº†å™äº‹è¿ç»­æ€§æµ‹è¯•ï¼ˆNCTï¼‰ï¼Œä¸ºè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„AIç³»ç»Ÿçš„èº«ä»½æŒç»­æ€§æä¾›äº†ä¸€ä¸ªæ¦‚å¿µæ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>A Unified Geometric Space Bridging AI Models and the Human Brain</strong>
                        <span class="contribution">æœ¬ç ”ç©¶æ¢è®¨äº†ç°ä»£äººå·¥ç¥ç»ç½‘ç»œä¸äººè„‘ä¹‹é—´çš„ä¿¡æ¯ç»„ç»‡æ–¹å¼ï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å‡ ä½•ç©ºé—´ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model</strong>
                        <span class="contribution">è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ç§å—æµ·é©¬ä½“å¯å‘çš„æ¨¡å‹ï¼Œé€šè¿‡3D LiDARæŠ€æœ¯æé«˜äº†æœºå™¨äººå®šä½çš„å‡†ç¡®æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 7: å¤šè¯­è¨€LLMè¯„ä¼°ä¸æ•°æ®é›†</h3>
                <ul>
                    
                    <li>
                        <strong>Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices</strong>
                        <span class="contribution">æä¾›äº†ä¸€ä¸ªå…³äºéè‹±è¯­è¯­è¨€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯„ä¼°çš„æ–°åˆ†ç±»æ³•å’Œæœ€ä½³å®è·µçš„æ¦‚è¿°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs</strong>
                        <span class="contribution">æ¢è®¨äº†åœ¨å¤šè¯­è¨€LLMä¸­ä»…ä½¿ç”¨è‹±è¯­æ•°æ®è¿›è¡ŒçŸ¥è¯†æ¶ˆé™¤çš„æ½œåœ¨é£é™©ï¼Œå¼ºè°ƒäº†è¯„ä¼°è§†è§’çš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Relative Scaling Laws for LLMs</strong>
                        <span class="contribution">å¼•å…¥äº†ç›¸å¯¹ç¼©æ”¾æ³•åˆ™ï¼Œæ­ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨ä¸åŒå­ç¾¤ä½“ä¸­çš„æ€§èƒ½å·®å¼‚ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„èšåˆè¯„ä¼°æ–¹æ³•ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data</strong>
                        <span class="contribution">å¼€å‘äº†LuxITï¼Œä¸€ä¸ªé’ˆå¯¹å¢æ£®å ¡è¯­çš„å•è¯­æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼Œä»¥åº”å¯¹ä½èµ„æºè¯­è¨€ç¯å¢ƒä¸­çš„æ•°æ®ä¸è¶³é—®é¢˜ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 8: ICUä¸­çš„æœºå™¨å­¦ä¹ ä¸ä¸´åºŠé¢„æµ‹</h3>
                <ul>
                    
                    <li>
                        <strong>Closing Gaps: An Imputation Analysis of ICU Vital Signs</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ•°æ®æ’è¡¥åˆ†ææ–¹æ³•ï¼Œä»¥æé«˜ICUç”Ÿå‘½ä½“å¾æ•°æ®çš„è´¨é‡ï¼Œä»è€Œæ”¹å–„ä¸´åºŠé¢„æµ‹æ¨¡å‹çš„æ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU</strong>
                        <span class="contribution">ä»‹ç»äº†MIMIC-Sepsisï¼Œä¸€ä¸ªç»è¿‡æ•´ç†çš„åŸºå‡†æ¡†æ¶ï¼Œç”¨äºå»ºæ¨¡å’Œå­¦ä¹ ICUä¸­è„“æ¯’ç—‡çš„è½¨è¿¹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Filtering instances and rejecting predictions to obtain reliable models in healthcare</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤æ­¥æ•°æ®ä¸­å¿ƒæ–¹æ³•ï¼Œé€šè¿‡è¿‡æ»¤å®ä¾‹å’Œæ‹’ç»ä½ç½®ä¿¡åº¦é¢„æµ‹æ¥æé«˜åŒ»ç–—ä¿å¥ä¸­çš„æ¨¡å‹å¯é æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Towards actionable hypotension prediction -- predicting catecholamine therapy initiation in the intensive care unit</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§é¢„æµ‹å±é‡ç—…äººä½è¡€å‹å¹¶å¯åŠ¨å„¿èŒ¶é…šèƒºæ²»ç–—çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜ä¸´åºŠå¹²é¢„çš„åŠæ—¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 9: è‡ªåŠ¨é©¾é©¶ä¸­çš„å¤šæ¨¡æ€ç†è§£ä¸è¯„ä¼°</h3>
                <ul>
                    
                    <li>
                        <strong>SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è½»é‡çº§æ¡†æ¶SCOUTï¼Œç”¨äºåœ¨è‡ªåŠ¨é©¾é©¶ä¸­è¯„ä¼°åœºæ™¯è¦†ç›–ç‡ï¼Œè§£å†³äº†é«˜æˆæœ¬å’Œä½æ•ˆç‡çš„é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§ç³»ç»Ÿæ¡†æ¶ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šçš„æç¤ºå’Œç©ºé—´æ¨ç†æ¥å¢å¼ºè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ç†è§£ä¸­çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space</strong>
                        <span class="contribution">æå‡ºSPARTAæ–¹æ³•ï¼Œé€šè¿‡é»‘ç®±å¯¹æŠ—æ€§æ”¹å†™åœ¨æ–‡æœ¬è‡ªç¼–ç å™¨æ½œåœ¨ç©ºé—´ä¸­è¯„ä¼°æ¨ç†åˆ†å‰²çš„é²æ£’æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 10: åŸºäºè„‰å†²ç¥ç»ç½‘ç»œçš„èƒ½æ•ˆä¼˜åŒ–</h3>
                <ul>
                    
                    <li>
                        <strong>Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºç”µå‹ä¾èµ–æ€§çªè§¦å¯å¡‘æ€§çš„æ— ç›‘ç£å±€éƒ¨å­¦ä¹ æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜è¾¹ç¼˜è®¡ç®—è®¾å¤‡çš„èƒ½æ•ˆå’ŒåŠŸèƒ½æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>All in one timestep: Enhancing Sparsity and Energy efficiency in Multi-level Spiking Neural Networks</strong>
                        <span class="contribution">é€šè¿‡å¤šçº§è„‰å†²ç¥ç»ç½‘ç»œçš„æ—¶é—´æ­¥ä¼˜åŒ–ï¼Œå¢å¼ºäº†ç¨€ç–æ€§å’Œèƒ½æ•ˆï¼Œæ¨åŠ¨äº†ç”Ÿç‰©å¯å‘æ¨¡å‹çš„å‘å±•ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks</strong>
                        <span class="contribution">å¼•å…¥è‡ªé€‚åº”æ›¿ä»£æ¢¯åº¦æ–¹æ³•ï¼Œæå‡äº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨åºåˆ—å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨æ•ˆç‡ï¼Œä¿ƒè¿›äº†èƒ½é‡å—é™æœºå™¨äººæŠ€æœ¯çš„å‘å±•ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
        </div>

        <div class="footer">
            <p>ç”Ÿæˆæ—¶é—´: 2025-11-03 21:23:06</p>
            <p>æ•°æ®æ¥æº: arXiv AI è®ºæ–‡æ¨èç³»ç»Ÿ</p>
        </div>
    </div>
</body>
</html>
