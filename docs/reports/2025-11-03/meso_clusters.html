<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¸»é¢˜èšç±»åˆ†æ - 2025-11-03</title>
    <style>
        body {
            font-family: 'åœ†ä½“-ç®€', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #ffa500;
            margin: 0;
            font-size: 28px;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 6px;
        }
        .nav-links a {
            color: #007bff;
            text-decoration: none;
            margin-right: 15px;
            font-size: 14px;
        }
        .nav-links a:hover {
            text-decoration: underline;
        }
        .macro-summary-section {
            background-color: #f0f7ff;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #007bff;
            margin-bottom: 30px;
        }
        .macro-summary-section h2 {
            color: #007bff;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 20px;
        }
        .macro-summary-content {
            color: #333;
            line-height: 1.8;
        }
        .macro-summary-content h3 {
            color: #2c3e50;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        .macro-summary-content ul, .macro-summary-content ol {
            margin: 10px 0;
            padding-left: 25px;
        }
        .macro-summary-content li {
            margin: 8px 0;
        }
        .content-section {
            background-color: #fff9e6;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #ffa500;
        }
        .cluster-item {
            margin: 20px 0;
            padding: 20px;
            background-color: white;
            border-radius: 6px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .cluster-item h3 {
            color: #2c3e50;
            margin-top: 0;
            font-size: 18px;
            border-bottom: 2px solid #ffa500;
            padding-bottom: 10px;
        }
        .cluster-item ul {
            margin: 15px 0;
            padding-left: 20px;
        }
        .cluster-item li {
            margin: 12px 0;
            line-height: 1.6;
        }
        .cluster-item strong {
            color: #2c3e50;
            display: block;
            margin-bottom: 5px;
        }
        .cluster-item .contribution {
            color: #666;
            font-size: 14px;
        }
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ä¸»é¢˜èšç±»åˆ†æ</h1>
            <div class="date">2025-11-03</div>
        </div>

        <div class="nav-links">
            <a href="index.html">â† è¿”å›æ¯æ—¥ç®€æŠ¥</a>
            <a href="../../index.html">è¿”å›æ±‡æ€»é¡µ</a>
            <a href="../../search.html">ğŸ” æœç´¢å†å²å½’æ¡£</a>
        </div>

        <!-- å®è§‚ç ”ç©¶è¶‹åŠ¿ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ -->
        
        <div class="macro-summary-section">
            <h2>ğŸ“ˆ å®è§‚ç ”ç©¶è¶‹åŠ¿</h2>
            <div class="macro-summary-content">
                <h2>æ ¸å¿ƒç ”ç©¶ä¸»é¢˜</h2>

<ol>
<li>å¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒä¸åº”ç”¨æ­£åœ¨æ¨åŠ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„è¾¹ç•Œï¼Œæå‡äº†æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</li>
<li>åŠ¨æ€ç³»ç»Ÿä¸æ—¶é—´åºåˆ—å»ºæ¨¡çš„ç ”ç©¶ä¸ºå®æ—¶æ•°æ®åˆ†æå’Œé¢„æµ‹æä¾›äº†æ–°çš„æ–¹æ³•ï¼Œå¢å¼ºäº†AIåœ¨é‡‘èå’ŒåŒ»ç–—ç­‰é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚</li>
<li>å¤šä»£ç†åä½œä¸è¯­è¨€æ¨¡å‹çš„ç»“åˆæ­£åœ¨ä¿ƒè¿›æ™ºèƒ½ä½“ä¹‹é—´çš„äº’åŠ¨ä¸åˆä½œï¼Œæå‡äº†å¤æ‚ä»»åŠ¡çš„æ‰§è¡Œæ•ˆç‡ã€‚</li>
<li>ç”µå­å¥åº·è®°å½•ä¸å¯¹è¯ç”Ÿæˆçš„æ•´åˆä½¿å¾—åŒ»ç–—æœåŠ¡æ›´åŠ æ™ºèƒ½åŒ–ï¼Œæé«˜äº†æ‚£è€…ä¸åŒ»ç–—ç³»ç»Ÿä¹‹é—´çš„æ²Ÿé€šæ•ˆç‡ã€‚</li>
<li>è·¨æ–‡åŒ–ç¿»è¯‘ä¸å¤šè¯­è¨€æ¨¡å‹çš„å‘å±•ä¿ƒè¿›äº†å…¨çƒåŒ–äº¤æµï¼Œå¢å¼ºäº†ä¸åŒè¯­è¨€ç”¨æˆ·ä¹‹é—´çš„ç†è§£ä¸äº’åŠ¨ã€‚</li>
</ol>

<h2>æŠ€æœ¯è¶‹åŠ¿</h2>

<ol>
<li>è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹çš„è®¡ç®—æ•ˆç‡å’Œèµ„æºåˆ©ç”¨ç‡æ­£åœ¨ä¸æ–­æå‡ï¼Œæ¨åŠ¨äº†æ›´å¤§è§„æ¨¡å’Œæ›´å¤æ‚æ¨¡å‹çš„å¼€å‘ã€‚</li>
<li>ä¸ªæ€§åŒ–çš„LLMè®­ç»ƒæ­£åœ¨æˆä¸ºä¸»æµï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ç”¨æˆ·çš„ç‰¹å®šéœ€æ±‚å’Œåå¥½ã€‚</li>
<li>è¯­éŸ³å¤„ç†ä¸ç†è§£æŠ€æœ¯çš„è¿›æ­¥æ­£åœ¨æ¨åŠ¨è¯­éŸ³äº¤äº’çš„æ™®åŠï¼Œä½¿å¾—äººæœºäº¤äº’æ›´åŠ è‡ªç„¶å’Œé«˜æ•ˆã€‚</li>
</ol>

            </div>
        </div>
        

        <!-- ä¸»é¢˜èšç±»åˆ†æ -->
        <div class="content-section">
            <h2 style="color: #ffa500; margin-top: 0; margin-bottom: 20px;">ğŸ” ä¸»é¢˜èšç±»åˆ†æ</h2>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 1: å¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆè®­ç»ƒä¸åº”ç”¨</h3>
                <ul>
                    
                    <li>
                        <strong>AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§é€šè¿‡æ³¨æ„åŠ›ç¼“å­˜åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹é¢„å¡«å……é˜¶æ®µæ¨ç†çš„æ–¹æ³•ï¼Œæå‡äº†å®é™…åº”ç”¨çš„æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Revisiting Multilingual Data Mixtures in Language Model Pretraining</strong>
                        <span class="contribution">æ¢è®¨äº†å¤šè¯­è¨€æ•°æ®æ··åˆåœ¨å¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¸­çš„å½±å“ï¼Œåˆ†æäº†è¯­è¨€è¦†ç›–ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„æƒè¡¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation</strong>
                        <span class="contribution">è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©æ³¨é‡Šåœ¨è¯­è¨€èµ„æºåˆ›å»ºä¸­çš„è¡¨ç°å’Œå½±å“ï¼Œå¼ºè°ƒå…¶åœ¨è¯­è¨€å­¦ç ”ç©¶ä¸­çš„æ½œåŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Gaperon: A Peppered English-French Generative Language Model Suite</strong>
                        <span class="contribution">å‘å¸ƒäº†ä¸€ä¸ªå¼€æ”¾çš„æ³•è‹±ç”Ÿæˆè¯­è¨€æ¨¡å‹å¥—ä»¶ï¼Œæ—¨åœ¨æé«˜å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒçš„é€æ˜åº¦å’Œå¯é‡å¤æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>A Survey on Efficient Large Language Model Training: From Data-centric Perspectives</strong>
                        <span class="contribution">ç»¼è¿°äº†å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒçš„é«˜æ•ˆæ€§ï¼Œèšç„¦äºæ•°æ®ä¸­å¿ƒçš„æŒ‘æˆ˜åŠå…¶å¯¹åè®­ç»ƒè¿‡ç¨‹çš„å½±å“ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Serve Programs, Not Prompts</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„å¤§è¯­è¨€æ¨¡å‹æœåŠ¡æ¶æ„ï¼Œæ—¨åœ¨é€šè¿‡æœåŠ¡ç¨‹åºè€Œéæç¤ºæ¥æé«˜ç³»ç»Ÿçš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Adapting Small Language Models to Low-Resource Domains: A Case Study in Hindi Tourism QA</strong>
                        <span class="contribution">å±•ç¤ºäº†ä¸€ç§å¤šé˜¶æ®µå¾®è°ƒç­–ç•¥ï¼Œä»¥é€‚åº”ä½èµ„æºè¯­è¨€é¢†åŸŸçš„è½»é‡çº§è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨å°åœ°è¯­æ—…æ¸¸é—®ç­”ä¸­çš„åº”ç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data</strong>
                        <span class="contribution">é‡åŒ–äº†é•¿æ–‡æœ¬æ•°æ®ä¸­é•¿è·ç¦»ä¿¡æ¯çš„æœ‰æ•ˆæ€§ï¼Œå¼ºè°ƒäº†åœ¨é•¿ä¸Šä¸‹æ–‡é¢„è®­ç»ƒä¸­çš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Testing Cross-Lingual Text Comprehension In LLMs Using Next Sentence Prediction</strong>
                        <span class="contribution">é€šè¿‡ä¸‹ä¸€å¥é¢„æµ‹æµ‹è¯•äº†å¤§è¯­è¨€æ¨¡å‹åœ¨è·¨è¯­è¨€æ–‡æœ¬ç†è§£ä¸­çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½èµ„æºè¯­è¨€ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Pretraining Strategies using Monolingual and Parallel Data for Low-Resource Machine Translation</strong>
                        <span class="contribution">ç ”ç©¶äº†é’ˆå¯¹ä½èµ„æºè¯­è¨€çš„æœºå™¨ç¿»è¯‘æ¨¡å‹çš„ä¸åŒé¢„è®­ç»ƒç­–ç•¥ï¼Œæä¾›äº†å¤šç§è¯­è¨€çš„æ¯”è¾ƒåˆ†æã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 2: åŠ¨æ€ç³»ç»Ÿä¸æ—¶é—´åºåˆ—å»ºæ¨¡</h3>
                <ul>
                    
                    <li>
                        <strong>InputDSA: Demixing then Comparing Recurrent and Externally Driven Dynamics</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥æ¯”è¾ƒç¥ç»ç³»ç»Ÿçš„åŠ¨æ€è¡Œä¸ºï¼Œä»è€Œæ­ç¤ºå¤§è„‘å’Œæ·±åº¦ç¥ç»ç½‘ç»œä¸­çš„æ–°å…´è®¡ç®—ç‰¹æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Neural Stochastic Flows: Solver-Free Modelling and Inference for SDE Solutions</strong>
                        <span class="contribution">å¼•å…¥äº†ç¥ç»éšæœºæµï¼ˆNSFsï¼‰ï¼Œæä¾›äº†ä¸€ç§æ— éœ€æ•°å€¼æ±‚è§£å™¨çš„éšæœºå¾®åˆ†æ–¹ç¨‹å»ºæ¨¡å’Œæ¨æ–­æ–¹æ³•ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Convolutional Spiking-based GRU Cell for Spatio-temporal Data</strong>
                        <span class="contribution">ç»“åˆè„‰å†²ç¥ç»ç½‘ç»œå’Œé—¨æ§é€’å½’å•å…ƒï¼Œæå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ä»¥é«˜æ•ˆå¤„ç†æ—¶ç©ºæ•°æ®ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PyDPF: A Python Package for Differentiable Particle Filtering</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ä¸ªPythonåŒ…ï¼Œæ”¯æŒå¯å¾®åˆ†ç²’å­æ»¤æ³¢ï¼Œä¸ºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ—¶é—´åºåˆ—åˆ†ææä¾›äº†æ–°å·¥å…·ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Mechanistic Interpretability of RNNs emulating Hidden Markov Models</strong>
                        <span class="contribution">æ¢è®¨äº†é€’å½’ç¥ç»ç½‘ç»œåœ¨æ¨¡æ‹Ÿéšé©¬å°”å¯å¤«æ¨¡å‹ä¸­çš„æœºåˆ¶è§£é‡Šï¼Œæ­ç¤ºäº†ç¥ç»è®¡ç®—çš„æ½œåœ¨åŠ¨æ€ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 3: å¤šä»£ç†åä½œä¸è¯­è¨€æ¨¡å‹</h3>
                <ul>
                    
                    <li>
                        <strong>Debate2Create: Robot Co-design via Large Language Model Debates</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†è¿›è¡Œç»“æ„åŒ–è¾©è®ºçš„æ¡†æ¶ï¼Œä»¥è‡ªåŠ¨åŒ–æœºå™¨äººå½¢æ€å’Œæ§åˆ¶çš„ååŒè®¾è®¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Completion $
eq$ Collaboration: Scaling Collaborative Effort with Agents</strong>
                        <span class="contribution">ä¸»å¼ ä»å•æ¬¡ä»»åŠ¡å®Œæˆè½¬å‘è¯„ä¼°ä»£ç†çš„è¿­ä»£å’Œåä½œèƒ½åŠ›ï¼Œä»¥æ›´å¥½åœ°é€‚åº”ç°å®ä¸–ç•Œä¸­çš„å¤æ‚é—®é¢˜ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 4: ç”µå­å¥åº·è®°å½•ä¸å¯¹è¯ç”Ÿæˆ</h3>
                <ul>
                    
                    <li>
                        <strong>Beyond Long Context: When Semantics Matter More than Tokens</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ä¸´åºŠå®ä½“å¢å¼ºæ£€ç´¢çš„æ–¹æ³•ï¼Œä»¥æ”¹å–„ç”µå­å¥åº·è®°å½•ä¸­çš„è¯­ä¹‰é—®ç­”èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic Health Record Analysis</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§å¢å¼ºæ¨ç†çš„åŸºç¡€è¯­è¨€æ¨¡å‹ï¼Œä»¥æé«˜ç”µå­å¥åº·è®°å½•çš„è‡ªåŠ¨åˆ†æèƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Roleplaying with Structure: Synthetic Therapist-Client Conversation Generation from Questionnaires</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºç»“æ„åŒ–é—®å·ç”Ÿæˆåˆæˆæ²»ç–—å¸ˆ-å®¢æˆ·å¯¹è¯çš„ç®¡é“ï¼Œæ¨åŠ¨å¿ƒç†å¥åº·é¢†åŸŸçš„AIåº”ç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Medical Records to Diagnostic Dialogues: A Clinical-Grounded Approach and Dataset for Psychiatric Comorbidity</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç»“åˆåˆæˆæ‚£è€…ç”µå­ç—…å†å’Œå¤šæ™ºèƒ½ä½“è¯Šæ–­å¯¹è¯ç”Ÿæˆï¼Œä»¥åº”å¯¹ç²¾ç¥å…±ç—…çš„å¤æ‚æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>GAPMAP: Mapping Scientific Knowledge Gaps in Biomedical Literature Using Large Language Models</strong>
                        <span class="contribution">ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®ä¸­çš„ç ”ç©¶çŸ¥è¯†ç©ºç™½æ–¹é¢çš„èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 5: è¯­éŸ³å¤„ç†ä¸ç†è§£</h3>
                <ul>
                    
                    <li>
                        <strong>Lost in Phonation: Voice Quality Variation as an Evaluation Dimension for Speech Foundation Models</strong>
                        <span class="contribution">æ¢è®¨äº†è¯­éŸ³åŸºç¡€æ¨¡å‹åœ¨å¤„ç†è¯­éŸ³è´¨é‡å˜åŒ–æ—¶çš„è¯„ä¼°ç»´åº¦ï¼Œå¼ºè°ƒäº†å…¶åœ¨ä¸°å¯Œçš„å‰¯è¯­è¨€å˜å¼‚ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>More than a Moment: Towards Coherent Sequences of Audio Descriptions</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œæ—¨åœ¨ç”Ÿæˆè¿è´¯çš„éŸ³é¢‘æè¿°åºåˆ—ï¼Œä»¥å¸®åŠ©è§†éšœè§‚ä¼—æ›´å¥½åœ°ç†è§£è§†é¢‘å†…å®¹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Explainable Disentanglement on Discrete Speech Representations for Noise-Robust ASR</strong>
                        <span class="contribution">ç ”ç©¶äº†ç¦»æ•£éŸ³é¢‘è¡¨ç¤ºåœ¨å™ªå£°ç¯å¢ƒä¸­çš„ä¼˜åŒ–ï¼Œæå‡äº†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Evaluating Emotion Recognition in Spoken Language Models on Emotionally Incongruent Speech</strong>
                        <span class="contribution">è¯„ä¼°äº†æƒ…æ„Ÿè¯†åˆ«åœ¨å£è¯­è¯­è¨€æ¨¡å‹ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨æƒ…æ„Ÿä¸ä¸€è‡´çš„è¯­éŸ³è¾“å…¥ä¸Šçš„æŒ‘æˆ˜ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 6: å·¥å…·ä½¿ç”¨ä¸ä¸ªæ€§åŒ–çš„LLMè®­ç»ƒ</h3>
                <ul>
                    
                    <li>
                        <strong>PORTool: Tool-Use LLM Training with Rewarded Tree</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡å¥–åŠ±æ ‘æ¥å¢å¼ºå·¥å…·ä½¿ç”¨çš„LLMçš„å¤šæ­¥éª¤æ¨ç†èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation</strong>
                        <span class="contribution">å»ºç«‹äº†ä¸€ä¸ªå¤šç»´åŸºå‡†ï¼Œä»¥è¯„ä¼°LLMåœ¨æ¨¡æ‹Ÿä¸ªæ€§å’Œè¡Œä¸ºç‰¹å¾æ–¹é¢çš„èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Grounded in Reality: Learning and Deploying Proactive LLM from Offline Logs</strong>
                        <span class="contribution">æ¢è®¨äº†å¦‚ä½•ä»ç¦»çº¿æ—¥å¿—ä¸­å­¦ä¹ å¹¶éƒ¨ç½²ä¸»åŠ¨å‹LLMï¼Œä»¥æå‡å…¶åœ¨é«˜é£é™©é¢†åŸŸçš„åº”ç”¨èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 7: é«˜æ•ˆæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ</h3>
                <ul>
                    
                    <li>
                        <strong>MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å¤šå¥–åŠ±æ¡ä»¶é¢„è®­ç»ƒæ–¹æ³•ï¼Œä»¥æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„è´¨é‡å’Œæ•ˆç‡ï¼Œè§£å†³ç”¨æˆ·åå¥½çš„å¯¹é½é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation</strong>
                        <span class="contribution">é€šè¿‡åˆ©ç”¨ç©ºé—´ä¸Šä¸‹æ–‡åŠ é€Ÿè‡ªå›å½’å›¾åƒç”Ÿæˆï¼Œæå‡ºäº†ä¸€ç§è½»é‡çº§è‰ç¨¿æ¨¡å‹ä»¥æé«˜æ¨ç†é€Ÿåº¦ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§é«˜æ•ˆä¸”æ¨¡å‹æ— å…³çš„æ‰©æ•£æ–¹æ³•ï¼Œä»¥å…‹æœæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆè¶…å‡ºè®­ç»ƒåˆ†è¾¨ç‡å›¾åƒæ—¶çš„æ€§èƒ½ä¸‹é™ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 8: è·¨æ–‡åŒ–ç¿»è¯‘ä¸å¤šè¯­è¨€æ¨¡å‹</h3>
                <ul>
                    
                    <li>
                        <strong>Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs</strong>
                        <span class="contribution">æå‡ºäº†åœ¨å¤šè¯­è¨€å¤§æ¨¡å‹ä¸­å¹³è¡¡çŸ¥è¯†è½¬ç§»ä¸æ–‡åŒ–ä¿ç•™çš„é‡è¦æ€§ï¼Œå¼ºè°ƒäº†æ–‡åŒ–æŠ¹é™¤çš„æ½œåœ¨é£é™©ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Semantic Label Drift in Cross-Cultural Translation</strong>
                        <span class="contribution">æ¢è®¨äº†æ–‡åŒ–å¯¹æœºå™¨ç¿»è¯‘ä¸­æƒ…æ„Ÿä¿ç•™çš„å½±å“ï¼Œæ­ç¤ºäº†è¯­ä¹‰æ ‡ç­¾æ¼‚ç§»çš„ç°è±¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains</strong>
                        <span class="contribution">æ¨å‡ºäº†BhashaBench V1åŸºå‡†ï¼Œä¸“æ³¨äºå°åº¦ç‰¹å®šé¢†åŸŸçš„è¯„ä¼°ï¼Œå¡«è¡¥äº†ç°æœ‰åŸºå‡†çš„æ–‡åŒ–å’Œé¢†åŸŸç©ºç™½ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 9: LLMsä¸­çš„æ•°æ®ç®¡ç†ä¸è¯„ä¼°</h3>
                <ul>
                    
                    <li>
                        <strong>RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline</strong>
                        <span class="contribution">æå‡ºäº†RECAPï¼Œä¸€ä¸ªä»£ç†ç®¡é“ï¼Œç”¨äºä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æå–å’ŒéªŒè¯ç‰ˆæƒæ•°æ®çš„å†ç°æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework</strong>
                        <span class="contribution">æ¢è®¨äº†é€šè¿‡åˆºæ¿€-çŸ¥è¯†çº ç¼ -è¡Œä¸ºæ¡†æ¶è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ä¸å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>A Survey on Unlearning in Large Language Models</strong>
                        <span class="contribution">å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„ä¸å­¦ä¹ è¿›è¡Œäº†å…¨é¢çš„è°ƒæŸ¥ï¼Œå¼ºè°ƒäº†éšç§å’Œå®‰å…¨é£é™©ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 10: è¯­è¨€ä»£ç†çš„ä»»åŠ¡æ‰§è¡Œä¸è¯„ä¼°</h3>
                <ul>
                    
                    <li>
                        <strong>The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°è¯­è¨€ä»£ç†åœ¨å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡æ‰§è¡Œä¸­çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents</strong>
                        <span class="contribution">å¼•å…¥äº†ä¸€ç§è¿‡ç¨‹çº§è½¨è¿¹è¯„ä¼°æ–¹æ³•ï¼Œä»¥è§£å†³è½¯ä»¶å·¥ç¨‹ä»£ç†ç¯å¢ƒé…ç½®ä¸­çš„ç“¶é¢ˆé—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared Memories</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ å’Œå…±äº«è®°å¿†çš„å•†ä¸šä»£ç†æ¨¡å‹ï¼Œæ—¨åœ¨æé«˜ä¸æ•°æ®åº“å’ŒçŸ¥è¯†åº“çš„äº¤äº’èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
        </div>

        <div class="footer">
            <p>ç”Ÿæˆæ—¶é—´: 2025-11-06 19:32:54</p>
            <p>æ•°æ®æ¥æº: arXiv AI è®ºæ–‡æ¨èç³»ç»Ÿ</p>
        </div>
    </div>
</body>
</html>
