<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Survey on Unlearning in Large Language Models</title>
    <style>
        :root {
            /* 配色方案：Slate + Indigo */
            --primary-color: #4f46e5;
            --bg-body: #f8fafc;
            --bg-paper: #ffffff;
            --text-main: #1e293b;      /* Slate 800 */
            --text-body: #334155;      /* Slate 700 - 正文颜色略浅，减少视觉疲劳 */
            --text-secondary: #64748b; /* Slate 500 */
            --border-color: #e2e8f0;
            --code-bg: #f1f5f9;
            
            /* 警告色 */
            --warn-bg: #fff7ed;
            --warn-text: #9a3412;
            --warn-border: #fdba74;

            --font-stack: '圆体-简', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            --font-mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: var(--font-stack);
            background-color: var(--bg-body);
            color: var(--text-body);
            line-height: 1.8; /* 增加行高，适合阅读 */
            padding: 40px 20px;
            min-height: 100vh;
        }

        /* 阅读容器：限制宽度以提升阅读体验 */
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: var(--bg-paper);
            border-radius: 16px; /* 更圆润的角 */
            padding: 40px 60px; /* 宽敞的内边距 */
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05), 0 2px 4px -1px rgba(0, 0, 0, 0.03);
        }

        /* 顶部导航 */
        .nav-bar {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 1px solid var(--border-color);
            font-size: 14px;
        }

        .nav-link {
            color: var(--text-secondary);
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            transition: color 0.2s;
        }

        .nav-link:hover { color: var(--primary-color); }
        .nav-link::before { content: "←"; margin-right: 5px; }
        
        .arxiv-link {
            background-color: #f1f5f9;
            color: var(--text-main);
            padding: 6px 12px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s;
        }
        
        .arxiv-link:hover {
            background-color: #e2e8f0;
            color: var(--primary-color);
        }

        /* 论文头部信息 */
        .paper-header {
            margin-bottom: 40px;
        }

        .paper-title {
            font-size: 32px;
            font-weight: 700;
            color: var(--text-main);
            line-height: 1.4;
            margin-bottom: 20px;
            letter-spacing: -0.02em;
        }

        /* 标签组 */
        .tags-wrapper {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-bottom: 20px;
        }

        .tag {
            background-color: #e0e7ff; /* Indigo 100 */
            color: #4338ca;            /* Indigo 700 */
            font-size: 12px;
            padding: 4px 10px;
            border-radius: 99px;
            font-weight: 500;
        }

        /* 元数据栏 */
        .metadata-box {
            background-color: #f8fafc;
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 20px;
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            font-size: 14px;
            color: var(--text-secondary);
        }

        .meta-item {
            display: flex;
            flex-direction: column;
            gap: 4px;
        }

        .meta-label {
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: #94a3b8;
        }

        .meta-value {
            font-weight: 600;
            color: var(--text-main);
        }
        
        .score-badge {
            color: var(--primary-color);
        }

        /* 核心图片展示 */
        .core-image-container {
            margin: 40px 0;
            text-align: center;
            background-color: #f8fafc;
            padding: 20px;
            border-radius: 12px;
            border: 1px solid var(--border-color);
        }

        .core-image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        
        .image-caption {
            margin-top: 10px;
            font-size: 13px;
            color: var(--text-secondary);
            font-style: italic;
        }

        /* 警告框 */
        .warning-box {
            background-color: var(--warn-bg);
            border-left: 4px solid var(--warn-border);
            color: var(--warn-text);
            padding: 15px;
            border-radius: 0 6px 6px 0;
            margin: 20px 0;
            font-size: 14px;
        }

        /* 章节标题 */
        .section-header {
            display: flex;
            align-items: center;
            margin-top: 50px;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px dashed var(--border-color);
        }

        .section-header h2 {
            font-size: 24px;
            font-weight: 700;
            color: var(--text-main);
            margin: 0;
            position: relative;
        }
        
        /* 章节前的装饰点 */
        .section-header h2::before {
            content: '';
            display: inline-block;
            width: 8px;
            height: 8px;
            background-color: var(--primary-color);
            border-radius: 50%;
            margin-right: 12px;
            vertical-align: middle;
        }

        /* Markdown 内容样式重置 - 极简学术风 */
        .content-body {
            font-size: 17px; /* 略大的字号适合阅读 */
            color: var(--text-body);
        }

        .content-body p {
            margin-bottom: 1.5em;
            text-align: justify;
        }

        .content-body h3 {
            font-size: 20px;
            font-weight: 600;
            color: var(--text-main);
            margin-top: 2em;
            margin-bottom: 1em;
        }
        
        .content-body h4 {
            font-size: 18px;
            font-weight: 600;
            margin-top: 1.5em;
            margin-bottom: 0.8em;
        }

        .content-body ul, .content-body ol {
            margin-bottom: 1.5em;
            padding-left: 1.5em;
        }

        .content-body li {
            margin-bottom: 0.5em;
        }

        .content-body strong {
            color: var(--text-main);
            font-weight: 600;
        }
        
        /* 引用块 - 学术风 */
        .content-body blockquote {
            border-left: 4px solid var(--primary-color);
            background-color: #f8fafc;
            padding: 16px 20px;
            margin: 20px 0;
            font-style: italic;
            color: var(--text-secondary);
            border-radius: 0 8px 8px 0;
        }

        /* 代码块 */
        .content-body pre {
            background-color: var(--code-bg);
            padding: 16px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            border: 1px solid var(--border-color);
        }

        .content-body code {
            font-family: var(--font-mono);
            background-color: var(--code-bg);
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.9em;
            color: #d63384; /* 类似 GitHub 的代码红 */
        }
        
        .content-body pre code {
            color: inherit;
            padding: 0;
            background-color: transparent;
        }

        /* Footer */
        .footer {
            margin-top: 80px;
            text-align: center;
            color: var(--text-secondary);
            font-size: 13px;
            border-top: 1px solid var(--border-color);
            padding-top: 30px;
        }

        /* 移动端适配 */
        @media (max-width: 768px) {
            body { padding: 0; }
            
            .container {
                border-radius: 0;
                padding: 30px 20px;
                box-shadow: none;
            }

            .paper-title { font-size: 26px; }
            
            .metadata-box {
                flex-direction: column;
                gap: 15px;
            }
            
            .content-body { font-size: 16px; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="nav-bar">
            <a href="index.html" class="nav-link">返回今日简报</a>
            <a href="http://arxiv.org/abs/2510.25117v1" target="_blank" class="arxiv-link">PDF / arXiv ↗</a>
        </div>

        <div class="paper-header">
            <h1 class="paper-title">A Survey on Unlearning in Large Language Models</h1>
            
            
            <div class="tags-wrapper">
                
                <span class="tag">去学习</span>
                
                <span class="tag">大语言模型(LLM)</span>
                
                <span class="tag">知识删除</span>
                
                <span class="tag">模型性能</span>
                
                <span class="tag">安全合规</span>
                
            </div>
            

            <div class="metadata-box">
                
                <div class="meta-item" style="flex: 2; min-width: 200px;">
                    <span class="meta-label">作者单位</span>
                    <span class="meta-value">School of Advanced Interdisciplinary Sciences, UCAS, China, Institute of Computing Technology, CAS, China, University of Chinese Academy of Sciences, China, Academy of Mathematics and Systems Science, CAS, China</span>
                </div>
                
                
                <div class="meta-item">
                    <span class="meta-label">推荐指数</span>
                    <span class="meta-value score-badge">0.473</span>
                </div>
                
                <div class="meta-item">
                    <span class="meta-label">arXiv ID</span>
                    <span class="meta-value">2510.25117v1</span>
                </div>
            </div>

            
        </div>

        
        <div class="core-image-container">
            
            <img src="../../images/2025-11-03/af6434d1cc55541b48f7df1e73ea11553d7222246d09e008f0a968e603aa4506.jpg" alt="核心思路示意图" />
            <div class="image-caption">图 1：论文核心方法/架构示意图</div>
        </div>
        

        <div class="section-header">
            <h2>快速简介</h2>
        </div>
        <div class="content-body">
            <p>本文提出了一种机器去学习技术，以解决大语言模型（LLM）在训练中记忆敏感数据和版权材料的问题。通过分类不同的去学习方法（训练时、后训练、推理时），并建立评估体系，研究提供了有效的知识删除方案，同时确保模型性能不受影响。这项工作为安全、合规的LLM发展提供了系统性指导。</p>
        </div>

        <div class="section-header">
            <h2>深度解读</h2>
        </div>
        <div class="content-body">
            
                <h3>现有问题</h3>

<p>大语言模型（LLM）在训练过程中会记忆大量数据，这引发了严峻的隐私、安全和版权问题。核心挑战在于如何有效地选择性删除模型中的特定信息（如个人敏感数据、受版权保护的材料或有害知识），以满足“被遗忘权”等法律法规要求，同时避免完全重新训练模型所带来的高昂计算成本。现有方法在处理连续的遗忘请求、多语言内容以及平衡“遗忘”效果与保留模型整体性能方面仍面临困难。</p>

<h3>Hypothesis</h3>

<p>核心假设是，可以通过专门设计的“机器去学习”技术，在不完全重新训练模型的情况下，高效、选择性地移除LLM中的特定知识。这些技术能够使修改后的模型在行为上接近于从未学习过目标数据的模型，同时最大限度地保留其原有的通用知识和能力，从而增强模型的安全性、合规性和可控性。</p>

<h3>相关研究</h3>

<p>相关研究涵盖了多种去学习方法，可以从不同维度进行分类：
*   <strong>按应用阶段</strong>: 分为训练时、后训练和推理时方法。
*   <strong>按技术路径</strong>: 包括基于参数算术操作的方法、基于梯度的方法（如梯度上升）、模型编辑技术、集成稀疏自编码器（SAE）的方法、引入新结构（如LoRA、EUL）的方法，以及在推理时通过上下文提示（如ICUL）进行干预的方法。
*   <strong>评估与基准</strong>: 研究还包括如何评估遗忘效果，涉及成员推理攻击（MIA）、专门的评估指标（如Truth Ratio）和基准数据集（如TOFU、WMDP）。</p>

<h3>解决方案</h3>

<p>本文提出的解决方案围绕<strong>“机器遗忘”（Machine Unlearning）</strong>这一核心概念，为大型语言模型（LLMs）提供了一套系统性的知识删除框架。该框架旨在有效移除模型中的特定信息（如隐私数据、版权材料或有害知识），同时最大限度地保留模型的整体性能和效用。这对于确保AI系统的安全性、合规性和可信赖性至关重要。</p>

<p>以下是该解决方案的详细阐述：</p>

<h4><strong>一、 机器遗忘的核心概念与目标</strong></h4>

<p>机器遗忘是一种选择性地从已训练好的模型中移除特定训练数据影响的技术，其行为应尽可能接近于从未见过这些数据重新训练的模型。</p>

<ul>
<li><p><strong>核心目标</strong>:</p>

<ol>
<li><strong>有效遗忘</strong>: 确保模型不再“记住”或生成被指定遗忘集中的内容。</li>
<li><strong>效用保持</strong>: 遗忘过程不应损害模型在其他无关知识上的表现，避免“灾难性遗忘”。</li>
<li><strong>效率与可扩展性</strong>: 遗忘算法应在计算和时间成本上远低于完全重新训练模型。</li>
<li><strong>鲁棒性</strong>: 遗忘效果应持久且能抵抗对抗性攻击（如Jailbreak提示或成员资格推断攻击）。</li>
</ol></li>
<li><p><strong>主要动机</strong>:</p>

<ul>
<li><strong>隐私保护</strong>: 响应“被遗忘权”，删除训练数据中包含的个人可识别信息（PII）。</li>
<li><strong>法律合规</strong>: 移除受版权保护的材料，避免侵权风险。</li>
<li><strong>模型安全与对齐 (Alignment)</strong>: 清除模型内化的有害、带偏见或不准确的知识，作为一种<strong>负向对齐</strong>的关键技术，与RLHF等正向引导方法互补。</li>
<li><strong>知识更新</strong>: 纠正过时或错误的信息，保持模型的时效性。</li>
</ul></li>
</ul>

<h4><strong>二、 机器遗忘方法的系统性分类</strong></h4>

<p>为了系统化地理解和应用遗忘技术，论文根据实施阶段和技术原理对方法进行了分类。</p>

<h5><strong>1. 按实施阶段分类</strong></h5>

<ul>
<li><strong>训练时遗忘</strong>: 在模型训练过程中直接引入机制，例如采用SISA（Sharded, Isolated, Sliced, and Aggregated）训练范式，通过数据分片和保存检查点，使得当需要遗忘某一片数据时，只需从相应的检查点重新训练，从而提高效率。</li>
<li><strong>后训练遗忘</strong>: 这是最主流的方法，即对一个已经训练好的LLM进行参数修改，以实现知识移除。</li>
<li><strong>推理时遗忘</strong>: 不修改模型参数，而是在模型进行推理时，通过操纵输入（如指令提示）或输出来动态阻止模型生成特定内容。</li>
</ul>

<h5><strong>2. 按技术原理分类（主要针对后训练遗忘）</strong></h5>

<ul>
<li><p><strong>基于目标优化的方法</strong>: 将遗忘视为一个优化问题，通过设计特定的损失函数来指导模型参数更新。</p>

<ul>
<li><strong>基于文本的目标</strong>: 直接最大化遗忘样本的预测损失（如Gradient Ascent），或引入参考模型约束参数变化，防止模型“走偏”。</li>
<li><strong>基于分布的目标</strong>: 强制模型在面对遗忘输入时的输出分布趋向于一个无信息的参考分布（如均匀分布）。</li>
<li><strong>基于激活的目标</strong>: 扰动模型内部特定层的激活状态，使其在处理遗忘数据时产生无信息的、随机的内部表示。</li>
</ul></li>
<li><p><strong>基于参数算术操作的方法</strong>: 通过直接对模型参数进行算术运算来实现遗忘。</p>

<ul>
<li>例如，训练一个专门学习有害知识的“反专家”模型，然后从原始模型的参数中“减去”这个反专家的参数，从而抵消相关知识。</li>
<li>常与<strong>参数高效微调（PEFT）</strong>技术（如LoRA）结合，仅修改少量适配器参数，提高效率。</li>
</ul></li>
<li><p><strong>基于内部表示操控的方法</strong>: 侧重于理解和修改模型的内部知识表示。</p>

<ul>
<li><strong>稀疏自编码器（SAE）</strong>: 利用SAE识别并分离出与特定知识相关的“特征”，然后在推理时抑制这些特征的激活。</li>
</ul></li>
<li><p><strong>基于新结构引入的方法</strong>:</p>

<ul>
<li>在模型层与层之间插入新的、</li>
</ul></li>
</ul>

            
        </div>

        <div class="footer">
            <p>Generated by AI Paper Review System at 2025-11-20 13:23:20</p>
            <p style="margin-top: 10px;">
                <a href="https://jycarlos1019.pp.ua">系统首页</a> • 
                <a href="../../search.html">搜索归档</a>
            </p>
        </div>
    </div>
</body>
</html>