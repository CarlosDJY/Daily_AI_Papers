<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks</title>
    <style>
        :root {
            /* 配色方案：Slate + Indigo */
            --primary-color: #4f46e5;
            --bg-body: #f8fafc;
            --bg-paper: #ffffff;
            --text-main: #1e293b;      /* Slate 800 */
            --text-body: #334155;      /* Slate 700 - 正文颜色略浅，减少视觉疲劳 */
            --text-secondary: #64748b; /* Slate 500 */
            --border-color: #e2e8f0;
            --code-bg: #f1f5f9;
            
            /* 警告色 */
            --warn-bg: #fff7ed;
            --warn-text: #9a3412;
            --warn-border: #fdba74;

            --font-stack: '圆体-简', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            --font-mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: var(--font-stack);
            background-color: var(--bg-body);
            color: var(--text-body);
            line-height: 1.8; /* 增加行高，适合阅读 */
            padding: 40px 20px;
            min-height: 100vh;
        }

        /* 阅读容器：限制宽度以提升阅读体验 */
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: var(--bg-paper);
            border-radius: 16px; /* 更圆润的角 */
            padding: 40px 60px; /* 宽敞的内边距 */
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05), 0 2px 4px -1px rgba(0, 0, 0, 0.03);
        }

        /* 顶部导航 */
        .nav-bar {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 1px solid var(--border-color);
            font-size: 14px;
        }

        .nav-link {
            color: var(--text-secondary);
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            transition: color 0.2s;
        }

        .nav-link:hover { color: var(--primary-color); }
        .nav-link::before { content: "←"; margin-right: 5px; }
        
        .arxiv-link {
            background-color: #f1f5f9;
            color: var(--text-main);
            padding: 6px 12px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 500;
            transition: all 0.2s;
        }
        
        .arxiv-link:hover {
            background-color: #e2e8f0;
            color: var(--primary-color);
        }

        /* 论文头部信息 */
        .paper-header {
            margin-bottom: 40px;
        }

        .paper-title {
            font-size: 32px;
            font-weight: 700;
            color: var(--text-main);
            line-height: 1.4;
            margin-bottom: 20px;
            letter-spacing: -0.02em;
        }

        /* 标签组 */
        .tags-wrapper {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-bottom: 20px;
        }

        .tag {
            background-color: #e0e7ff; /* Indigo 100 */
            color: #4338ca;            /* Indigo 700 */
            font-size: 12px;
            padding: 4px 10px;
            border-radius: 99px;
            font-weight: 500;
        }

        /* 元数据栏 */
        .metadata-box {
            background-color: #f8fafc;
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 20px;
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            font-size: 14px;
            color: var(--text-secondary);
        }

        .meta-item {
            display: flex;
            flex-direction: column;
            gap: 4px;
        }

        .meta-label {
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: #94a3b8;
        }

        .meta-value {
            font-weight: 600;
            color: var(--text-main);
        }
        
        .score-badge {
            color: var(--primary-color);
        }

        /* 核心图片展示 */
        .core-image-container {
            margin: 40px 0;
            text-align: center;
            background-color: #f8fafc;
            padding: 20px;
            border-radius: 12px;
            border: 1px solid var(--border-color);
        }

        .core-image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        
        .image-caption {
            margin-top: 10px;
            font-size: 13px;
            color: var(--text-secondary);
            font-style: italic;
        }

        /* 警告框 */
        .warning-box {
            background-color: var(--warn-bg);
            border-left: 4px solid var(--warn-border);
            color: var(--warn-text);
            padding: 15px;
            border-radius: 0 6px 6px 0;
            margin: 20px 0;
            font-size: 14px;
        }

        /* 章节标题 */
        .section-header {
            display: flex;
            align-items: center;
            margin-top: 50px;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 1px dashed var(--border-color);
        }

        .section-header h2 {
            font-size: 24px;
            font-weight: 700;
            color: var(--text-main);
            margin: 0;
            position: relative;
        }
        
        /* 章节前的装饰点 */
        .section-header h2::before {
            content: '';
            display: inline-block;
            width: 8px;
            height: 8px;
            background-color: var(--primary-color);
            border-radius: 50%;
            margin-right: 12px;
            vertical-align: middle;
        }

        /* Markdown 内容样式重置 - 极简学术风 */
        .content-body {
            font-size: 17px; /* 略大的字号适合阅读 */
            color: var(--text-body);
        }

        .content-body p {
            margin-bottom: 1.5em;
            text-align: justify;
        }

        .content-body h3 {
            font-size: 20px;
            font-weight: 600;
            color: var(--text-main);
            margin-top: 2em;
            margin-bottom: 1em;
        }
        
        .content-body h4 {
            font-size: 18px;
            font-weight: 600;
            margin-top: 1.5em;
            margin-bottom: 0.8em;
        }

        .content-body ul, .content-body ol {
            margin-bottom: 1.5em;
            padding-left: 1.5em;
        }

        .content-body li {
            margin-bottom: 0.5em;
        }

        .content-body strong {
            color: var(--text-main);
            font-weight: 600;
        }
        
        /* 引用块 - 学术风 */
        .content-body blockquote {
            border-left: 4px solid var(--primary-color);
            background-color: #f8fafc;
            padding: 16px 20px;
            margin: 20px 0;
            font-style: italic;
            color: var(--text-secondary);
            border-radius: 0 8px 8px 0;
        }

        /* 代码块 */
        .content-body pre {
            background-color: var(--code-bg);
            padding: 16px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            border: 1px solid var(--border-color);
        }

        .content-body code {
            font-family: var(--font-mono);
            background-color: var(--code-bg);
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 0.9em;
            color: #d63384; /* 类似 GitHub 的代码红 */
        }
        
        .content-body pre code {
            color: inherit;
            padding: 0;
            background-color: transparent;
        }

        /* Footer */
        .footer {
            margin-top: 80px;
            text-align: center;
            color: var(--text-secondary);
            font-size: 13px;
            border-top: 1px solid var(--border-color);
            padding-top: 30px;
        }

        /* 移动端适配 */
        @media (max-width: 768px) {
            body { padding: 0; }
            
            .container {
                border-radius: 0;
                padding: 30px 20px;
                box-shadow: none;
            }

            .paper-title { font-size: 26px; }
            
            .metadata-box {
                flex-direction: column;
                gap: 15px;
            }
            
            .content-body { font-size: 16px; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="nav-bar">
            <a href="index.html" class="nav-link">返回今日简报</a>
            <a href="http://arxiv.org/abs/2511.16540v1" target="_blank" class="arxiv-link">PDF / arXiv ↗</a>
        </div>

        <div class="paper-header">
            <h1 class="paper-title">Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks</h1>
            
            
            <div class="tags-wrapper">
                
                <span class="tag">大型语言模型</span>
                
                <span class="tag">可解释性</span>
                
                <span class="tag">文本体裁</span>
                
                <span class="tag">激活分析</span>
                
                <span class="tag">分类器</span>
                
            </div>
            

            <div class="metadata-box">
                
                <div class="meta-item" style="flex: 2; min-width: 200px;">
                    <span class="meta-label">作者单位</span>
                    <span class="meta-value">Independent, Chalmers Technical University, Lund University</span>
                </div>
                
                
                <div class="meta-item">
                    <span class="meta-label">推荐指数</span>
                    <span class="meta-value score-badge">0.498</span>
                </div>
                
                <div class="meta-item">
                    <span class="meta-label">arXiv ID</span>
                    <span class="meta-value">2511.16540v1</span>
                </div>
            </div>

            
        </div>

        
        <div class="core-image-container">
            
            <img src="../../images/2025-11-21/f831edf780b1a6f938207f62a62ce8e54d9fd32bfcebd87618ab809ddc50ba9e.jpg" alt="核心思路示意图" />
            <div class="image-caption">图 1：论文核心方法/架构示意图</div>
        </div>
        

        <div class="section-header">
            <h2>快速简介</h2>
        </div>
        <div class="content-body">
            <p>本文提出了一种新框架，通过分析大型语言模型（LLM）激活来推断文本体裁，解决了LLM可解释性的问题。实验结果显示，使用简单分类器可在合成数据集上实现高达98%的F1分数，验证了从LLM激活中提取可解释文本体裁信息的有效性，为理解和监控LLM输出提供了新方法。</p>
        </div>

        <div class="section-header">
            <h2>深度解读</h2>
        </div>
        <div class="content-body">
            
                <h3>现有问题</h3>

<p>本文旨在解决大型语言模型（LLMs）的可解释性问题，特别是如何从模型的内部激活中提取和理解文本的体裁（genre）或类别信息。随着LLMs在各领域的广泛应用，理解其工作原理和监控其输出变得至关重要，但现有研究多集中于解释单个词元（token）的预测，缺乏对多词元文本块的整体性解释。</p>

<h3>Hypothesis</h3>

<ul>
<li><strong>核心假设</strong>: LLMs的内部激活包含了关于文本体裁或类别的高层次、可解释的信息。通过分析这些激活，可以准确地推断出文本块的体裁。</li>
<li><strong>关键发现</strong>: 实验表明，通过简单的分类器分析模型激活，可以高效地预测文本体裁，在不同数据集上F1分数可高达98%和71%。</li>
<li><strong>初步结论</strong>: 模型在较深层次的激活中能更准确地表示文本结构，这为从LLMs中提取可解释概念提供了概念证明（proof-of-concept）。</li>
</ul>

<h3>相关研究</h3>

<ul>
<li><strong>机制可解释性</strong>: 主要关注神经元激活对单个词元预测的影响。</li>
<li><strong>表示工程 (Representation Engineering)</strong>: 探讨如何利用模型激活来提取人类可理解的概念，如Nora Belrose等人的工作。</li>
<li><strong>文本分类</strong>: 涉及使用传统方法和LLMs进行文本分类的研究，如CORE数据集上的相关工作。</li>
<li><strong>模型激活分析</strong>: 研究Mistral-7B等模型的激活特性，以及使用PHATE等工具进行高维数据可视化。</li>
</ul>

<h3><strong>论文核心解决方案：通过分析大型语言模型（LLMs）的激活来预测文本类型</strong></h3>

<p>本论文提出了一种创新的方法，旨在通过分析大型语言模型（LLMs）在处理文本时产生的内部激活（activations），来预测文本块（chunks）的类别（如指令、叙述、代码等）。该方法不仅显著提高了对LLM行为的可解释性，还为监控和理解模型输出提供了有效的工具。</p>

<p>整个解决方案可以分为三个主要阶段：<strong>1) 多样化文本数据集的构建</strong>，<strong>2) 基于模型激活的分类器训练与评估</strong>，以及 <strong>3) 激活特征的可视化分析</strong>。</p>

<hr />

<h4><strong>第一阶段：数据集构建——生成多样化的分类文本</strong></h4>

<p>为了训练和验证所提出的方法，研究团队首先构建了一个高质量、多样化的文本数据集。此过程确保了生成的文本能够覆盖广泛的类别和主题。</p>

<ol>
<li><p><strong>设计初始提示（Prompts）</strong>：</p>

<ul>
<li>研究人员手动编写了68个开放式提示，这些提示旨在引导LLM生成五种特定类别的文本：<strong>指令性（instructional）</strong>、<strong>叙述性（narrative）</strong>、<strong>解释性（explanatory）</strong>、<strong>演讲（speech）</strong>和<strong>代码（code）</strong>。</li>
</ul></li>
<li><p><strong>扩展提示集</strong>：</p>

<ul>
<li>为了进一步增加多样性，研究团队使用<code>Mistral-7B-Instruct-v2.0</code>模型，基于初始提示列表生成了更多的合成提示。这些新生成的提示经过筛选，剔除了无意义或不相关的内容，最终形成一个包含669个提示的列表。</li>
</ul></li>
<li><p><strong>生成文本</strong>：</p>

<ul>
<li>使用<code>Mistral-7B-Instruct-v2.0</code>模型处理这669个提示，生成大量文本。每个输出的长度被限制在500个标记（tokens）以内。</li>
</ul></li>
<li><p><strong>文本分块与自动标注</strong>：</p>

<ul>
<li>生成的文本被送入<code>GPT-4 Turbo Preview</code>模型进行处理。该模型负责将长文本按照自然的段落（通常以双换行符 <code>\n\n</code> 分隔）分割成文本块，并为每个文本块自动标注预定义的类别。</li>
</ul></li>
<li><p><strong>人工审核与最终数据集</strong>：</p>

<ul>
<li>所有自动标注的结果都经过了严格的人工审核，以纠正和移除错误标记的文本块，确保了数据集的准确性和高质量。</li>
<li>最终，研究团队获得了包含3914个已标注文本块的数据集，其类别分布如下：
<ul>
<li>指令性文本：1159</li>
<li>解释性文本：699</li>
<li>演讲文本：548</li>
<li>叙述性文本：542</li>
<li>代码文本：290</li>
</ul></li>
</ul></li>
</ol>

<hr />

<h4><strong>第二阶段：分类器训练与评估——从激活中预测文本类别</strong></h4>

<p>此阶段是方法的核心，旨在验证是否可以仅通过分析LLM的内部激活来准确预测文本块的类别。</p>

<ol>
<li><p><strong>提取激活</strong>：</p>

<ul>
<li>研究团队使用<code>Mistral-7B</code>模型处理第一阶段构建的数据集中的每一个文本块。</li>
<li>在处理过程中，他们从模型的每一层提取了激活值和残余流（residual stream）。这些激活值构成了用于训练分类器的特征。</li>
</ul></li>
<li><p><strong>训练探测模型（Probing Classifiers）</strong>：</p>

<ul>
<li>将提取出的激活值作为输入特征，研究者训练了多种浅层机器学习分类器（例如，使用<code>scikit-learn</code>和<code>Lazy Predict</code>库中的模型）。</li>
<li>这些分类器的任务是学习激活模式与文本块类别之间的映射关系，即“探测”模型内部是否编码了关于文本类型的高层语义信息。</li>
</ul></li>
<li><p><strong>性能评估与对照实验</strong>：</p>

<ul>
<li>该方法在两个不同的数据集上进行了评估，取得了优异的性能，F1分数分别达到了<strong>98%</strong>和<strong>71%</strong>，显著优于对照任务。</li>
<li>为了确保分类器的性能确实来源于模型学到的有意义的表示，研究者设计了一个对照实验：他们使用一个具有相同架构但参数是随机初始化的<code>Mistral-7B</code>模型提取激活，并用其训练分类器。结果显示，基于随机参数模型的分类器性能远低于基于预训练模型的分类器，这有力地证明了探测模型依赖的是LLM学到的真实激活表示，而非偶然。</li>
</ul></li>
</ol>

<hr />

<h4><strong>第三阶段：维度减少与可视化分析</strong></h4>

<p>为了更直观地理解LLM是如何在其内部表示空间中组织不同文本类别的，研究团队进行了维度减少和可视化分析。</p>

<ol>
<li><p><strong>文本编码</strong>：</p>

<ul>
<li>使用<code>Qwen3-Embedding-0.6B</code>文本嵌入模型，将数据集中的文本块编码为高维向量。</li>
</ul></li>
<li><p><strong>维度减少与可视化</strong>：</p>

<ul>
<li>采用<strong>PHATE</strong>算法对文本嵌入向量进行降维处理。PHATE擅长保留数据的局部和全局结构。</li>
<li>通过将降维后的数据点在二维空间中进行可视化，研究者观察到，<strong>相同类别的文本块在嵌入空间中形成了明显独立的聚类</strong>。这直观地表明，LLM的内部表示确实能够区分和组织不同类型的高层语义概念。</li>
</ul></li>
</ol>

<hr />

<h3><strong>结论与应用价值</strong></h3>

<p>本论文提出的解决方案成功地证明了，通过分析大型语言模型（LLMs）的内部激活，可以准确地预测文本块的宏观类别。这一发现填补了当前可解释性研究主要关注单个词元（token）预测的空白，将分析单元提升到了更具语义意义的段落级别。</p>

<p>该方法的应用价值主要体现在以下两个方面：</p>

<ul>
<li><strong>增强模型可解释性</strong>：提供了一种更直观、更高层次的视角来理解LLM的内部工作机制，帮助研究人员和开发者理解模型“在想什么”。</li>
<li><strong>实现文本监控</strong>：可用于实时监控和分析LLM的输出内容，例如在内容生成、对话系统或安全审查等场景中，自动识别模型正在生成的文本类型，从而进行干预或调整。</li>
</ul>

<p>通过提供完整的代码和数据集，该研究为未来的LLM可解释性工作奠定了坚实的基础。</p>

<h3>实验设计</h3>

<ul>
<li><strong>模型</strong>: 使用Mistral-7B模型进行实验。</li>
<li><strong>数据集</strong>:
<ol>
<li>一个手动构建的<strong>合成数据集</strong>，包含669个提示生成的3914个文本块。</li>
<li>一个已建立的<strong>CORE数据集</strong>，用于对比验证。</li>
</ol></li>
<li><strong>评估</strong>: 将数据集按80/20划分为训练集和测试集，使用宏F1分数（Macro F1-score）作为主要性能评估指标，并与随机基线进行比较。</li>
<li><strong>分析</strong>: 对比模型在不同层次的激活上的分类性能，以及在不同数据集（合成 vs. CORE）上的表现差异。</li>
</ul>

<h3>数据集和代码</h3>

<ul>
<li><strong>数据集</strong>: 实验使用了手动构建的合成数据集和公开的CORE数据集。</li>
<li><strong>代码</strong>: 相关代码已在GitHub上开源：<a href="https://github.com/Aza-Spearal/Trajectories-Probing">https://github.com/Aza-Spearal/Trajectories-Probing</a></li>
</ul>

<h3>实验结果</h3>

<ul>
<li><strong>性能优越</strong>: 在合成数据集上，分类器的F1分数高达<strong>0.98</strong>；在更具挑战性的CORE数据集上，最佳F1分数为<strong>0.71</strong>。这些结果远超随机基线，验证了假设的有效性。</li>
<li><strong>激活深度影响</strong>: 模型的分类性能随网络层数的加深而提高，表明更深层次的激活捕获了更抽象、更高层次的文本结构信息。</li>
<li><strong>数据集影响</strong>: 合成数据集由于类别界限清晰，分类效果显著优于类别存在重叠的CORE数据集，这揭示了文本类别的重叠度对模型表示能力有直接影响。</li>
</ul>

<h3>论文贡献</h3>

<ul>
<li><strong>提出新框架</strong>: 提出了一个通过分析LLM激活来解释多词元文本块的新框架，为LLM的可解释性研究开辟了新方向。</li>
<li><strong>验证可行性</strong>: 首次系统性地验证了从LLM激活中提取可解释的文本体裁信息是可行的，并展示了其高准确性。</li>
<li><strong>提供新方法</strong>: 展示了如何利用LLM生成和分类文本以支持定性分析，并为评估模型如何表示文本类别提供了新的方法论基础。</li>
</ul>

            
        </div>

        <div class="footer">
            <p>Generated by AI Paper Review System at 2025-11-28 10:47:21</p>
            <p style="margin-top: 10px;">
                <a href="https://jycarlos1019.pp.ua">系统首页</a> • 
                <a href="../../search.html">搜索归档</a>
            </p>
        </div>
    </div>
</body>
</html>