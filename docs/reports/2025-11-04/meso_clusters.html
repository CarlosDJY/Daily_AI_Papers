<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¸­è§‚èšç±»åˆ†æ - 2025-11-04</title>
    <style>
        body {
            font-family: 'åœ†ä½“-ç®€', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #ffa500;
            margin: 0;
            font-size: 28px;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 6px;
        }
        .nav-links a {
            color: #007bff;
            text-decoration: none;
            margin-right: 15px;
            font-size: 14px;
        }
        .nav-links a:hover {
            text-decoration: underline;
        }
        .content-section {
            background-color: #fff9e6;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #ffa500;
        }
        .cluster-item {
            margin: 20px 0;
            padding: 20px;
            background-color: white;
            border-radius: 6px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .cluster-item h3 {
            color: #2c3e50;
            margin-top: 0;
            font-size: 18px;
            border-bottom: 2px solid #ffa500;
            padding-bottom: 10px;
        }
        .cluster-item ul {
            margin: 15px 0;
            padding-left: 20px;
        }
        .cluster-item li {
            margin: 12px 0;
            line-height: 1.6;
        }
        .cluster-item strong {
            color: #2c3e50;
            display: block;
            margin-bottom: 5px;
        }
        .cluster-item .contribution {
            color: #666;
            font-size: 14px;
        }
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ä¸­è§‚èšç±»åˆ†æ</h1>
            <div class="date">2025-11-04</div>
        </div>

        <div class="nav-links">
            <a href="index.html">â† è¿”å›æ¯æ—¥ç®€æŠ¥</a>
            <a href="../../index.html">è¿”å›æ±‡æ€»é¡µ</a>
        </div>

        <div class="content-section">
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 1: å¤šæ¨¡æ€å­¦ä¹ ä¸è§†è§‰è¯­è¨€æ¨¡å‹</h3>
                <ul>
                    
                    <li>
                        <strong>Finding Culture-Sensitive Neurons in Vision-Language Models</strong>
                        <span class="contribution">ç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹ä¸­å¯¹æ–‡åŒ–ä¿¡æ¯æ•æ„Ÿçš„ç¥ç»å…ƒï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨å¤„ç†æ–‡åŒ–èƒŒæ™¯è¾“å…¥æ—¶çš„å±€é™æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºå›¾çš„ä¼ªæ ‡è®°æ¡†æ¶ï¼Œä»¥æé«˜åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„ç¤ºä¾‹æ”¶é›†æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Rethinking Visual Intelligence: Insights from Video Pretraining</strong>
                        <span class="contribution">æ¢è®¨äº†è§†é¢‘é¢„è®­ç»ƒå¯¹è§†è§‰æ™ºèƒ½çš„å½±å“ï¼Œå¹¶æŒ‡å‡ºè§†è§‰é¢†åŸŸåœ¨é€‚åº”æ–°é—®é¢˜æ—¶çš„æŒ‘æˆ˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–¹æ³•æ¥å¢å¼ºè§†è§‰è¯­è¨€æ¨¡å‹çš„ç»†ç²’åº¦è§†è§‰æ„ŸçŸ¥èƒ½åŠ›ï¼Œè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>DualCap: Enhancing Lightweight Image Captioning via Dual Retrieval with Similar Scenes Visual Prompts</strong>
                        <span class="contribution">æå‡ºäº†DualCapæ¨¡å‹ï¼Œé€šè¿‡åŒé‡æ£€ç´¢å¢å¼ºè½»é‡çº§å›¾åƒæè¿°ï¼Œç¼©å°è¯­ä¹‰å·®è·ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>BLM_1: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§æ— ç•Œå¤§å‹æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å­¦ä¹ ä¸­çš„ç©ºé—´å’Œä»»åŠ¡æ³›åŒ–é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>VC4VG: Optimizing Video Captions for Text-to-Video Generation</strong>
                        <span class="contribution">æ¢è®¨äº†ä¼˜åŒ–è§†é¢‘å­—å¹•ä»¥æé«˜æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>What do vision-language models see in the context? Investigating multimodal in-context learning</strong>
                        <span class="contribution">ç³»ç»Ÿç ”ç©¶äº†è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å…¶æ½œåœ¨çš„ä¸è¶³ä¹‹å¤„ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>V-SAT: Video Subtitle Annotation Tool</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„è§†é¢‘å­—å¹•æ³¨é‡Šå·¥å…·ï¼Œä»¥è§£å†³ç°æœ‰ç”Ÿæˆæ–¹æ³•çš„å±€é™æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs</strong>
                        <span class="contribution">ä»‹ç»äº†Latent Sketchpadå·¥å…·ï¼Œåˆ©ç”¨è‰å›¾ä¿ƒè¿›å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›çš„æå‡ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 2: æ·±åº¦å­¦ä¹ ä¸ç‰©ç†å»ºæ¨¡çš„ç»“åˆ</h3>
                <ul>
                    
                    <li>
                        <strong>Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨æé«˜å¤æ‚ç‰©ç†ç³»ç»Ÿçš„æ—¶ç©ºé¢„æµ‹å‡†ç¡®æ€§å’Œé•¿æœŸé¢„æµ‹èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning</strong>
                        <span class="contribution">ä»‹ç»äº†æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰ï¼Œé€šè¿‡è·³è·ƒè¿æ¥å…‹æœäº†è®­ç»ƒæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œæ—¶çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation</strong>
                        <span class="contribution">æ¢è®¨äº†ç»Ÿè®¡ç‰©ç†åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œåˆ†æäº†å¤šå±‚æ„ŸçŸ¥æœºçš„æœ€ä½³å­¦ä¹ èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç‰©ç†å¼•å¯¼çš„å®šé‡å¢å¼ºæ–¹æ³•SPARKï¼Œä»¥æ”¹å–„åŠ¨æ€ç³»ç»Ÿå»ºæ¨¡ä¸­çš„åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Identifiable learning of dissipative dynamics</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§å­¦ä¹ å¤æ‚è€—æ•£ç³»ç»ŸåŠ¨åŠ›å­¦çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿä»æ•°æ®ä¸­é‡åŒ–å…¶è¡Œä¸ºç‰¹å¾ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning</strong>
                        <span class="contribution">æä¾›äº†å…³äºå¼±åˆ°å¼ºæ³›åŒ–ç°è±¡çš„ç†è®ºè§£é‡Šï¼Œå¼ºè°ƒç‰¹å¾å­¦ä¹ åœ¨éçº¿æ€§æ¨¡å‹ä¸­çš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Deep Learning-Enhanced Calibration of the Heston Model: A Unified Framework</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ å¢å¼ºHestonæ¨¡å‹çš„æ ¡å‡†è¿‡ç¨‹ï¼Œè§£å†³äº†å…¶è®¡ç®—å¤æ‚æ€§å’Œå±€éƒ¨æœ€å°å€¼æ•æ„Ÿæ€§é—®é¢˜ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 3: äººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ </h3>
                <ul>
                    
                    <li>
                        <strong>Greedy Sampling Is Provably Efficient for RLHF</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç†è®ºæ¡†æ¶ï¼Œè¯æ˜äº†è´ªå©ªé‡‡æ ·åœ¨åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§æ–°çš„å¥–åŠ±å»ºæ¨¡æ–¹æ³•ï¼Œç»“åˆäº†æˆå¯¹å’Œé€ç‚¹ä¿¡å·ï¼Œä»¥æé«˜äººç±»åå¥½çš„å¯¹é½ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Evolving Diagnostic Agents in a Virtual Clinical Environment</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåœ¨è™šæ‹Ÿä¸´åºŠç¯å¢ƒä¸­ä½œä¸ºè¯Šæ–­ä»£ç†è¿›è¡Œå¤šè½®å¯¹è¯ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§æ–°çš„å¥–åŠ±æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³çŸ¥è¯†å¯†é›†å‹å’Œé•¿ç¯‡ä»»åŠ¡ä¸­çš„è¯„ä¼°é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?</strong>
                        <span class="contribution">æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå°†äººç±»æŒ‡ä»¤è½¬åŒ–ä¸ºå†…éƒ¨ç¬¦å·è¡¨ç¤ºï¼Œä»¥æ”¯æŒå‘å±•æ€§å­¦ä¹ ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Reinforcement Learning for Long-Horizon Multi-Turn Search Agents</strong>
                        <span class="contribution">å±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ å¦‚ä½•é€šè¿‡ç»éªŒå­¦ä¹ æ˜¾è‘—æå‡å¤šè½®æœç´¢ä»£ç†çš„èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 4: å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰</h3>
                <ul>
                    
                    <li>
                        <strong>Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems</strong>
                        <span class="contribution">ç»¼è¿°äº†å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹å¹»è§‰çš„å¤šç§ç­–ç•¥ï¼Œé‡ç‚¹ä»‹ç»äº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œæ¨ç†å¢å¼ºçš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ¡†æ¶å’ŒåŸºå‡†ï¼Œä»¥æ­ç¤ºå¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¿»è¯‘ä¸­çš„å¹»è§‰ç°è±¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºå…ƒåˆ†æçš„è¯æ®é‡æ–°æ’åºæ–¹æ³•ï¼Œä»¥æé«˜åŸºäºè¯æ®çš„åŒ»å­¦ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ•ˆæœã€‚</span>
                    </li>
                    
                    <li>
                        <strong>PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§æ”¯æŒPICOçš„æŸ¥è¯¢é‡å†™æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–åŸºäºè¯æ®çš„åŒ»å­¦ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆè¿‡ç¨‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºå¼‚è´¨æ€§çš„æ¡†æ¶ï¼Œç”¨äºåœ¨åŒ»å­¦æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿä¸­è¿›è¡Œå¤šè¯æ®éªŒè¯ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 5: å› æœæ¨æ–­ä¸åŠ¨æ€ç³»ç»Ÿåˆ†æ</h3>
                <ul>
                    
                    <li>
                        <strong>Cyclic Counterfactuals under Shift-Scale Interventions</strong>
                        <span class="contribution">æ¢è®¨äº†åœ¨å…·æœ‰åé¦ˆå¾ªç¯çš„ç³»ç»Ÿä¸­è¿›è¡Œåäº‹å®æ¨æ–­çš„æ–°æ–¹æ³•ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Causal Ordering for Structure Learning From Time Series</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æ¨æ–­å› æœç»“æ„çš„æ–°ç­–ç•¥ï¼Œä»¥åº”å¯¹ç»„åˆå¤æ‚æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŠ¨æ€è·¯å¾„è½¨è¿¹å­¦ä¹ æ–¹æ³•ï¼Œä»¥åˆ†æå¤§è„‘åŠŸèƒ½ç½‘ç»œçš„æ—¶é—´æ¼”å˜ç‰¹å¾ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Graph Distance Based on Cause-Effect Estimands with Latents</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºå› æœæ•ˆåº”ä¼°è®¡çš„å›¾è·ç¦»åº¦é‡æ–¹æ³•ï¼Œä»¥è¯„ä¼°å› æœå‘ç°çš„è¿›å±•ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 6: AIä¸äººç±»è®¤çŸ¥çš„äº¤äº’</h3>
                <ul>
                    
                    <li>
                        <strong>Efficiency Without Cognitive Change: Evidence from Human Interaction with Narrow AI Systems</strong>
                        <span class="contribution">æœ¬ç ”ç©¶å®éªŒæ€§åœ°æµ‹è¯•äº†çŸ­æœŸæ¥è§¦ç‹­ä¹‰AIå·¥å…·æ˜¯å¦æå‡æ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼Œæˆ–ä»…ä»…æé«˜æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems</strong>
                        <span class="contribution">æå‡ºäº†å™äº‹è¿ç»­æ€§æµ‹è¯•ï¼ˆNCTï¼‰ï¼Œä¸ºè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„AIç³»ç»Ÿçš„èº«ä»½æŒç»­æ€§æä¾›äº†æ¦‚å¿µæ¡†æ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>A Unified Geometric Space Bridging AI Models and the Human Brain</strong>
                        <span class="contribution">æ¢è®¨äº†ç°ä»£äººå·¥ç¥ç»ç½‘ç»œä¸äººè„‘åœ¨ä¿¡æ¯ç»„ç»‡ä¸Šçš„å…³ç³»ï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å‡ ä½•ç©ºé—´ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model</strong>
                        <span class="contribution">é€šè¿‡å¼•å…¥è¾¹ç•Œå‘é‡ç»†èƒï¼ˆBVCsï¼‰æ¨¡å‹ï¼Œæå‡äº†åŸºäº3D LiDARçš„æœºå™¨äººå®šä½ç²¾åº¦ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 7: å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä¸æ•°æ®æŒ‘æˆ˜</h3>
                <ul>
                    
                    <li>
                        <strong>Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ³•å’Œæœ€ä½³å®è·µï¼Œä»¥ä¿ƒè¿›éè‹±è¯­è¯­è¨€å¤§è¯­è¨€æ¨¡å‹çš„åŸºå‡†è¯„ä¼°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs</strong>
                        <span class="contribution">æ¢è®¨äº†ä»…ä½¿ç”¨è‹±è¯­æ•°æ®è¿›è¡Œå¤šè¯­è¨€çŸ¥è¯†æ¶ˆé™¤çš„é£é™©ï¼Œå¹¶å¼ºè°ƒäº†è¯„ä¼°è§†è§’çš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Relative Scaling Laws for LLMs</strong>
                        <span class="contribution">å¼•å…¥äº†ç›¸å¯¹ç¼©æ”¾å®šå¾‹ï¼Œæ­ç¤ºäº†åœ¨ä¸åŒå­ç¾¤ä½“ä¸­å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½å·®å¼‚çš„å¤æ‚æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data</strong>
                        <span class="contribution">å¼€å‘äº†LuxITæ•°æ®é›†ï¼Œæ—¨åœ¨ä¸ºå¢æ£®å ¡è¯­çš„æŒ‡ä»¤è°ƒä¼˜æä¾›é«˜è´¨é‡çš„å•è¯­è®­ç»ƒæ•°æ®ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 8: ICUä¸­çš„æœºå™¨å­¦ä¹ ä¸æ•°æ®è´¨é‡</h3>
                <ul>
                    
                    <li>
                        <strong>Closing Gaps: An Imputation Analysis of ICU Vital Signs</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ•°æ®æ’è¡¥åˆ†ææ–¹æ³•ï¼Œä»¥æé«˜ICUç”Ÿå‘½ä½“å¾æ•°æ®çš„è´¨é‡ï¼Œä»è€Œå¢å¼ºä¸´åºŠé¢„æµ‹æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU</strong>
                        <span class="contribution">å¼•å…¥äº†MIMIC-Sepsisæ•°æ®é›†ï¼Œæä¾›äº†ä¸€ä¸ªç»è¿‡æ•´ç†çš„åŸºå‡†æ¡†æ¶ï¼Œä»¥ä¾¿æ›´å¥½åœ°å»ºæ¨¡å’Œå­¦ä¹ ICUä¸­çš„è„“æ¯’ç—‡è½¨è¿¹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Filtering instances and rejecting predictions to obtain reliable models in healthcare</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤æ­¥æ•°æ®ä¸­å¿ƒæ–¹æ³•ï¼Œä»¥æé«˜åŒ»ç–—é¢†åŸŸæœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯é æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ä¸ç¡®å®šæ€§æ—¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Towards actionable hypotension prediction -- predicting catecholamine therapy initiation in the intensive care unit</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§é¢„æµ‹ä½è¡€å‹æ‚£è€…å¯åŠ¨å„¿èŒ¶é…šèƒºæ²»ç–—çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨æ”¹å–„ICUæ‚£è€…çš„ç®¡ç†å†³ç­–ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 9: è‡ªåŠ¨é©¾é©¶ä¸­çš„å¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°</h3>
                <ul>
                    
                    <li>
                        <strong>SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è½»é‡çº§æ¡†æ¶SCOUTï¼Œç”¨äºåœ¨è‡ªåŠ¨é©¾é©¶ä¸­è¯„ä¼°åœºæ™¯è¦†ç›–ç‡ï¼Œé™ä½äº†å¯¹æ˜‚è´µäººå·¥æ ‡æ³¨å’Œè®¡ç®—å¯†é›†å‹æ¨¡å‹çš„ä¾èµ–ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§ç³»ç»Ÿæ¡†æ¶ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šçš„æç¤ºå’Œç©ºé—´æ¨ç†æ¥å¢å¼ºè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ç†è§£ä¸­çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space</strong>
                        <span class="contribution">å¼•å…¥äº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•SPARTAï¼Œé€šè¿‡é»‘ç®±å¯¹æŠ—æ€§æ”¹å†™åœ¨æ–‡æœ¬è‡ªç¼–ç å™¨æ½œåœ¨ç©ºé—´ä¸­è¯„ä¼°æ¨ç†åˆ†å‰²çš„é²æ£’æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 10: åŸºäºå°–å³°ç¥ç»ç½‘ç»œçš„èƒ½æ•ˆä¼˜åŒ–</h3>
                <ul>
                    
                    <li>
                        <strong>Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºç”µå‹ä¾èµ–çš„çªè§¦å¯å¡‘æ€§çš„æ— ç›‘ç£å±€éƒ¨å­¦ä¹ æ–¹æ³•ï¼Œä»¥æé«˜è¾¹ç¼˜è®¡ç®—è®¾å¤‡çš„èƒ½æ•ˆå’ŒåŠŸèƒ½æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>All in one timestep: Enhancing Sparsity and Energy efficiency in Multi-level Spiking Neural Networks</strong>
                        <span class="contribution">é€šè¿‡å¢å¼ºå¤šçº§å°–å³°ç¥ç»ç½‘ç»œçš„ç¨€ç–æ€§å’Œèƒ½æ•ˆï¼Œæ¨åŠ¨äº†äº‹ä»¶é©±åŠ¨é€šä¿¡æœºåˆ¶åœ¨ç¥ç»å½¢æ€ç¡¬ä»¶ä¸Šçš„åº”ç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ›¿ä»£æ¢¯åº¦æ–¹æ³•ï¼Œä»¥æé«˜å°–å³°ç¥ç»ç½‘ç»œåœ¨åºåˆ—å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨æ•ˆç‡ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
        </div>

        <div class="footer">
            <p>ç”Ÿæˆæ—¶é—´: 2025-11-04 13:06:02</p>
            <p>æ•°æ®æ¥æº: arXiv AI è®ºæ–‡æ¨èç³»ç»Ÿ</p>
        </div>
    </div>
</body>
</html>
