<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model</title>
    <style>
        body {
            font-family: '圆体-简', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #2c3e50;
            margin: 0 0 15px 0;
            font-size: 26px;
            line-height: 1.4;
        }
        .paper-meta {
            color: #666;
            font-size: 14px;
            margin-bottom: 10px;
        }
        .paper-meta strong {
            color: #333;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 0;
            background-color: transparent;
            border-radius: 0;
        }
        .nav-links a {
            display: inline-block;
            background-color: #6c757d;
            color: white;
            text-decoration: none;
            padding: 10px 20px;
            border-radius: 6px;
            font-weight: normal;
            font-size: 14px;
            margin-right: 10px;
            margin-bottom: 10px;
            transition: background-color 0.3s ease;
        }
        .nav-links a:hover {
            background-color: #545b62;
            color: white;
            text-decoration: none;
        }
        .nav-links a[style*="background-color: #007bff"]:hover {
            background-color: #0056b3 !important;
        }
        .paper-score {
            display: inline-block;
            background-color: #007bff;
            color: white;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 14px;
            font-weight: bold;
            margin-right: 10px;
        }
        .paper-id {
            display: inline-block;
            background-color: #6c757d;
            color: white;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 14px;
        }
        .section {
            margin: 25px 0;
        }
        .section h2 {
            color: #2c3e50;
            font-size: 20px;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid #e9ecef;
        }
        .section-content {
            line-height: 1.8;
            color: #495057;
            font-size: 16px;
        }
        /* Markdown 内容区域样式 */
        .section-content > * {
            margin-bottom: 1rem;
        }
        .section-content h1,
        .section-content h2,
        .section-content h3,
        .section-content h4,
        .section-content h5,
        .section-content h6 {
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }
        .section-content code {
            background-color: #f4f4f4;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: monospace;
        }
        .section-content pre {
            background-color: #f4f4f4;
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
        }
        .section-content pre code {
            background-color: transparent;
            padding: 0;
        }
        .section-content blockquote {
            border-left: 4px solid #ddd;
            padding-left: 1rem;
            margin-left: 0;
            color: #666;
        }
        .section-content ul,
        .section-content ol {
            padding-left: 2em;
        }
        .section-content img {
            max-width: 100%;
            height: auto;
        }
        .paper-image {
            margin: 20px 0;
            text-align: center;
        }
        .paper-image img {
            max-width: 100%;
            height: auto;
            border-radius: 6px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            border: 1px solid #e9ecef;
        }
        .paper-warning {
            color: #e67e22;
            font-size: 14px;
            margin: 15px 0;
            padding: 12px;
            background-color: #fff4e6;
            border-left: 4px solid #e67e22;
            border-radius: 4px;
        }
        .links {
            margin: 25px 0;
        }
        .btn {
            display: inline-block;
            background-color: #007bff;
            color: white;
            text-decoration: none;
            padding: 10px 20px;
            border-radius: 6px;
            font-weight: normal;
            font-size: 14px;
            margin-right: 10px;
            margin-bottom: 10px;
            transition: background-color 0.3s ease;
        }
        .btn:hover {
            background-color: #0056b3;
            color: white;
            text-decoration: none;
        }
        .btn-secondary {
            background-color: #6c757d;
        }
        .btn-secondary:hover {
            background-color: #545b62;
        }
        .footer {
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model</h1>
            
            <div class="paper-meta"><strong>作者单位:</strong> Google DeepMind</div>
            
            <div>
                <span class="paper-score">推荐分数: 0.447</span>
                <span class="paper-id">arXiv ID: 2510.26622v1</span>
            </div>
            
        </div>
        
        <div class="nav-links">
            <a href="http://arxiv.org/abs/2510.26622v1" target="_blank" style="background-color: #007bff;">📄 查看 arXiv 原文</a>
            <a href="index.html">← 返回每日报告</a>
            <a href="../../index.html">← 返回汇总页</a>
        </div>
        
        
        <div class="paper-image">
            
            <img src="../../images/2025-11-02/d537952d866e662a58a63aaf1a0e9d538bfe190580b64c80ac14795551af817c.jpg" alt="核心思路示意图" />
        </div>
        
        
        <div class="section">
            <h2>📖 简介</h2>
            <div class="section-content">
                本文提出了一种新型编码器-解码器模型RedLLM，结合了现代解码器模型的技术，系统比较了其与仅解码器模型DecLLM的性能。研究表明，尽管DecLLM在预训练阶段更具计算效率，RedLLM在微调和推理效率上表现更佳，尤其在处理长序列时展现出优越的外推能力。这一发现为编码器-解码器架构的潜力提供了新的视角。
            </div>
        </div>
        
        <div class="section">
            <h2>📝 详细解读</h2>
            
            <style>
                /* 确保页面的 body 样式不被 report_css 中的全局样式覆盖 */
                body {
                    max-width: 900px !important;
                    margin: 0 auto !important;
                    padding: 20px !important;
                    font-size: 16px !important;
                    line-height: 1.6 !important;
                    background-color: #f8f9fa !important;
                    background-image: none !important;
                    word-break: normal !important;
                }
                
                /* Markdown 渲染样式 - 作用域限定在 .markdown-content */
                .markdown-content {
                    min-width: 200px;
                    max-width: 100% !important;  /* 覆盖 CSS 文件中的 1800px */
                    width: 100% !important;
                    margin: 0 !important;
                    padding: 1em;
                    font-family: '圆体-简', 'Yuanti SC', Segoe UI, Helvetica, Arial, sans-serif, Apple Color Emoji, Segoe UI Emoji;
                    color: #595959;
                    font-size: 18px !important;  /* 覆盖 CSS 文件中的 40px */
                    line-height: 1.8em;
                    background-image: linear-gradient(90deg, rgba(60, 10, 30, 0.05) 3%, transparent 0), linear-gradient(1turn, rgba(60, 10, 30, 0.05) 3%, transparent 0);
                    background-size: 20px 20px;
                    background-position: 50%;
                    word-break: break-word !important;  /* 覆盖 CSS 文件中的 break-all */
                    box-sizing: border-box;
                }
                
                /* 将 report_css 中的全局样式作用域限定到 .markdown-content */
                /* 使用正则表达式替换 body { 为 .markdown-content { */
                
                @charset "UTF-8";
* {
  box-sizing: border-box;
}

.markdown-content {
  min-width: 200px;
  max-width: 1800px;
  margin: 0 auto;
  padding: 1em;
  font-family: '圆体-简', 'Yuanti SC', Segoe UI, Helvetica, Arial, sans-serif, Apple Color Emoji, Segoe UI Emoji;
  color: #595959;
  font-size: 40px;
  line-height: 1.8em;
  background-image: linear-gradient(90deg, rgba(60, 10, 30, 0.05) 3%, transparent 0), linear-gradient(1turn, rgba(60, 10, 30, 0.05) 3%, transparent 0);
  background-size: 20px 20px;
  background-position: 50%;
  word-break: break-all;
}

/* 主题自定义 */
blockquote {
  margin-left: 0;
  background-color: #ebf4ff;
  border-color: #7f9cf5;
  padding-top: 0.5rem;
  padding-bottom: 0.5rem;
  color: #667eea;
}

strong {
  color: #5a67d8;
}

code, a {
  color: #5a67d8;
}

a {
  border-color: #667eea;
}

code {
  background-color: #ebf4ff;
}

blockquote, details, dl, ol, p, pre, table, ul {
  margin-bottom: 1rem;
}

ol {
  list-style: decimal;
}

ul {
  list-style: disc;
}

ol, ul {
  padding-left: 2em;
}

h1, h2 {
  border-color: #5a67d8;
  border-style: solid;
  border-top-width: 0px;
  border-right-width: 0px;
  font-weight: 500;
  padding-top: 0.25rem;
  padding-bottom: 0.25rem;
  padding-left: 0.75rem;
}

/* 主题自定义 end */
/* 布局，一般不需要改动 */
h1, h2 {
  border-bottom: 1px solid #eaecef !important;
  border-left-width: 6px;
}

h1, h2, h3, h4, h5, h6 {
  margin-bottom: 16px;
  line-height: 1.25;
}

blockquote {
  padding-top: 0.5rem;
  padding-bottom: 0.5rem;
  padding-left: 1rem;
  padding-right: 1rem;
  border-left: 0.25em solid;
}

blockquote > :last-child {
  margin-bottom: 0;
}

blockquote > :first-child {
  margin-top: 0;
}

strong {
  font-weight: bold;
}

strong::before {
  content: "「";
}

strong::after {
  content: "」";
}

code, a {
  font-weight: 500;
}

code, a {
  font-size: unset;
}

a {
  text-decoration: none;
  border-bottom: 1px solid;
}

.footnote-ref {
  border-width: 0px;
}

code {
  font-family: '圆体-简', 'Yuanti SC', Segoe UI, Helvetica, Arial, sans-serif;
  font-size: 1.07em;
}

pre > code {
  font-weight: 400;
  color: unset;
  line-height: 1.6;
}

picture img {
  border-radius: 6px;
  display: block;
  margin: 10px auto;
  -o-object-fit: contain;
  object-fit: contain;
  box-shadow: 2px 4px 7px #999;
}

img {
  max-width: 100%;
  display: block;
  margin: 10px auto;
  object-fit: contain;
  border-radius: 6px;
  box-shadow: 2px 4px 7px #999;
}

picture {
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  margin-top: 6px;
  margin-bottom: 6px;
}

pre, pre code[class*=language-] {
  display: block;
  overflow-x: auto;
  padding: 0;
  /* color: #abb2bf; */
}

pre code[class*=language-] {
  padding: 12px;
  padding-top: 6px;
}

pre::before {
  content: "";
  display: block;
  background-image: url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI1NCIgaGVpZ2h0PSIxNCIgdmlld0JveD0iMCAwIDU0IDE0Ij4KICA8ZyBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDEgMSkiPgogICAgPGNpcmNsZSBjeD0iNiIgY3k9IjYiIHI9IjYiIGZpbGw9IiNGRjVGNTYiIHN0cm9rZT0iI0UwNDQzRSIgc3Ryb2tlLXdpZHRoPSIuNSIvPgogICAgPGNpcmNsZSBjeD0iMjYiIGN5PSI2IiByPSI2IiBmaWxsPSIjRkZCRDJFIiBzdHJva2U9IiNERUExMjMiIHN0cm9rZS13aWR0aD0iLjUiLz4KICAgIDxjaXJjbGUgY3g9IjQ2IiBjeT0iNiIgcj0iNiIgZmlsbD0iIzI3QzkzRiIgc3Ryb2tlPSIjMUFBQjI5IiBzdHJva2Utd2lkdGg9Ii41Ii8+CiAgPC9nPgo8L3N2Zz4K");
  height: 30px;
  width: 100%;
  margin-bottom: -7px;
  background-size: 40px;
  background-repeat: no-repeat;
  /* border-radius: 5px; */
  /* background-color: #282c34; */
  /* background-position: 10px 10px; */
}

.svg-markmap-box {
  min-height: 20rem;
  width: 100%;
}

.footnotes {
  padding-top: 0.5rem;
  padding-bottom: 0.5rem;
}

/* 布局 end */
/* prism-js 样式 */
/* PrismJS 1.23.0
https://prismjs.com/download.html#themes=prism-okaidia&languages=markup+css+clike+javascript */
/**
 * okaidia theme for JavaScript, CSS and HTML
 * Loosely based on Monokai textmate theme by http://www.monokai.nl/
 * @author ocodia
 */
code[class*=language-],
pre[class*=language-] {
  color: #f8f8f2;
  background: none;
  text-shadow: 0 1px rgba(0, 0, 0, 0.3);
  font-family: '圆体-简', 'Yuanti SC', Consolas, Monaco, "Andale Mono", "Ubuntu Mono", monospace;
  font-size: 1em;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*=language-] {
  padding: 1em;
  margin: 0.5em 0;
  overflow: auto;
  border-radius: 6px;
}

:not(pre) > code[class*=language-],
pre[class*=language-] {
  background: #272822;
}

/* Inline code */
:not(pre) > code[class*=language-] {
  padding: 0.1em;
  border-radius: 0.3em;
  white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
  color: #8292a2;
}

.token.punctuation {
  color: #f8f8f2;
}

.token.namespace {
  opacity: 0.7;
}

.token.property,
.token.tag,
.token.constant,
.token.symbol,
.token.deleted {
  color: #f92672;
}

.token.boolean,
.token.number {
  color: #ae81ff;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
  color: #a6e22e;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string,
.token.variable {
  color: #f8f8f2;
}

.token.atrule,
.token.attr-value,
.token.function,
.token.class-name {
  color: #e6db74;
}

.token.keyword {
  color: #66d9ef;
}

.token.regex,
.token.important {
  color: #fd971f;
}

.token.important,
.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}

.token.entity {
  cursor: help;
}

/* prism-js end */
                
                /* 覆盖一些全局样式，确保不影响页面其他部分 */
                .markdown-content h1,
                .markdown-content h2,
                .markdown-content h3,
                .markdown-content h4,
                .markdown-content h5,
                .markdown-content h6 {
                    margin-top: 1.5rem;
                    margin-bottom: 1rem;
                }
                
                /* 确保 .markdown-content 不会超出父容器 */
                .section-content {
                    width: 100%;
                    max-width: 100%;
                    box-sizing: border-box;
                }
                
                /* 覆盖 report_css 中可能影响宽度的其他样式 */
                .markdown-content * {
                    max-width: 100%;
                    box-sizing: border-box;
                }
            </style>
            
            <div class="section-content">
                
                    <div class="markdown-content" style="max-width: 100%; width: 100%;">
                        <p><think>
<strong>Considering Report Modification</strong></p>

<p>I've pinpointed the "解决方案" section slated for replacement in the user's report outline. Next, I need to find the existing section in order to replace it with the user's detailed solution.</p>

<p><strong>Evaluating Section Replacement</strong></p>

<p>Now, I'm examining the user's detailed solution. I've noted that it contains subheadings, which I must integrate while maintaining the report's overall structure. My next step involves preparing the original report outline for the replacement, carefully removing the "解决方案" section.</p>

<p><strong>Implementing the Replacement Plan</strong></p>

<p>I'm now fully immersed in the replacement phase. The core strategy is clear: delete the old "解决方案" section and inject the user's detailed content. I'm focusing on preserving the structural integrity of the report. The user's detailed solution has been carefully examined for heading levels and formatting. Now, I'm working through the steps to assemble the final, complete Markdown. The key is to flawlessly incorporate the user's solution while maintaining the report's overall consistency.</p>

<p></think>### 现有问题
本文旨在系统性地解决当前大语言模型（LLM）研究中，对<strong>编码器-解码器（Encoder-Decoder）架构</strong>（以RedLLM为代表）与<strong>仅解码器（Decoder-Only）架构</strong>（以DecLLM为代表）之间比较不足的问题。尽管近年来研究重心转向了仅解码器模型，但编码器-解码器模型的潜力可能被忽视。该问题的重要性体现在：
- 需要明确不同架构在不同场景（如预训练、微调、长序列处理）下的性能、效率和扩展性差异。
- 了解架构与预训练目标之间的平衡关系，对于优化模型性能和有效利用计算资源至关重要。</p>

<h3>Hypothesis</h3>

<p>核心假设是，通过将现代LLM技术（如旋转位置嵌入、新的预训练目标）应用于编码器-解码器架构（RedLLM），可以使其在性能和扩展性上与主流的仅解码器架构（DecLLM）相媲美，并展现出独特的优势。具体假设包括：
- <strong>架构权衡</strong>：两种架构在性能、参数效率和计算效率之间存在不同的权衡。
- <strong>场景优势</strong>：DecLLM在预训练效率和零样本（zero-shot）任务上更具优势；而RedLLM因其双向注意力机制，在微调适应性、推理效率和长序列上下文处理上表现更佳。
- <strong>效率差异</strong>：RedLLM在微调和推理阶段具有更高的计算效率。</p>

<h3>相关研究</h3>

<p>本文的研究建立在以下工作之上：
- <strong>LLM架构比较</strong>：先前关于编码器-解码器与仅解码器模型优劣势的分析（如Wang et al., 2022; Tay et al., 2022）。
- <strong>模型扩展法则</strong>：关于计算最优扩展法则的研究（如Hoffmann et al., 2022）。
- <strong>开源模型复现</strong>：如LLaMA等大规模模型的训练和复现工作（Touvron et al., 2023）。
- <strong>预训练目标</strong>：对因果语言建模（Causal LM）、前缀语言建模（Prefix LM）等不同预训练目标的研究。</p>

<h3>解决方案</h3>

<h4><strong>论文核心解决方案：对编码-解码大语言模型（RedLLM）的再评估与增强</strong></h4>

<p>该论文提出的核心解决方案是，通过系统性的增强和严谨的实验比较，重新评估并证明编码-解码架构的大语言模型（下文简称 RedLLM）在当前由仅解码模型（下文简称 DecLLM）主导的领域中，仍然具备强大的竞争力和独特的优势。解决方案并非提出一个全新的模型，而是通过现代化改造、公平对比和深入分析，为大语言模型的架构选择提供了新的视角和实证依据。</p>

<p>该解决方案主要由以下几个关键部分组成：</p>

<h4><strong>第一部分：RedLLM 架构的现代化增强</strong></h4>

<p>为了与先进的 DecLLM 进行公平比较，研究团队首先对传统的编码-解码架构进行了现代化改造，借鉴了当前主流 LLM 的最新技术进展。</p>

<ul>
<li><strong>核心架构</strong>：基于 Transformer，采用了对称的编码器和解码器层数，以实现处理输入和生成输出之间的平衡。</li>
<li><strong>关键技术集成</strong>：
<ul>
<li><strong>旋转位置嵌入 (Rotary Positional Embedding, RoPE)</strong>：在编码器和解码器的所有注意力层中均使用 RoPE，以有效处理位置信息，增强模型的上下文理解和长序列外推能力。</li>
<li><strong>SwiGLU 激活函数</strong>：在前馈网络中使用 SwiGLU，以提升模型的非线性表达能力。</li>
<li><strong>RMSNorm 归一化</strong>：采用 RMSNorm 代替传统的层归一化（LayerNorm），并在预归一化结构下使用，以增强训练过程的稳定性，防止参数爆炸。</li>
<li><strong>额外归一化层</strong>：在注意力机制的查询（Q）、键（K）、值（V）向量上应用额外的归一化，进一步提升训练稳定性。</li>
</ul></li>
</ul>

<h4><strong>第二部分：严谨的比较实验设计与训练策略</strong></h4>

<p>为了系统性地评估增强后的 RedLLM 与 DecLLM 的性能，研究团队设计了一套全面的实验流程。</p>

<ul>
<li><strong>模型与规模</strong>：在多个模型规模下（从约150M到8B参数）构建了对应的 RedLLM 和 DecLLM，确保比较的公平性。</li>
<li><strong>预训练阶段</strong>：
<ul>
<li><strong>数据集</strong>：使用大规模、高质量的 RedPajama V1 数据集（约1.6T tokens）进行预训练。</li>
<li><strong>训练目标</strong>：统一采用<strong>前缀语言建模（Prefix Language Modeling, Prefix LM）</strong>作为训练目标。这种方法既高效又简化了训练流程，使两种架构能够在相同的目标下进行学习。</li>
<li><strong>训练框架</strong>：整个实验基于 <strong>T5X 和 SeqIO 框架</strong>，这是一个专为大规模模型训练和灵活数据处理而设计的工具，确保了实验的可扩展性和效率。</li>
</ul></li>
<li><strong>微调阶段</strong>：
<ul>
<li><strong>数据集</strong>：使用涵盖超过1800个任务的 <strong>FLAN</strong> 数据集进行指令微调（instruction tuning），以激发和评估模型在多样化下游任务上的泛化能力。</li>
<li><strong>评估任务</strong>：在13个不同的下游任务上，全面评估模型的零样本（zero-shot）和少样本（few-shot）学习能力。</li>
</ul></li>
</ul>

<h4><strong>第三部分：核心发现与性能分析</strong></h4>

<p>通过上述实验，论文揭示了 RedLLM 和 DecLLM 之间深刻的性能权衡与架构优势。</p>

<ol>
<li><p><strong>预训练与微调的性能权衡</strong>：</p>

<ul>
<li>在<strong>预训练阶段</strong>，DecLLM 在零样本学习任务上表现出更强的性能，并且在给定相同计算预算的情况下，其困惑度（Perplexity）更低。</li>
<li>然而，在经过<strong>指令微调</strong>后，RedLLM 的性能得到巨大提升，能够追平甚至在部分零样本和少样本任务上<strong>超越</strong> DecLLM。这表明 RedLLM 具有更强的微调适应性。</li>
</ul></li>
<li><p><strong>推理与训练的效率优势</strong>：</p>

<ul>
<li>RedLLM 在训练和推理的<strong>吞吐量（Throughput）</strong>上显著优于 DecLLM。这意味着在单位时间内，RedLLM 可以处理更多的样本，使其在实际部署和应用中更具计算效率优势。这一优势构成了其在质量-计算权衡中的核心竞争力。</li>
</ul></li>
<li><p><strong>双向注意力的关键作用</strong>：</p>

<ul>
<li>RedLLM 的核心优势之一源于其编码器中的<strong>双向注意力机制（Bidirectional Attention）</strong>，这使其能够对输入文本形成更全面的理解。</li>
<li>为了验证这一点，研究人员为 DecLLM 引入了一个类似的<strong>双向输入注意力模块（BiAttn）</strong>，结果发现 DecLLM 的性能也获得了显著提升。这从侧面证明了双向上下文理解对于提升模型能力的重要性。</li>
</ul></li>
<li><p><strong>长上下文处理能力</strong>：</p>

<ul>
<li>在处理长序列时，RedLLM 的困惑度（PPL）上升曲线更为平滑，展现出更好的上下文长度外推潜力。</li>
<li>相比之下，DecLLM 在处理超过其预训练长度的序列时，自注意力权重会出现“局部性衰减”现象，导致性能下降，这揭示了其在长上下文建模方面的一些内在局限性。</li>
</ul></li>
</ol>

<h4><strong>结论与启示</strong></h4>

<p>综合来看，该解决方案通过对 RedLLM 的现代化改造和与 DecLLM 的全面对比，得出了一个重要结论：尽管近年来行业趋势倾向于仅解码模型，但<strong>编码-解码模型（RedLLM）远未过时</strong>。</p>

<p>RedLLM 在微调后的性能上极具竞争力，并且在计算效率上拥有显著优势。这项研究呼吁学术界和工业界重新审视并进一步探索编码-解码架构的潜力，尤其是在构建高效且强大的特定任务大语言模型方面。未来的研究方向可以包括探索非对称的编码器/解码器层数配比，以及进一步优化其在超长序列任务上的表现。</p>

<h3>实验设计</h3>

<p>实验围绕RedLLM和DecLLM的全面对比展开：
- <strong>模型规模</strong>：训练了从约150M到8B参数不等的多个模型。
- <strong>训练与微调</strong>：在<strong>RedPajama V1</strong>数据集上进行预训练，然后在<strong>FLAN</strong>数据集上进行指令微调。
- <strong>评估维度</strong>：
    - <strong>预训练性能</strong>：比较不同计算预算下的困惑度（PPL）。
    - <strong>下游任务</strong>：在13个下游任务上评估模型的零样本（zero-shot）和少样本（few-shot）能力。
    - <strong>长序列能力</strong>：分析模型在处理长上下文时的表现。
    - <strong>效率</strong>：评估微调和推理过程中的计算效率。</p>

<h3>数据集和代码</h3>

<ul>
<li><strong>预训练数据集</strong>：RedPajama V1（约1.6T tokens）。</li>
<li><strong>指令微调数据集</strong>：FLAN。</li>
<li><strong>代码和模型</strong>：在提供的片段中，未明确提及代码和模型的发布链接。</li>
</ul>

<h3>实验结果</h3>

<p>实验结果揭示了两种架构之间复杂的权衡关系：
- <strong>预训练与零样本</strong>：DecLLM在预训练阶段更具计算效率（在相同计算量下PPL更低），并在零样本任务上普遍优于RedLLM，尤其是在模型规模较大时。
- <strong>微调与适应性</strong>：经过指令微调后，RedLLM的性能显著提升，与DecLLM相当，甚至在某些任务上超越了后者。两者在少样本任务上的性能差距远小于零样本任务。
- <strong>长序列与效率</strong>：RedLLM在长序列上表现出更好的外推能力（PPL增长更平滑）。此外，RedLLM在微调和推理过程中的运行效率明显高于DecLLM。</p>

<h3>论文贡献</h3>

<ul>
<li><strong>系统性比较</strong>：首次对现代化的编码器-解码器（RedLLM）和仅解码器（DecLLM）架构进行了大规模、系统性的比较，揭示了它们在不同场景下的性能权衡。</li>
<li><strong>重估编码器-解码器架构</strong>：证明了经过现代化改造的编码器-解码器模型依然是LLM领域一个极具竞争力的选择，尤其在微调和推理效率方面具有优势。</li>
<li><strong>提供实践指导</strong>：为研究人员和开发者根据具体应用需求（如计算预算、是否需要微调、推理延迟要求）选择合适的LLM架构提供了宝贵的实证依据和见解。</li>
</ul>

                    </div>
                
            </div>
        </div>
        
        <div class="links">
            <a href="http://arxiv.org/abs/2510.26622v1" class="btn" target="_blank">📄 查看 arXiv 原文</a>
            <a href="index.html" class="btn btn-secondary">← 返回每日报告</a>
            <a href="../../index.html" class="btn btn-secondary">← 返回汇总页</a>
        </div>
        
        <div class="footer">
            <p>📧 这是由智能论文简报系统自动生成的页面</p>
            <p>生成时间: 2025-11-02 11:29:09</p>
            <p>访问地址: <a href="https://jycarlos1019.pp.ua">https://jycarlos1019.pp.ua</a></p>
        </div>
    </div>
</body>
</html>
