<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>微观深度解读 - 2025-11-10</title>
    <style>
        :root {
            /* 配色：Slate (基调) + Sky (微观主题色) + Indigo (交互) */
            --primary-color: #4f46e5;
            --micro-color: #0ea5e9;    /* Sky 500 - 对应每日简报中的微观色条 */
            --bg-body: #f8fafc;
            --bg-card: #ffffff;
            --text-main: #0f172a;
            --text-secondary: #64748b;
            --text-light: #94a3b8;
            --border-color: #e2e8f0;
            
            --tag-bg: #f0f9ff;
            --tag-text: #0369a1;
            
            --warn-bg: #fff7ed;
            --warn-text: #c2410c;
            
            --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
            --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
            
            --font-stack: '圆体-简', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: var(--font-stack);
            background-color: var(--bg-body);
            color: var(--text-main);
            line-height: 1.6;
            padding: 40px 20px;
            min-height: 100vh;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
        }

        /* SVG 图标 */
        .icon {
            width: 1.1em;
            height: 1.1em;
            display: inline-block;
            vertical-align: middle;
            stroke-width: 2;
            stroke: currentColor;
            fill: none;
            stroke-linecap: round;
            stroke-linejoin: round;
            margin-bottom: 2px;
        }

        /* 导航栏 */
        .nav-bar {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 40px;
            font-size: 14px;
        }

        .back-link {
            color: var(--text-secondary);
            text-decoration: none;
            display: flex;
            align-items: center;
            transition: color 0.2s;
        }

        .back-link:hover { color: var(--primary-color); }
        .back-link .icon { margin-right: 6px; }

        /* 头部 */
        .header {
            text-align: center;
            margin-bottom: 50px;
        }

        .header h1 {
            color: var(--text-main);
            font-size: 28px;
            font-weight: 700;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
        }
        
        .header h1 .icon { color: var(--micro-color); width: 32px; height: 32px; }

        .header .subtitle {
            color: var(--text-secondary);
            font-size: 15px;
        }

        /* 论文卡片列表 */
        .paper-list {
            display: flex;
            flex-direction: column;
            gap: 30px;
        }

        .paper-card {
            background-color: var(--bg-card);
            border-radius: 16px;
            border: 1px solid var(--border-color);
            padding: 30px;
            position: relative;
            transition: all 0.2s ease;
        }

        .paper-card:hover {
            box-shadow: var(--shadow-md);
            border-color: #cbd5e1;
        }

        /* 序号水印 */
        .paper-index {
            position: absolute;
            top: 20px;
            right: 20px;
            font-size: 40px;
            font-weight: 900;
            color: #f1f5f9;
            line-height: 1;
            pointer-events: none;
            z-index: 0;
        }

        /* 卡片头部 */
        .card-header {
            position: relative;
            z-index: 1;
            margin-bottom: 20px;
        }

        .paper-title {
            font-size: 20px;
            font-weight: 700;
            margin-bottom: 12px;
            line-height: 1.4;
            padding-right: 40px; /* 给序号留位 */
        }

        .paper-title a {
            color: var(--text-main);
            text-decoration: none;
            background-image: linear-gradient(transparent 90%, var(--micro-color) 0); /* 极简下划线 */
            background-size: 0 10px;
            background-repeat: no-repeat;
            background-position: bottom;
            transition: background-size 0.3s;
        }

        .paper-card:hover .paper-title a {
            background-size: 100% 10px;
            color: var(--primary-color);
        }

        /* 元数据行 */
        .meta-row {
            display: flex;
            flex-wrap: wrap;
            gap: 16px;
            align-items: center;
            font-size: 13px;
            color: var(--text-secondary);
            margin-bottom: 16px;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .score-badge {
            background-color: #eff6ff;
            color: var(--primary-color);
            font-weight: 700;
            padding: 2px 8px;
            border-radius: 6px;
            font-size: 12px;
        }

        /* 关键词 */
        .keywords-row {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-bottom: 20px;
        }

        .keyword-tag {
            background-color: var(--tag-bg);
            color: var(--tag-text);
            font-size: 12px;
            padding: 4px 10px;
            border-radius: 99px;
            font-weight: 500;
        }

        /* 摘要内容 */
        .summary-content {
            font-size: 15px;
            color: #334155;
            line-height: 1.7;
            margin-bottom: 20px;
            text-align: justify;
        }
        
        .summary-label {
            font-weight: 700;
            color: var(--text-main);
            margin-right: 4px;
        }

        /* 警告框 */
        .warning-box {
            background-color: var(--warn-bg);
            color: var(--warn-text);
            padding: 12px;
            border-radius: 8px;
            font-size: 13px;
            margin-bottom: 20px;
            display: flex;
            align-items: flex-start;
            gap: 8px;
        }
        
        .warning-box .icon { flex-shrink: 0; margin-top: 2px; }

        /* 图片容器 */
        .image-wrapper {
            margin: 20px 0;
            background-color: #f8fafc;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 10px;
            text-align: center;
        }

        .image-wrapper img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            display: block;
            margin: 0 auto;
        }

        /* 底部操作栏 */
        .card-footer {
            margin-top: 25px;
            padding-top: 20px;
            border-top: 1px dashed var(--border-color);
            display: flex;
            justify-content: flex-end;
        }

        .btn-read {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            background-color: var(--bg-body);
            color: var(--text-main);
            padding: 8px 16px;
            border-radius: 8px;
            text-decoration: none;
            font-size: 14px;
            font-weight: 600;
            transition: all 0.2s;
            border: 1px solid var(--border-color);
        }

        .btn-read:hover {
            background-color: var(--primary-color);
            color: #fff;
            border-color: var(--primary-color);
        }

        .page-footer {
            margin-top: 60px;
            text-align: center;
            color: var(--text-secondary);
            font-size: 13px;
            border-top: 1px solid var(--border-color);
            padding-top: 30px;
        }

        /* 移动端适配 */
        @media (max-width: 640px) {
            .paper-card { padding: 20px; }
            .paper-index { font-size: 30px; top: 15px; right: 15px; }
            .paper-title { font-size: 18px; padding-right: 30px; }
            .card-footer { justify-content: stretch; }
            .btn-read { width: 100%; justify-content: center; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="nav-bar">
            <a href="index.html" class="back-link">
                <svg class="icon" viewBox="0 0 24 24"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>
                返回每日简报
            </a>
            <a href="../../index.html" class="back-link">返回汇总页</a>
        </div>

        <div class="header">
            <h1>
                <svg class="icon" viewBox="0 0 24 24"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                微观深度解读
            </h1>
            <div class="subtitle">为您精选了 6 篇高质量 AI 论文的深度解析</div>
        </div>

        <div class="paper-list">
            
            <div class="paper-card">
                <div class="paper-index">#1</div>
                
                <div class="card-header">
                    <div class="paper-title">
                        
                        
                        <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06390v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06390v1.html">
                            Ghost in the Transformer: Tracing LLM Lineage with SVD-Fingerprint
                        </a>
                    </div>

                    <div class="meta-row">
                        <div class="meta-item">
                            <span class="score-badge">0.513 分</span>
                        </div>
                        
                        <div class="meta-item">
                            <svg class="icon" style="color: var(--text-light);" viewBox="0 0 24 24"><path d="M3 21h18"/><path d="M5 21V7l8-4 8 4v14"/><path d="M17 21v-8H7v8"/></svg>
                            School of Artificial Intelligence, Wuhan University, School of Computer Science, Wuhan University
                        </div>
                        
                    </div>

                    
                    <div class="keywords-row">
                        
                        <span class="keyword-tag">大语言模型</span>
                        
                        <span class="keyword-tag">奇异值分解</span>
                        
                        <span class="keyword-tag">谱指纹</span>
                        
                        <span class="keyword-tag">知识产权保护</span>
                        
                        <span class="keyword-tag">AI生态系统透明度</span>
                        
                    </div>
                    
                </div>

                <div class="summary-content">
                    

                    <span class="summary-label">简介：</span>本文提出了GhostSpec，一种轻量级且高效的方法，用于验证大语言模型（LLM）的来源和血统。通过对内部注意力权重矩阵进行奇异值分解，GhostSpec生成不变谱指纹，能够抵抗多种模型修改。该方法无需访问训练数据，且在多种复杂场景下表现出色，有效提升了知识产权保护和AI生态系统的透明度。
                </div>

                
                <div class="image-wrapper">
                    
                    <img src="../../images/2025-11-10/d881cc7a40773792227fdc2f24e2abf175f5d819a415b0618dad6930087e23d5.jpg" alt="核心思路示意图" loading="lazy" />
                </div>
                

                <div class="card-footer">
                    
                    
                    <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06390v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06390v1.html" class="btn-read">
                        阅读详细解读
                        <svg class="icon" viewBox="0 0 24 24"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
                    </a>
                </div>
            </div>
            
            <div class="paper-card">
                <div class="paper-index">#2</div>
                
                <div class="card-header">
                    <div class="paper-title">
                        
                        
                        <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06428v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06428v1.html">
                            Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective
                        </a>
                    </div>

                    <div class="meta-row">
                        <div class="meta-item">
                            <span class="score-badge">0.481 分</span>
                        </div>
                        
                        <div class="meta-item">
                            <svg class="icon" style="color: var(--text-light);" viewBox="0 0 24 24"><path d="M3 21h18"/><path d="M5 21V7l8-4 8 4v14"/><path d="M17 21v-8H7v8"/></svg>
                            无相关单位信息。
                        </div>
                        
                    </div>

                    
                    <div class="keywords-row">
                        
                        <span class="keyword-tag">大型语言模型</span>
                        
                        <span class="keyword-tag">软件开发</span>
                        
                        <span class="keyword-tag">社会技术基础理论</span>
                        
                        <span class="keyword-tag">平衡控制</span>
                        
                        <span class="keyword-tag">管理策略</span>
                        
                    </div>
                    
                </div>

                <div class="summary-content">
                    

                    <span class="summary-label">简介：</span>本文通过对22名软件从业者的访谈，采用社会技术基础理论分析了大型语言模型（LLMs）在软件开发中的双重影响。研究识别了LLMs的优势（如提升效率、改善开发者心智模型）与劣势（如技能退化、团队协作障碍），并提出了“平衡控制”的管理策略，帮助开发者和管理者有效利用LLMs，同时规避潜在风险。
                </div>

                
                <div class="image-wrapper">
                    
                    <img src="../../images/2025-11-10/2dedcffffacda0d75453561094ad2b77972671b289d8cd84131403b577d883dd.jpg" alt="核心思路示意图" loading="lazy" />
                </div>
                

                <div class="card-footer">
                    
                    
                    <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06428v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06428v1.html" class="btn-read">
                        阅读详细解读
                        <svg class="icon" viewBox="0 0 24 24"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
                    </a>
                </div>
            </div>
            
            <div class="paper-card">
                <div class="paper-index">#3</div>
                
                <div class="card-header">
                    <div class="paper-title">
                        
                        
                        <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06174v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06174v1.html">
                            LUT-LLM: Efficient Large Language Model Inference with Memory-based Computations on FPGAs
                        </a>
                    </div>

                    <div class="meta-row">
                        <div class="meta-item">
                            <span class="score-badge">0.479 分</span>
                        </div>
                        
                        <div class="meta-item">
                            <svg class="icon" style="color: var(--text-light);" viewBox="0 0 24 24"><path d="M3 21h18"/><path d="M5 21V7l8-4 8 4v14"/><path d="M17 21v-8H7v8"/></svg>
                            University of California, Los Angeles, Microsoft Research Asia
                        </div>
                        
                    </div>

                    
                    <div class="keywords-row">
                        
                        <span class="keyword-tag">大型语言模型</span>
                        
                        <span class="keyword-tag">FPGA加速器</span>
                        
                        <span class="keyword-tag">内存计算</span>
                        
                        <span class="keyword-tag">激活-权重共同量化</span>
                        
                        <span class="keyword-tag">二维查找表操作</span>
                        
                    </div>
                    
                </div>

                <div class="summary-content">
                    

                    <span class="summary-label">简介：</span>本文提出了LUT-LLM，一种基于内存计算的FPGA加速器，旨在提高大型语言模型（LLM）推理的效率和能效。通过激活-权重共同量化和二维查找表操作，LUT-LLM在AMD V80 FPGA上实现了显著低于GPU的延迟和更高的能效，解决了传统算术计算在FPGA上的性能瓶颈问题。
                </div>

                
                <div class="image-wrapper">
                    
                    <img src="../../images/2025-11-10/7f7ea2718cf6bcaa99c239e9bc6fdcc40c0c4ed5a449f3f8c3c379ba3756c879.jpg" alt="核心思路示意图" loading="lazy" />
                </div>
                

                <div class="card-footer">
                    
                    
                    <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06174v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06174v1.html" class="btn-read">
                        阅读详细解读
                        <svg class="icon" viewBox="0 0 24 24"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
                    </a>
                </div>
            </div>
            
            <div class="paper-card">
                <div class="paper-index">#4</div>
                
                <div class="card-header">
                    <div class="paper-title">
                        
                        
                        <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06571v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06571v1.html">
                            Rep2Text: Decoding Full Text from a Single LLM Token Representation
                        </a>
                    </div>

                    <div class="meta-row">
                        <div class="meta-item">
                            <span class="score-badge">0.467 分</span>
                        </div>
                        
                        <div class="meta-item">
                            <svg class="icon" style="color: var(--text-light);" viewBox="0 0 24 24"><path d="M3 21h18"/><path d="M5 21V7l8-4 8 4v14"/><path d="M17 21v-8H7v8"/></svg>
                            New Jersey Institute of Technology, Wake Forest University, Cisco Research
                        </div>
                        
                    </div>

                    
                    <div class="keywords-row">
                        
                        <span class="keyword-tag">Rep2Text</span>
                        
                        <span class="keyword-tag">大型语言模型</span>
                        
                        <span class="keyword-tag">token表示</span>
                        
                        <span class="keyword-tag">自回归文本重建</span>
                        
                        <span class="keyword-tag">泛化能力</span>
                        
                    </div>
                    
                </div>

                <div class="summary-content">
                    

                    <span class="summary-label">简介：</span>本文提出了Rep2Text框架，旨在从大型语言模型（LLM）的最后一个token表示中恢复原始输入文本。该方法通过可训练的适配器将压缩表示投影到解码模型的嵌入空间，实现自回归文本重建。实验表明，Rep2Text能有效恢复超过一半的16-token序列信息，并在不同模型和分布外数据上展示了良好的泛化能力。
                </div>

                
                <div class="image-wrapper">
                    
                    <img src="../../images/2025-11-10/4700430e4f6ce601b2ac508b7d9c4d546b92aca39de2695019698e38b65c2ed8.jpg" alt="核心思路示意图" loading="lazy" />
                </div>
                

                <div class="card-footer">
                    
                    
                    <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06571v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06571v1.html" class="btn-read">
                        阅读详细解读
                        <svg class="icon" viewBox="0 0 24 24"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
                    </a>
                </div>
            </div>
            
            <div class="paper-card">
                <div class="paper-index">#5</div>
                
                <div class="card-header">
                    <div class="paper-title">
                        
                        
                        <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06237v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06237v1.html">
                            Mixtures of SubExperts for Large Language Continual Learning
                        </a>
                    </div>

                    <div class="meta-row">
                        <div class="meta-item">
                            <span class="score-badge">0.460 分</span>
                        </div>
                        
                        <div class="meta-item">
                            <svg class="icon" style="color: var(--text-light);" viewBox="0 0 24 24"><path d="M3 21h18"/><path d="M5 21V7l8-4 8 4v14"/><path d="M17 21v-8H7v8"/></svg>
                            Deep.AI
                        </div>
                        
                    </div>

                    
                    <div class="keywords-row">
                        
                        <span class="keyword-tag">子专家混合</span>
                        
                        <span class="keyword-tag">持续学习</span>
                        
                        <span class="keyword-tag">灾难性遗忘</span>
                        
                        <span class="keyword-tag">知识隔离</span>
                        
                        <span class="keyword-tag">模型扩展</span>
                        
                    </div>
                    
                </div>

                <div class="summary-content">
                    

                    <span class="summary-label">简介：</span>本文提出了一种名为“子专家混合”（Mixtures of SubExperts, MoSEs）的新框架，旨在解决大型语言模型在持续学习中面临的灾难性遗忘问题。MoSEs通过集成稀疏的子专家网络和任务特定的路由机制，实现了知识的隔离与重用，确保模型在学习新任务时有效保留旧知识，同时以亚线性方式扩展模型容量。实验结果显示，MoSEs在知识保留和任务适应性方面显著优于传统方法。
                </div>

                
                <div class="image-wrapper">
                    
                    <img src="../../images/2025-11-10/6892d6317cb9656793fda2c9ffac7cac64b64d5bb2b17fe1c9a2ba043e88a1a1.jpg" alt="核心思路示意图" loading="lazy" />
                </div>
                

                <div class="card-footer">
                    
                    
                    <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06237v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06237v1.html" class="btn-read">
                        阅读详细解读
                        <svg class="icon" viewBox="0 0 24 24"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
                    </a>
                </div>
            </div>
            
            <div class="paper-card">
                <div class="paper-index">#6</div>
                
                <div class="card-header">
                    <div class="paper-title">
                        
                        
                        <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06552v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06552v1.html">
                            LLM For Loop Invariant Generation and Fixing: How Far Are We?
                        </a>
                    </div>

                    <div class="meta-row">
                        <div class="meta-item">
                            <span class="score-badge">0.383 分</span>
                        </div>
                        
                        <div class="meta-item">
                            <svg class="icon" style="color: var(--text-light);" viewBox="0 0 24 24"><path d="M3 21h18"/><path d="M5 21V7l8-4 8 4v14"/><path d="M17 21v-8H7v8"/></svg>
                            York University, Canada, Microsoft Research, USA
                        </div>
                        
                    </div>

                    
                    <div class="keywords-row">
                        
                        <span class="keyword-tag">大型语言模型</span>
                        
                        <span class="keyword-tag">循环不变式</span>
                        
                        <span class="keyword-tag">生成与修复</span>
                        
                        <span class="keyword-tag">逻辑整合</span>
                        
                        <span class="keyword-tag">推理修复</span>
                        
                    </div>
                    
                </div>

                <div class="summary-content">
                    

                    <span class="summary-label">简介：</span>本文系统评估了大型语言模型（LLMs）在生成和修复程序循环不变式的能力。研究发现，LLMs在生成不变式的成功率最高可达78%，但修复能力仅为16%。通过提供结构化的辅助信息，如领域知识和示例，显著提升了生成性能。论文揭示了LLMs在逻辑整合和推理修复方面的局限性，为未来研究提供了重要指导。
                </div>

                
                <div class="image-wrapper">
                    
                    <img src="../../images/2025-11-10/6ef1ea6650f821d11328a3ac1f2dd2b2b4c816e998d5fb14b2ca3e4cc5fda83f.jpg" alt="核心思路示意图" loading="lazy" />
                </div>
                

                <div class="card-footer">
                    
                    
                    <a href="https://jycarlos1019.pp.ua/track?paper_id=2511.06552v1&redirect_url=%2Freports%2F2025-11-10%2F2511_06552v1.html" class="btn-read">
                        阅读详细解读
                        <svg class="icon" viewBox="0 0 24 24"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg>
                    </a>
                </div>
            </div>
            
        </div>

        <div class="page-footer">
            <p>生成时间: 2025-11-20 13:08:11</p>
            <p>访问地址: <a href="https://jycarlos1019.pp.ua">https://jycarlos1019.pp.ua</a></p>
        </div>
    </div>
</body>
</html>