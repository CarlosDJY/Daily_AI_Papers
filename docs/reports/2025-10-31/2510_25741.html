<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scaling Latent Reasoning via Looped Language Models</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #2c3e50;
            margin: 0 0 15px 0;
            font-size: 26px;
            line-height: 1.4;
        }
        .paper-meta {
            color: #666;
            font-size: 14px;
            margin-bottom: 10px;
        }
        .paper-meta strong {
            color: #333;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 6px;
        }
        .nav-links a {
            color: #007bff;
            text-decoration: none;
            margin-right: 15px;
        }
        .nav-links a:hover {
            text-decoration: underline;
        }
        .paper-score {
            display: inline-block;
            background-color: #007bff;
            color: white;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 14px;
            font-weight: bold;
            margin-right: 10px;
        }
        .paper-id {
            display: inline-block;
            background-color: #6c757d;
            color: white;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 14px;
        }
        .section {
            margin: 25px 0;
        }
        .section h2 {
            color: #2c3e50;
            font-size: 20px;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid #e9ecef;
        }
        .section-content {
            line-height: 1.8;
            color: #495057;
            font-size: 16px;
        }
        /* Markdown 内容区域样式 */
        .section-content > * {
            margin-bottom: 1rem;
        }
        .section-content h1,
        .section-content h2,
        .section-content h3,
        .section-content h4,
        .section-content h5,
        .section-content h6 {
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }
        .section-content code {
            background-color: #f4f4f4;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: monospace;
        }
        .section-content pre {
            background-color: #f4f4f4;
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
        }
        .section-content pre code {
            background-color: transparent;
            padding: 0;
        }
        .section-content blockquote {
            border-left: 4px solid #ddd;
            padding-left: 1rem;
            margin-left: 0;
            color: #666;
        }
        .section-content ul,
        .section-content ol {
            padding-left: 2em;
        }
        .section-content img {
            max-width: 100%;
            height: auto;
        }
        .paper-image {
            margin: 20px 0;
            text-align: center;
        }
        .paper-image img {
            max-width: 100%;
            height: auto;
            border-radius: 6px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            border: 1px solid #e9ecef;
        }
        .paper-warning {
            color: #e67e22;
            font-size: 14px;
            margin: 15px 0;
            padding: 12px;
            background-color: #fff4e6;
            border-left: 4px solid #e67e22;
            border-radius: 4px;
        }
        .links {
            margin: 25px 0;
        }
        .btn {
            display: inline-block;
            background-color: #007bff;
            color: white;
            text-decoration: none;
            padding: 12px 24px;
            border-radius: 6px;
            font-weight: bold;
            margin-right: 10px;
            margin-bottom: 10px;
            transition: background-color 0.3s ease;
        }
        .btn:hover {
            background-color: #0056b3;
            color: white;
            text-decoration: none;
        }
        .btn-secondary {
            background-color: #6c757d;
        }
        .btn-secondary:hover {
            background-color: #545b62;
        }
        .footer {
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Scaling Latent Reasoning via Looped Language Models</h1>
            
            <div class="paper-meta"><strong>作者单位:</strong> ByteDance Seed, UC Santa Cruz, Princeton University, Mila - Quebec AI Institute, University of Montreal, Peking University, Carnegie Mellon University, University of Pennsylvania, Conscium, University of Manchester, M-A-P</div>
            
            <div>
                <span class="paper-score">推荐分数: 0.554</span>
                <span class="paper-id">arXiv ID: 2510.25741</span>
            </div>
            
        </div>
        
        <div class="nav-links">
            <a href="index.html">← 返回每日报告</a>
            <a href="../../index.html">← 返回汇总页</a>
        </div>
        
        
        <div class="paper-image">
            
            <img src="../../images/2025-10-31/05c0e4f69cbb4392266785c7e4f400f57bcda8a4d6339a54e3868d1844ed71c0.jpg" alt="核心思路示意图" />
        </div>
        
        
        <div class="section">
            <h2>📖 简介</h2>
            <div class="section-content">
                本文提出了Ouro（LoopLM）架构，通过在预训练阶段内置推理机制，显著提升大型语言模型的推理能力和参数效率。该方法采用递归计算和自适应深度策略，优化了知识操作，解决了传统模型在多步骤推理和计算效率上的不足。实验结果表明，Ouro在多个基准测试中表现优于同规模的现有模型，展示了其在推理时代的潜力。
            </div>
        </div>
        
        <div class="section">
            <h2>📝 详细解读</h2>
            
            <style>
                /* Markdown 渲染样式 - 作用域限定在 .markdown-content */
                .markdown-content {
                    min-width: 200px;
                    max-width: 100%;
                    margin: 0;
                    padding: 1em;
                    font-family: '圆体-简', 'Yuanti SC', Segoe UI, Helvetica, Arial, sans-serif, Apple Color Emoji, Segoe UI Emoji;
                    color: #595959;
                    font-size: 18px;
                    line-height: 1.8em;
                    background-image: linear-gradient(90deg, rgba(60, 10, 30, 0.05) 3%, transparent 0), linear-gradient(1turn, rgba(60, 10, 30, 0.05) 3%, transparent 0);
                    background-size: 20px 20px;
                    background-position: 50%;
                    word-break: break-word;
                }
                @charset "UTF-8";
* {
  box-sizing: border-box;
}

body {
  min-width: 200px;
  max-width: 1800px;
  margin: 0 auto;
  padding: 1em;
  font-family: '圆体-简', 'Yuanti SC', Segoe UI, Helvetica, Arial, sans-serif, Apple Color Emoji, Segoe UI Emoji;
  color: #595959;
  font-size: 40px;
  line-height: 1.8em;
  background-image: linear-gradient(90deg, rgba(60, 10, 30, 0.05) 3%, transparent 0), linear-gradient(1turn, rgba(60, 10, 30, 0.05) 3%, transparent 0);
  background-size: 20px 20px;
  background-position: 50%;
  word-break: break-all;
}

/* 主题自定义 */
blockquote {
  margin-left: 0;
  background-color: #ebf4ff;
  border-color: #7f9cf5;
  padding-top: 0.5rem;
  padding-bottom: 0.5rem;
  color: #667eea;
}

strong {
  color: #5a67d8;
}

code, a {
  color: #5a67d8;
}

a {
  border-color: #667eea;
}

code {
  background-color: #ebf4ff;
}

blockquote, details, dl, ol, p, pre, table, ul {
  margin-bottom: 1rem;
}

ol {
  list-style: decimal;
}

ul {
  list-style: disc;
}

ol, ul {
  padding-left: 2em;
}

h1, h2 {
  border-color: #5a67d8;
  border-style: solid;
  border-top-width: 0px;
  border-right-width: 0px;
  font-weight: 500;
  padding-top: 0.25rem;
  padding-bottom: 0.25rem;
  padding-left: 0.75rem;
}

/* 主题自定义 end */
/* 布局，一般不需要改动 */
h1, h2 {
  border-bottom: 1px solid #eaecef !important;
  border-left-width: 6px;
}

h1, h2, h3, h4, h5, h6 {
  margin-bottom: 16px;
  line-height: 1.25;
}

blockquote {
  padding-top: 0.5rem;
  padding-bottom: 0.5rem;
  padding-left: 1rem;
  padding-right: 1rem;
  border-left: 0.25em solid;
}

blockquote > :last-child {
  margin-bottom: 0;
}

blockquote > :first-child {
  margin-top: 0;
}

strong {
  font-weight: bold;
}

strong::before {
  content: "「";
}

strong::after {
  content: "」";
}

code, a {
  font-weight: 500;
}

code, a {
  font-size: unset;
}

a {
  text-decoration: none;
  border-bottom: 1px solid;
}

.footnote-ref {
  border-width: 0px;
}

code {
  font-family: '圆体-简', 'Yuanti SC', Segoe UI, Helvetica, Arial, sans-serif;
  font-size: 1.07em;
}

pre > code {
  font-weight: 400;
  color: unset;
  line-height: 1.6;
}

picture img {
  border-radius: 6px;
  display: block;
  margin: 10px auto;
  -o-object-fit: contain;
  object-fit: contain;
  box-shadow: 2px 4px 7px #999;
}

img {
  max-width: 100%;
  display: block;
  margin: 10px auto;
  object-fit: contain;
  border-radius: 6px;
  box-shadow: 2px 4px 7px #999;
}

picture {
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  margin-top: 6px;
  margin-bottom: 6px;
}

pre, pre code[class*=language-] {
  display: block;
  overflow-x: auto;
  padding: 0;
  /* color: #abb2bf; */
}

pre code[class*=language-] {
  padding: 12px;
  padding-top: 6px;
}

pre::before {
  content: "";
  display: block;
  background-image: url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI1NCIgaGVpZ2h0PSIxNCIgdmlld0JveD0iMCAwIDU0IDE0Ij4KICA8ZyBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDEgMSkiPgogICAgPGNpcmNsZSBjeD0iNiIgY3k9IjYiIHI9IjYiIGZpbGw9IiNGRjVGNTYiIHN0cm9rZT0iI0UwNDQzRSIgc3Ryb2tlLXdpZHRoPSIuNSIvPgogICAgPGNpcmNsZSBjeD0iMjYiIGN5PSI2IiByPSI2IiBmaWxsPSIjRkZCRDJFIiBzdHJva2U9IiNERUExMjMiIHN0cm9rZS13aWR0aD0iLjUiLz4KICAgIDxjaXJjbGUgY3g9IjQ2IiBjeT0iNiIgcj0iNiIgZmlsbD0iIzI3QzkzRiIgc3Ryb2tlPSIjMUFBQjI5IiBzdHJva2Utd2lkdGg9Ii41Ii8+CiAgPC9nPgo8L3N2Zz4K");
  height: 30px;
  width: 100%;
  margin-bottom: -7px;
  background-size: 40px;
  background-repeat: no-repeat;
  /* border-radius: 5px; */
  /* background-color: #282c34; */
  /* background-position: 10px 10px; */
}

.svg-markmap-box {
  min-height: 20rem;
  width: 100%;
}

.footnotes {
  padding-top: 0.5rem;
  padding-bottom: 0.5rem;
}

/* 布局 end */
/* prism-js 样式 */
/* PrismJS 1.23.0
https://prismjs.com/download.html#themes=prism-okaidia&languages=markup+css+clike+javascript */
/**
 * okaidia theme for JavaScript, CSS and HTML
 * Loosely based on Monokai textmate theme by http://www.monokai.nl/
 * @author ocodia
 */
code[class*=language-],
pre[class*=language-] {
  color: #f8f8f2;
  background: none;
  text-shadow: 0 1px rgba(0, 0, 0, 0.3);
  font-family: '圆体-简', 'Yuanti SC', Consolas, Monaco, "Andale Mono", "Ubuntu Mono", monospace;
  font-size: 1em;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*=language-] {
  padding: 1em;
  margin: 0.5em 0;
  overflow: auto;
  border-radius: 6px;
}

:not(pre) > code[class*=language-],
pre[class*=language-] {
  background: #272822;
}

/* Inline code */
:not(pre) > code[class*=language-] {
  padding: 0.1em;
  border-radius: 0.3em;
  white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
  color: #8292a2;
}

.token.punctuation {
  color: #f8f8f2;
}

.token.namespace {
  opacity: 0.7;
}

.token.property,
.token.tag,
.token.constant,
.token.symbol,
.token.deleted {
  color: #f92672;
}

.token.boolean,
.token.number {
  color: #ae81ff;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
  color: #a6e22e;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string,
.token.variable {
  color: #f8f8f2;
}

.token.atrule,
.token.attr-value,
.token.function,
.token.class-name {
  color: #e6db74;
}

.token.keyword {
  color: #66d9ef;
}

.token.regex,
.token.important {
  color: #fd971f;
}

.token.important,
.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}

.token.entity {
  cursor: help;
}

/* prism-js end */
                /* 覆盖一些全局样式，确保不影响页面其他部分 */
                .markdown-content h1,
                .markdown-content h2,
                .markdown-content h3,
                .markdown-content h4,
                .markdown-content h5,
                .markdown-content h6 {
                    margin-top: 1.5rem;
                    margin-bottom: 1rem;
                }
            </style>
            
            <div class="section-content">
                
                    <div class="markdown-content">
                        <h3>现有问题</h3>

<p>本文旨在解决现代大型语言模型（LLMs）在多个维度上的核心挑战，包括计算效率、推理能力、知识操作、训练稳定性和安全性。具体问题包括：</p>

<ul>
<li><strong>推理与效率的权衡</strong>：传统LLMs将推理过程（如链式思维）置于训练后，未能充分利用预训练数据，且随着模型规模增大，推理的成本和延迟也急剧上升。</li>
<li><strong>参数效率低下</strong>：现有模型在处理复杂任务时，通常依赖增加参数数量，导致资源消耗巨大，限制了在资源受限环境下的部署。</li>
<li><strong>知识操作能力不足</strong>：模型在处理需要多步骤推理、知识组合或图结构遍历的复杂任务（如多跳问答）时，表现不佳且样本效率低下。</li>
<li><strong>自适应计算的局限性</strong>：现有的自适应计算方法（如PonderNet）使用的先验假设（如几何先验）可能限制模型在复杂任务中进行深度计算，导致过早退出。</li>
<li><strong>训练策略与安全性</strong>：如何高效利用多样化数据集进行稳定训练，以及如何确保模型在面对有害或模糊提示时能做出安全、一致的判断，是当前LLM面临的重要挑战。</li>
</ul>

<h3>Hypothesis</h3>

<p>本文的核心假设是，通过引入一种名为<strong>LoopLM</strong>（或<strong>Ouro</strong>模型）的循环架构，可以在预训练阶段内置推理机制，从而在不显著增加参数的情况下，大幅提升模型的性能。具体假设包括：</p>

<ul>
<li><strong>参数效率</strong>：通过递归应用共享权重层，LoopLM能够以更少的参数实现与更大规模标准变换器相匹配甚至超越的性能，实现2-3倍的参数效率提升。</li>
<li><strong>推理与知识操作</strong>：循环的迭代计算结构天然适合多步骤推理和知识操作任务，能够比非循环模型更有效地操控和组合知识，提高在数学、科学推理和多跳问答等任务上的表现。</li>
<li><strong>自适应计算优化</strong>：采用均匀先验和学习的门控机制进行早期退出，可以比传统方法更灵活地根据输入复杂度动态分配计算资源，从而在效率和准确性之间取得更好的平衡。</li>
<li><strong>提升安全性与一致性</strong>：增加递归步骤能够改善模型的“思考”过程，使其在处理有害性判断等安全敏感任务时，决策更准确、一致性更高。</li>
</ul>

<h3>相关研究</h3>

<p>本文的研究建立在多个领域的工作之上，主要包括：</p>

<ul>
<li><strong>循环与递归架构</strong>：循环变换器（Recurrent Transformers）、递归变换器（Recursive Transformers）和Universal Transformer。</li>
<li><strong>自适应计算</strong>：PonderNet等动态停止和自适应计算深度的机制。</li>
<li><strong>推理框架</strong>：链式思维（CoT）、潜在推理框架（Latent Reasoning Frameworks）。</li>
<li><strong>LLM预训练与评估</strong>：模型扩展法则（Scaling Laws）、多样化数据混合策略、以及各类推理基准（如MMLU, GSM8K, BBH）。</li>
<li><strong>知识操作与图算法</strong>：模块化算术（Mano任务）、多跳问答（Multi-hop QA）以及图可达性算法（如Warshall算法）。</li>
</ul>

<h3>解决方案</h3>

<p>本论文提出了一个名为 <strong>Ouro</strong> 的新型循环语言模型（Looped Language Model, <strong>LoopLM</strong>）架构，旨在通过架构创新，解决传统大型语言模型（LLM）在复杂推理任务中计算成本高、依赖显式文本生成（如思维链）的局限性。Ouro的核心思想是在模型内部引入<strong>迭代计算</strong>机制，使其能够在潜在空间中进行多步推理，从而在不显著增加参数量的前提下，大幅提升模型的推理能力、效率和安全性。</p>

<p>以下是该解决方案的详细构成：</p>

<h4><strong>第一部分：核心架构与自适应计算机制</strong></h4>

<p>Ouro模型的设计突破了传统Transformer的堆叠层结构，通过循环应用共享参数的层来实现更深层次的计算。</p>

<p><strong>1. 核心架构：迭代计算（Iterative Computation）</strong>
Ouro并非通过增加模型层数（深度）来提升能力，而是在一个前向传播过程中，通过<strong>递归</strong>地应用一组共享参数的变换器层（循环块）来进行迭代计算。这意味着模型可以根据需要重复“思考”，在每一步迭代中优化其内部表征，从而逐步深化对问题的理解和推理。</p>

<p><strong>2. 关键机制：自适应计算与提前退出（Adaptive Computation &amp; Early Exit）</strong>
为了使计算资源得到最高效的利用，Ouro引入了自适应计算机制，允许模型根据输入任务的复杂性动态调整计算深度（即循环次数）。</p>

<ul>
<li><strong>学习门控与熵正则化</strong>：模型在预训练阶段通过一个<strong>熵正则化</strong>目标来学习一个“退出门”。该门控机制在每个循环步骤后，会预测一个“退出概率”。为了避免模型偏向于浅层计算，训练时采用了<strong>均匀先验</strong>，鼓励模型在不同深度上进行无偏探索。</li>
<li><strong>Q-退出标准</strong>：在推理时，模型会计算累积退出概率。当该累积概率超过一个预设的阈值<code>q</code>时，模型将终止循环并输出结果。</li>
<li><strong>优势</strong>：
<ul>
<li><strong>效率</strong>：简单的输入可以在较少的循环后提前退出，节省计算资源；而复杂的输入则能自然地获得更多的计算步骤。</li>
<li><strong>避免上下文增长</strong>：与思维链（Chain-of-Thought）等需要生成长篇中间文本的推理方法不同，Ouro通过加深内部计算图来扩展推理，避免了因上下文窗口增长带来的内存和计算压力。</li>
</ul></li>
</ul>

<h4><strong>第二部分：多阶段训练策略与稳定性保障</strong></h4>

<p>为了充分发挥Ouro架构的潜力，作者设计了一个包含7.7T tokens的大规模、多阶段训练流程。</p>

<ul>
<li><p><strong>阶段一：预训练（Pre-training）</strong></p>

<ul>
<li>在海量网络数据（如Nemotron-CC）上进行训练，构建模型的基础语言理解能力。此阶段初步探索了8个递归步骤，但为保证稳定性，后续调整为4个。</li>
</ul></li>
<li><p><strong>阶段二：持续训练与退火（CT Anneal）</strong></p>

<ul>
<li>使用更高质量的数据（如MegaMath和OpenCoder）进行持续训练，重点强化模型的数学和代码能力。此阶段采用学习率退火策略，并扩展序列长度至16K。</li>
</ul></li>
<li><p><strong>阶段三：长上下文训练（LongCT）</strong></p>

<ul>
<li>使用专门的长文本数据集（ProLong-64K）训练，将模型的上下文处理能力扩展至64K。</li>
</ul></li>
<li><p><strong>阶段四：中期训练与指令微调（Mid-training &amp; SFT）</strong></p>

<ul>
<li>整合高质量的监督微调（SFT）数据集，包括问答和推理链样本，进一步提升模型的高级推理和对话能力。</li>
</ul></li>
<li><p><strong>训练稳定性调整</strong>：</p>

<ul>
<li>由于循环架构中梯度流动的复杂性，训练过程需要特别关注稳定性。作者通过<strong>减少递归步骤</strong>（从8到4）、<strong>逐步扩大批量大小</strong>（从4M到8M）以及<strong>降低KL散度系数</strong>等方式，确保了训练过程的平稳收敛。</li>
</ul></li>
</ul>

<h4><strong>第三部分：核心优势与能力验证</strong></h4>

<p>通过广泛的实验和分析，Ouro/LoopLM证明了其在多个方面的显著优势。</p>

<p><strong>1. 卓越的参数效率与性能</strong>
Ouro模型（1.4B和2.6B参数）在多个标准基准测试（如MMLU、GSM8K、MATH）中，其性能媲美甚至超越了参数量为其2-3倍的标准Transformer模型（如4B和8B）。这证明了迭代计算是提升模型能力的有效途径，是参数和数据之外的第三个扩展轴。</p>

<p><strong>2. 强大的知识操控能力（Knowledge Manipulation）</strong>
合成任务（如Mano模数算术、多跳问答）的实验表明，Ouro的性能提升并非源于知识容量的增加（其知识存储效率与标准模型相似），而是源于<strong>更优越的知识操作能力</strong>。循环结构使模型能够在参数空间中进行更深入的搜索，有效地组合和应用已存储的知识片段来解决复杂问题。理论分析也证明，LoopLM能以极高的效率解决如图可达性之类的多步推理问题。</p>

<p><strong>3. 提升的安全性、忠实性与一致性</strong>
*   <strong>安全性</strong>：实验表明，随着递归步骤的增加，模型的安全对齐能力显著提升，能够更有效地识别和拒绝有害提示。
*   <strong>忠实性（Faithfulness）</strong>：Ouro的迭代过程产生的是因果一致的推理轨迹。每个中间步骤的计算都直接影响最终输出，这与传统思维链可能产生“事后合理化”的解释不同。这种内在的“提案-验证”机制使得推理过程更加透明和可信。</p>

<h4><strong>第四部分：高效的推理阶段优化</strong></h4>

<p>为了让循环模型在实际部署中更具可行性，论文还探讨了推理阶段的优化策略。</p>

<ul>
<li><strong>KV缓存共享（KV Cache Sharing）</strong>：在自回归生成（解码）阶段，研究发现可以安全地重用最后一步循环的KV缓存，而无需为每个循环步骤都维护一个独立的缓存。这使得Ouro模型的内存占用减少了4倍，与同等参数量的标准模型相当，极大地提升了部署效率。</li>
</ul>

<p>Ouro/LoopLM解决方案通过引入<strong>循环架构</strong>和<strong>自适应计算</strong>，成功地构建了一个在参数和计算效率上远超传统模型的先进语言模型。它不仅通过多阶段训练策略实现了强大的基础能力，更重要的是，其核心的迭代计算机制赋予了模型卓越的<strong>知识操控能力</strong>和<strong>内在的推理忠实性</strong>。通过KV缓存共享等优化，该方案在保持高性能的同时，也兼顾了实际部署的效率需求，为未来语言模型的发展开辟了新的、更高效的路径。</p>

<h3>实验设计</h3>

<p>为了全面验证LoopLM架构的有效性，论文进行了一系列广泛的实验：</p>

<ul>
<li><strong>大规模预训练</strong>：在高达7.7T tokens的数据集上对1.4B和2.6B参数的Ouro模型进行预训练。</li>
<li><strong>基准性能评估</strong>：在多个公开基准上进行评估，包括通用语言理解（MMLU, ARC）、复杂推理（GSM8K, MATH, BBH）和安全性（有害性提示判断）。</li>
<li><strong>受控合成实验</strong>：设计了专门的合成任务来隔离和评估模型的特定能力，如知识操作（Mano模块化算术）、多跳问答和知识图可达性任务。</li>
<li><strong>消融研究</strong>：比较了不同递归深度、不同早期退出策略（静态、门控）、不同先验（均匀 vs. 几何）以及不同KV缓存策略对模型性能的影响。</li>
<li><strong>扩展性分析</strong>：研究了LoopLM的损失曲线，并提出了“步进损失缩放法则”来预测模型在不同规模、数据量和递归深度下的性能。</li>
</ul>

<h3>数据集和代码</h3>

<ul>
<li><strong>代码与模型</strong>：代码、模型和实验结果均在项目页面公开：<strong>http://ouro-llm.github.io</strong></li>
<li><strong>数据集</strong>：预训练使用了包含Web数据、数学、代码和长上下文文档在内的多种高质量公共数据集。评估则使用了多个标准基准（如MMLU, GSM8K）以及为特定实验构建的合成数据集（如Mano任务、多跳QA、Quora问题对）。</li>
</ul>

<h3>实验结果</h3>

<p>实验结果全面支持了本文的核心假设：</p>

<ul>
<li><strong>优越的参数效率</strong>：Ouro模型（1.4B和2.6B）在多个推理基准上的表现与规模为其2-3倍（如4B和8B）的标准变换器模型相当或更优。</li>
<li><strong>强大的推理与知识操作能力</strong>：在多跳问答、模块化算术和图可达性等需要深度推理和知识操作的任务上，LoopLM展现出比标准变换器更高的样本效率和准确性。</li>
<li><strong>自适应计算的有效性</strong>：采用均匀先验和学习门控的早期退出策略，在计算-准确率权衡曲线上优于其他策略。</li>
<li><strong>安全性的提升</strong>：随着递归步骤的增加，模型在有害性判断任务中的准确性和一致性显著提高，不安全响应数量减少。</li>
<li><strong>可预测的扩展性</strong>：实验验证了步进损失缩放法则的有效性，能够较好地预测模型在不同配置下的损失变化。</li>
</ul>

<h3>论文贡献</h3>

<p>本文的主要贡献可以总结为以下几点：</p>

<ol>
<li><strong>提出Ouro/LoopLM架构</strong>：引入了一种新颖的、通过迭代计算提升参数效率和推理能力的语言模型架构，并证明了将其直接整合到预训练中的有效性。</li>
<li><strong>确立迭代计算为新的扩展维度</strong>：通过实证和理论分析，论证了迭代潜在计算是超越传统参数和数据扩展的、提升LLM性能的关键新方向。</li>
<li><strong>提升知识操作与推理能力</strong>：展示了循环架构在复杂推理和知识密集型任务中的显著优势，并为解决此类问题提供了新的思路。</li>
<li><strong>优化自适应计算</strong>：提出了采用均匀先验和学习门控的自适应计算方法，为实现高效动态计算提供了有效策略。</li>
<li><strong>深入分析模型行为</strong>：系统地研究了递归深度对模型性能和安全性的影响，并提出了可预测模型损失的缩放法则，为理解和优化循环模型提供了理论基础。</li>
</ol>

                    </div>
                
            </div>
        </div>
        
        <div class="links">
            <a href="https://arxiv.org/abs/2510.25741" class="btn" target="_blank">📄 查看 arXiv 原文</a>
            <a href="index.html" class="btn btn-secondary">← 返回每日报告</a>
            <a href="../../index.html" class="btn btn-secondary">← 返回汇总页</a>
        </div>
        
        <div class="footer">
            <p>📧 这是由智能论文简报系统自动生成的页面</p>
            <p>生成时间: 2025-11-01 14:16:56</p>
            <p>访问地址: <a href="https://jycarlos1019.pp.ua">https://jycarlos1019.pp.ua</a></p>
        </div>
    </div>
</body>
</html>
