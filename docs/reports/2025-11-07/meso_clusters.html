<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¸»é¢˜èšç±»åˆ†æ - 2025-11-07</title>
    <style>
        body {
            font-family: 'åœ†ä½“-ç®€', 'Yuanti SC', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #e9ecef;
        }
        .header h1 {
            color: #ffa500;
            margin: 0;
            font-size: 28px;
        }
        .nav-links {
            margin-bottom: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            border-radius: 6px;
        }
        .nav-links a {
            color: #007bff;
            text-decoration: none;
            margin-right: 15px;
            font-size: 14px;
        }
        .nav-links a:hover {
            text-decoration: underline;
        }
        .macro-summary-section {
            background-color: #f0f7ff;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #007bff;
            margin-bottom: 30px;
        }
        .macro-summary-section h2 {
            color: #007bff;
            margin-top: 0;
            margin-bottom: 15px;
            font-size: 20px;
        }
        .macro-summary-content {
            color: #333;
            line-height: 1.8;
        }
        .macro-summary-content h3 {
            color: #2c3e50;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        .macro-summary-content ul, .macro-summary-content ol {
            margin: 10px 0;
            padding-left: 25px;
        }
        .macro-summary-content li {
            margin: 8px 0;
        }
        .content-section {
            background-color: #fff9e6;
            padding: 25px;
            border-radius: 8px;
            border-left: 4px solid #ffa500;
        }
        .cluster-item {
            margin: 20px 0;
            padding: 20px;
            background-color: white;
            border-radius: 6px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .cluster-item h3 {
            color: #2c3e50;
            margin-top: 0;
            font-size: 18px;
            border-bottom: 2px solid #ffa500;
            padding-bottom: 10px;
        }
        .cluster-item ul {
            margin: 15px 0;
            padding-left: 20px;
        }
        .cluster-item li {
            margin: 12px 0;
            line-height: 1.6;
        }
        .cluster-item strong {
            color: #2c3e50;
            display: block;
            margin-bottom: 5px;
        }
        .cluster-item .contribution {
            color: #666;
            font-size: 14px;
        }
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e9ecef;
            text-align: center;
            color: #6c757d;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ä¸»é¢˜èšç±»åˆ†æ</h1>
            <div class="date">2025-11-07</div>
        </div>

        <div class="nav-links">
            <a href="index.html">â† è¿”å›æ¯æ—¥ç®€æŠ¥</a>
            <a href="../../index.html">è¿”å›æ±‡æ€»é¡µ</a>
            <a href="../../search.html">ğŸ” æœç´¢å†å²å½’æ¡£</a>
        </div>

        <!-- å®è§‚ç ”ç©¶è¶‹åŠ¿ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ -->
        
        <div class="macro-summary-section">
            <h2>ğŸ“ˆ å®è§‚ç ”ç©¶è¶‹åŠ¿</h2>
            <div class="macro-summary-content">
                <h2>æ ¸å¿ƒç ”ç©¶ä¸»é¢˜</h2>

<ol>
<li>å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä¸å¯¹é½æ­£æˆä¸ºç¡®ä¿æ¨¡å‹è¾“å‡ºç¬¦åˆäººç±»ä»·å€¼è§‚å’ŒæœŸæœ›çš„é‡è¦ç ”ç©¶æ–¹å‘ã€‚</li>
<li>å¼ºåŒ–å­¦ä¹ åœ¨ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­çš„åº”ç”¨ï¼Œæ¨åŠ¨äº†æ¨¡å‹æ€§èƒ½çš„æ˜¾è‘—æå‡ã€‚</li>
<li>è”é‚¦å­¦ä¹ çš„é«˜æ•ˆæ€§ç ”ç©¶æ­£åœ¨è§£å†³æ•°æ®éšç§é—®é¢˜ï¼ŒåŒæ—¶æå‡äº†æ¨¡å‹åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ã€‚</li>
<li>LLMçš„å®‰å…¨æ€§ä¸é²æ£’æ€§ç ”ç©¶èšç„¦äºé˜²æ­¢æ¨¡å‹è¢«æ¶æ„åˆ©ç”¨å’Œæé«˜å…¶åœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚</li>
<li>å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–ä¸è¯„ä¼°æ­£åœ¨æ¨åŠ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸è®¡ç®—æœºè§†è§‰çš„æ·±åº¦èåˆã€‚</li>
</ol>

<h2>æŠ€æœ¯è¶‹åŠ¿</h2>

<ol>
<li>ç ”ç©¶è€…è¶Šæ¥è¶Šå…³æ³¨æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å’Œä¿¡ä»»AIç³»ç»Ÿçš„å†³ç­–è¿‡ç¨‹ã€‚</li>
<li>ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ çš„å…´èµ·ä½¿å¾—AIåœ¨å¤æ‚ç³»ç»Ÿå»ºæ¨¡å’Œä¸ç¡®å®šæ€§é‡åŒ–æ–¹é¢å±•ç°å‡ºæ–°çš„æ½œåŠ›ã€‚</li>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åä½œä¸è§„åˆ’ç ”ç©¶æ­£åœ¨æ¨åŠ¨æ™ºèƒ½ä½“ä¹‹é—´çš„ååŒå·¥ä½œï¼Œæå‡æ•´ä½“ç³»ç»Ÿçš„æ•ˆç‡å’Œæ™ºèƒ½æ°´å¹³ã€‚</li>
</ol>

            </div>
        </div>
        

        <!-- ä¸»é¢˜èšç±»åˆ†æ -->
        <div class="content-section">
            <h2 style="color: #ffa500; margin-top: 0; margin-bottom: 20px;">ğŸ” ä¸»é¢˜èšç±»åˆ†æ</h2>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 1: å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä¸å¯¹é½</h3>
                <ul>
                    
                    <li>
                        <strong>RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ï¼Œä»¥æé«˜é¢†åŸŸç‰¹å®šRAGç³»ç»Ÿçš„å¯¹é½æ€§å’Œå¯é æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Large language models replicate and predict human cooperation across experiments in game theory</strong>
                        <span class="contribution">ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åšå¼ˆè®ºå®éªŒä¸­å¦‚ä½•æ¨¡æ‹Ÿå’Œé¢„æµ‹äººç±»åˆä½œè¡Œä¸ºã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Evaluating LLM-Contaminated Crowdsourcing Data Without Ground Truth</strong>
                        <span class="contribution">æ¢è®¨äº†å¦‚ä½•åœ¨ç¼ºä¹çœŸå®æ ‡ç­¾çš„æƒ…å†µä¸‹è¯„ä¼°è¢«LLMæ±¡æŸ“çš„ä¼—åŒ…æ•°æ®çš„è´¨é‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Pragmatic Reasoning improves LLM Code Generation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å®ç”¨æ¨ç†æ–¹æ³•ï¼Œä»¥æ”¹å–„LLMåœ¨ä»£ç ç”Ÿæˆä¸­çš„è¡¨ç°ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors</strong>
                        <span class="contribution">å¼•å…¥äº†å®‰å…¨å¼•å¯¼æ›¿ä»£æ–¹æ¡ˆï¼Œä»¥å¸®åŠ©LLMè¯„ä¼°è€…è¯†åˆ«å’Œçº æ­£æ¨¡å‹ä¸­çš„å¾®å¦™ä¸è¯šå®è¡Œä¸ºã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Are We Aligned? A Preliminary Investigation of the Alignment of Responsible AI Values between LLMs and Human Judgment</strong>
                        <span class="contribution">åˆæ­¥è°ƒæŸ¥äº†LLMä¸äººç±»åˆ¤æ–­åœ¨è´Ÿè´£ä»»AIä»·å€¼è§‚ä¸Šçš„å¯¹é½ç¨‹åº¦ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises</strong>
                        <span class="contribution">æ¢è®¨äº†åœ¨RAGæ¨¡å‹ä¸­ç”Ÿæˆå’ŒéªŒè¯ç¼ºå¤±å‰æçš„å½’çº³æ¨ç†æ–¹æ³•ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation Benchmarks</strong>
                        <span class="contribution">å¯¹LLMåœ¨ä»£ç ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œæ­ç¤ºäº†å…¶ä»ç„¶å­˜åœ¨çš„æŒ‘æˆ˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Exploring the Feasibility of End-to-End Large Language Model as a Compiler</strong>
                        <span class="contribution">ç ”ç©¶äº†å°†ç«¯åˆ°ç«¯LLMä½œä¸ºç¼–è¯‘å™¨çš„å¯è¡Œæ€§åŠå…¶æ½œåœ¨ä¼˜åŠ¿ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Computational Turing Test Reveals Systematic Differences Between Human and AI Language</strong>
                        <span class="contribution">é€šè¿‡è®¡ç®—å›¾çµæµ‹è¯•æ­ç¤ºäº†äººç±»è¯­è¨€ä¸AIè¯­è¨€ä¹‹é—´çš„ç³»ç»Ÿæ€§å·®å¼‚ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºå…ƒåˆ†æçš„è¯æ®é‡æ–°æ’åºæ–¹æ³•ï¼Œä»¥æé«˜åŸºäºè¯æ®åŒ»å­¦ä¸­çš„RAGæ€§èƒ½ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Probe-Rewrite-Evaluate: A Workflow for Reliable Benchmarks and Quantifying Evaluation Awareness</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°çš„å·¥ä½œæµç¨‹ï¼Œä»¥é‡åŒ–è¯„ä¼°æ„è¯†å¹¶æé«˜LLMåŸºå‡†æµ‹è¯•çš„å¯é æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 2: å¤§è¯­è¨€æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–</h3>
                <ul>
                    
                    <li>
                        <strong>The Peril of Preference: Why GRPO fails on Ordinal Rewards</strong>
                        <span class="contribution">æ¢è®¨äº†GRPOåœ¨ä½¿ç”¨åºæ•°å¥–åŠ±æ—¶çš„å±€é™æ€§ï¼Œå¼ºè°ƒäº†éäºŒå…ƒåé¦ˆå¯¹å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åè®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡æœ€å°åŒ–åæ‚”æ¥æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„å†³ç­–èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§è‡ªæˆ‘æ”¹è¿›çš„æ¡†æ¶ï¼Œè§£å†³äº†å¼ºåŒ–å­¦ä¹ ä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œä¿ƒè¿›äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡è´å¶æ–¯åœ¨çº¿ä»»åŠ¡é€‰æ‹©ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„å¼ºåŒ–å¾®è°ƒè¿‡ç¨‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Rewarding the Journey, Not Just the Destination: A Composite Path and Answer Self-Scoring Reward Mechanism for Test-Time Reinforcement Learning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å¤åˆè·¯å¾„å’Œç­”æ¡ˆè‡ªè¯„åˆ†å¥–åŠ±æœºåˆ¶ï¼Œä»¥è§£å†³å½“å‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•çš„å¯æ‰©å±•æ€§ç“¶é¢ˆã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Reasoning Models Hallucinate More: Factuality-Aware Reinforcement Learning for Large Reasoning Models</strong>
                        <span class="contribution">åˆ†æäº†æ¨ç†æ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒä¸­äº§ç”Ÿå¹»è§‰çš„ç°è±¡ï¼Œå¹¶æå‡ºäº†æé«˜äº‹å®å‡†ç¡®æ€§çš„ç­–ç•¥ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Training Large Language Models To Reason In Parallel With Global Forking Tokens</strong>
                        <span class="contribution">æ¢è®¨äº†ä½¿ç”¨å…¨å±€åˆ†å‰ä»¤ç‰Œè®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ä»¥å®ç°å¹¶è¡Œæ¨ç†çš„æœ‰æ•ˆæ€§ï¼Œå¼ºè°ƒäº†å¤šæ ·æ€§å’Œå‡†ç¡®æ€§çš„å¹³è¡¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>How do Transformers Learn Implicit Reasoning?</strong>
                        <span class="contribution">ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹å¦‚ä½•åœ¨ä¸æ˜¾å¼è¡¨è¾¾ä¸­é—´æ­¥éª¤çš„æƒ…å†µä¸‹è¿›è¡Œéšå¼å¤šè·³æ¨ç†çš„æœºåˆ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented Generation Strategies for Bangla Biomedical Question Answering</strong>
                        <span class="contribution">ä»‹ç»äº†BanglaMedQAå’ŒBanglaMMedBenchï¼Œè¯„ä¼°äº†é’ˆå¯¹å­ŸåŠ æ‹‰è¯­ç”Ÿç‰©åŒ»å­¦é—®ç­”çš„æ£€ç´¢å¢å¼ºç”Ÿæˆç­–ç•¥ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>SSPO: Subsentence-level Policy Optimization</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å­å¥çº§ç­–ç•¥ä¼˜åŒ–æ–¹æ³•ï¼Œæ”¹è¿›äº†å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè§£å†³äº†ç°æœ‰RLVRç®—æ³•çš„ä¸è¶³ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models</strong>
                        <span class="contribution">å±•ç¤ºäº†æ‰¹é‡æç¤ºåœ¨å¤šæ­¥éª¤æ¨ç†ä¸­å¦‚ä½•é€šè¿‡æ­£åˆ™åŒ–æ¨¡å‹è¡Œä¸ºæ¥æŠ‘åˆ¶è¿‡åº¦æ€è€ƒçš„ç°è±¡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>RPRO: Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning</strong>
                        <span class="contribution">æå‡ºäº†æ’ååå¥½å¼ºåŒ–ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥æå‡åŒ»å­¦é—®ç­”å’Œè¯Šæ–­æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 3: é«˜æ•ˆçš„è”é‚¦å­¦ä¹ ä¸æ¨¡å‹ä¼˜åŒ–</h3>
                <ul>
                    
                    <li>
                        <strong>Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§éå‡¸çš„OTAå¼‚æ„è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œå¼ºè°ƒäº†åå·®-æ–¹å·®æƒè¡¡çš„é‡è¦æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§è”åˆæ¨¡å‹å‰ªæå’Œèµ„æºåˆ†é…çš„æ–¹æ³•ï¼Œä»¥æé«˜æ—¶é—´è§¦å‘çš„è”é‚¦å­¦ä¹ çš„é€šä¿¡æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åœ¨è®¾å¤‡ä¸Šè¿›è¡Œè”é‚¦é—å¿˜çš„æœºåˆ¶ï¼Œå…è®¸å‚ä¸è€…æœ‰æ•ˆåœ°åˆ é™¤å…¶è¿‡å»çš„è´¡çŒ®ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Revisiting Federated Fine-Tuning: A Single Communication Round is Enough for Foundation Models</strong>
                        <span class="contribution">è¯æ˜äº†åœ¨è”é‚¦ç¯å¢ƒä¸­å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œå¾®è°ƒåªéœ€ä¸€æ¬¡é€šä¿¡è½®æ¬¡å³å¯å®Œæˆã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Federated Stochastic Minimax Optimization under Heavy-Tailed Noises</strong>
                        <span class="contribution">ç ”ç©¶äº†åœ¨é‡å°¾å™ªå£°ä¸‹çš„éå‡¸éšæœºæå°æå¤§ä¼˜åŒ–é—®é¢˜ï¼Œæä¾›äº†æ›´ç°å®çš„ä¼˜åŒ–å‡è®¾ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning</strong>
                        <span class="contribution">æ¢è®¨äº†é€šè¿‡ç”ŸæˆæŒç»­å­¦ä¹ æ–¹æ³•æ„å»ºå¼€æ”¾ä¸”å¯æ‰©å±•çš„äººç±»ç§»åŠ¨åŸºç¡€æ¨¡å‹çš„å¯èƒ½æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Enhancing Efficiency in Multidevice Federated Learning through Data Selection</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ•°æ®é€‰æ‹©ç­–ç•¥ï¼Œä»¥æé«˜å¤šè®¾å¤‡è”é‚¦å­¦ä¹ çš„æ•ˆç‡ï¼Œè€ƒè™‘äº†è®¾å¤‡çš„è®¡ç®—å’Œé€šä¿¡é™åˆ¶ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 4: LLMçš„å®‰å…¨æ€§ä¸é²æ£’æ€§ç ”ç©¶</h3>
                <ul>
                    
                    <li>
                        <strong>AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€ä¸”æ¨¡å—åŒ–çš„å·¥å…·ç®±ï¼Œä»¥ä¿ƒè¿›LLMå®‰å…¨æ€§å’Œé²æ£’æ€§ç ”ç©¶çš„å¯é‡å¤æ€§å’Œå¯æ¯”æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§é«˜æ•ˆçš„é»‘ç®±æ–¹æ³•ï¼Œç”Ÿæˆå¯¹æŠ—åç¼€ä»¥çªç ´LLMçš„å®‰å…¨é˜²æŠ¤ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Robustness in Large Language Models: A Survey of Mitigation Strategies and Evaluation Metrics</strong>
                        <span class="contribution">æä¾›äº†ä¸€é¡¹å…³äºLLMé²æ£’æ€§æŒ‘æˆ˜çš„å…¨é¢è°ƒæŸ¥ï¼Œæ¶µç›–ç¼“è§£ç­–ç•¥å’Œè¯„ä¼°æŒ‡æ ‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Transferable & Stealthy Ensemble Attacks: A Black-Box Jailbreaking Framework for Large Language Models</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ–°é¢–çš„é»‘ç®±ç›‘ç‹±ç ´è§£æ¡†æ¶ï¼Œç»“åˆå¤šç§æ”»å‡»ç­–ç•¥ä»¥å®ç°é«˜æ•ˆçš„æ”»å‡»ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Control Barrier Function for Aligning Large Language Models</strong>
                        <span class="contribution">å¼•å…¥äº†ä¸€ç§åŸºäºæ§åˆ¶å±éšœå‡½æ•°çš„æ¡†æ¶ï¼Œä»¥ç¡®ä¿LLMç”Ÿæˆç”¨æˆ·æœŸæœ›çš„æ–‡æœ¬ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity</strong>
                        <span class="contribution">æ­ç¤ºäº†ç°æœ‰çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•åœ¨å¤„ç†æ¨¡ç³Šæ€§æ—¶çš„ä¸è¶³ï¼Œå¼ºè°ƒäº†çœŸå®è¯­è¨€çš„å¤æ‚æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>VERA: Variational Inference Framework for Jailbreaking Large Language Models</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§å˜åˆ†æ¨æ–­æ¡†æ¶ï¼Œç”¨äºåœ¨é»‘ç®±ç¯å¢ƒä¸­è¯†åˆ«LLMçš„è„†å¼±æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 5: å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–ä¸è¯„ä¼°</h3>
                <ul>
                    
                    <li>
                        <strong>Test-Time Warmup for Multimodal Large Language Models</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æµ‹è¯•æ—¶é¢„çƒ­çš„æ–¹æ³•ï¼Œä»¥æé«˜å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬ä¸å›¾åƒäº¤äº’ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>TowerVision: Understanding and Improving Multilinguality in Vision-Language Models</strong>
                        <span class="contribution">é€šè¿‡ç»¼åˆå®è¯ç ”ç©¶ï¼Œåˆ†æäº†å¤šè¯­è¨€è®¾è®¡é€‰æ‹©å¯¹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§çš„å½±å“ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Direct Semantic Communication Between Large Language Models via Vector Translation</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§é€šè¿‡å‘é‡ç¿»è¯‘å®ç°å¤§è¯­è¨€æ¨¡å‹ä¹‹é—´ç›´æ¥è¯­ä¹‰é€šä¿¡çš„æ–¹æ³•ï¼Œä»¥æé«˜ä¿¡æ¯ä¼ é€’æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Flashlight: PyTorch Compiler Extensions to Accelerate Attention Variants</strong>
                        <span class="contribution">å¼€å‘äº†Flashlightï¼Œä¸€ä¸ªPyTorchç¼–è¯‘å™¨æ‰©å±•ï¼Œä»¥åŠ é€Ÿå¤šç§æ³¨æ„åŠ›å˜ä½“çš„è®¡ç®—æ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm</strong>
                        <span class="contribution">æ¢è®¨äº†è§†é¢‘ç”Ÿæˆä½œä¸ºä¸€ç§æ–°å…´çš„å¤šæ¨¡æ€æ¨ç†èŒƒå¼ï¼Œå…‹æœäº†æ–‡æœ¬å’Œå›¾åƒæ¨ç†çš„å›ºæœ‰é™åˆ¶ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai</strong>
                        <span class="contribution">æ¨å‡ºäº†ThaiOCRBenchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè¯„ä¼°æ³°è¯­è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬ä¸°å¯Œè§†è§‰ç†è§£ä»»åŠ¡ä¸­çš„åŸºå‡†ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 6: æ·±åº¦å­¦ä¹ ä¼˜åŒ–ä¸ç½‘ç»œè®¾è®¡</h3>
                <ul>
                    
                    <li>
                        <strong>Residual Kolmogorov-Arnold Network for Enhanced Deep Learning</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§æ®‹å·®Kolmogorov-Arnoldç½‘ç»œï¼Œä»¥æå‡æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä¼˜åŒ–èƒ½åŠ›å’Œè®­ç»ƒæ•ˆç‡ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Deep Edge Filter: Return of the Human-Crafted Layer in Deep Learning</strong>
                        <span class="contribution">å¼•å…¥æ·±è¾¹ç¼˜æ»¤æ³¢å™¨ï¼Œé€šè¿‡é«˜é€šæ»¤æ³¢å¢å¼ºæ·±åº¦ç¥ç»ç½‘ç»œç‰¹å¾ä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks</strong>
                        <span class="contribution">æå‡ºæ­£äº¤æ›´æ–°æ–¹æ³•ï¼Œæ”¹è¿›æ®‹å·®è¿æ¥ä»¥å®ç°æ›´ç¨³å®šå’Œé«˜æ•ˆçš„æ·±åº¦ç½‘ç»œè®­ç»ƒã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers</strong>
                        <span class="contribution">æ¢è®¨äº†æ•°æ®å˜åŒ–ä¸‹æ·±åº¦é›†æˆå›¾åƒåˆ†ç±»å™¨çš„çº¿æ€§æ¨¡å¼è¿é€šæ€§ï¼Œæ­ç¤ºäº†è®­ç»ƒç¨³å®šæ€§å’Œå±€éƒ¨æœ€ä¼˜çš„ç‰¹æ€§ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>SySMOL: Co-designing Algorithms and Hardware for Neural Networks with Heterogeneous Precisions</strong>
                        <span class="contribution">æå‡ºSONIQæ¡†æ¶ï¼Œé€šè¿‡æ··åˆç²¾åº¦è®­ç»ƒä¼˜åŒ–ç®—æ³•ä¸ç¡¬ä»¶çš„ååŒè®¾è®¡ï¼Œä»¥å®ç°è¶…ä½ç²¾åº¦æ¨ç†ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 7: ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ ä¸ä¸ç¡®å®šæ€§é‡åŒ–</h3>
                <ul>
                    
                    <li>
                        <strong>Accelerating scientific discovery with the common task framework</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ä¸ªé€šç”¨ä»»åŠ¡æ¡†æ¶ï¼Œä»¥åŠ é€Ÿç§‘å­¦å‘ç°å¹¶è¯„ä¼°å¤šæ ·åŒ–çš„ç§‘å­¦æ¨¡å‹ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Physics-Informed Neural Networks and Neural Operators for Parametric PDEs: A Human-AI Collaborative Analysis</strong>
                        <span class="contribution">ä»‹ç»äº†ä¸€ç§äººæœºåä½œçš„æ–¹æ³•ï¼Œé€šè¿‡ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œå’Œç¥ç»ç®—å­é«˜æ•ˆæ¢ç´¢å‚æ•°åŒ–åå¾®åˆ†æ–¹ç¨‹çš„è§£ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in Scientific AI</strong>
                        <span class="contribution">æ¢è®¨äº†ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ åœ¨é€†é—®é¢˜ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œæ­ç¤ºäº†ç§‘å­¦AIä¸­çš„æ½œåœ¨é£é™©ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åå¤„ç†çš„æ¨¡å‹æ— å…³çš„ä¸ç¡®å®šæ€§é‡åŒ–æ¡†æ¶ï¼Œä»¥å¢å¼ºç®€åŒ–æ¨¡å‹åœ¨äº‘å¾®ç‰©ç†ä¸­çš„åº”ç”¨ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Universal Fourier Neural Operators for periodic homogenization problems in linear elasticity</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§é€šç”¨çš„å‚…é‡Œå¶ç¥ç»ç®—å­ï¼Œä»¥è§£å†³çº¿æ€§å¼¹æ€§ä¸­çš„å‘¨æœŸå‡åŒ€åŒ–é—®é¢˜ï¼Œæå‡äº†è®¡ç®—æ•ˆç‡å’Œé€‚ç”¨æ€§ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 8: å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—ä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜</h3>
                <ul>
                    
                    <li>
                        <strong>Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications</strong>
                        <span class="contribution">æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦é¢†åŸŸçš„è®°å¿†ç°è±¡åŠå…¶å½±å“ï¼Œå¼ºè°ƒäº†è®°å¿†çš„æ™®éæ€§å’Œç‰¹å¾ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation</strong>
                        <span class="contribution">æå‡ºäº†RxSafeBenchæ¡†æ¶ï¼Œä»¥è¯†åˆ«å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨¡æ‹Ÿå’¨è¯¢ä¸­çš„è¯ç‰©å®‰å…¨é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŸºäºTransformerçš„æ¨¡å‹ï¼Œæ—¨åœ¨å¤„ç†å¼‚æ„ç”µå­å¥åº·è®°å½•æ•°æ®ä¸­çš„ä¸´åºŠé£é™©åˆ†ç±»æŒ‘æˆ˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Will Large Language Models Transform Clinical Prediction?</strong>
                        <span class="contribution">è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ”¹å–„ä¸´åºŠé¢„æµ‹æ¨¡å‹ä¸­çš„æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†çºµå‘ç”µå­å¥åº·è®°å½•æ–¹é¢çš„èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 9: å¤šæ™ºèƒ½ä½“åä½œä¸è§„åˆ’</h3>
                <ul>
                    
                    <li>
                        <strong>DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§åŠ¨æ€æ¨ç†ä¸å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç¬¦å·ä¸–ç•Œæ¨¡å‹å¢å¼ºå¤šæ™ºèƒ½ä½“çš„åä½œèƒ½åŠ›ï¼Œè§£å†³äº†éƒ¨åˆ†ä¿¡æ¯å’Œæœ‰é™é€šä¿¡ä¸‹çš„è”åˆå†³ç­–é—®é¢˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Shared Spatial Memory Through Predictive Coding</strong>
                        <span class="contribution">å¼•å…¥äº†ä¸€ç§å¤šæ™ºèƒ½ä½“é¢„æµ‹ç¼–ç æ¡†æ¶ï¼Œå°†åè°ƒé—®é¢˜å»ºæ¨¡ä¸ºæœ€å°åŒ–é‡å»ºè¯¯å·®ï¼Œä»è€Œæœ‰æ•ˆè§£å†³äº†ç©ºé—´è®°å¿†å…±äº«ä¸­çš„ä¸€è‡´æ€§æŒ‘æˆ˜ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜æ— äººæœºç¾¤åœ¨å¤æ‚ç¯å¢ƒä¸‹è¿›è¡Œç¾éš¾æœç´¢ä¸æ•‘æ´ä»»åŠ¡çš„åä½œå’Œè®¤çŸ¥èƒ½åŠ›ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
            <div class="cluster-item">
                <h3>ä¸»é¢˜ 10: å¯è§£é‡Šæ€§ä¸å› æœæ¨æ–­</h3>
                <ul>
                    
                    <li>
                        <strong>Addressing divergent representations from causal interventions on neural networks</strong>
                        <span class="contribution">æ¢è®¨äº†å› æœå¹²é¢„å¯¹ç¥ç»ç½‘ç»œè¡¨ç¤ºçš„å½±å“ï¼Œå¹¶åˆ†æäº†è¿™äº›å¹²é¢„æ˜¯å¦å¯¼è‡´åˆ†å¸ƒå¤–çš„è¡¨ç¤ºã€‚</span>
                    </li>
                    
                    <li>
                        <strong>Explanations Go Linear: Interpretable and Individual Latent Encoding for Post-hoc Explainability</strong>
                        <span class="contribution">æå‡ºäº†ä¸€ç§çº¿æ€§åŒ–çš„åç½®å¯è§£é‡Šæ€§æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜é»‘ç®±æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼ŒåŒæ—¶é™ä½è®¡ç®—å¤æ‚åº¦ã€‚</span>
                    </li>
                    
                    <li>
                        <strong>T-FIX: Text-Based Explanations with Features Interpretable to eXperts</strong>
                        <span class="contribution">å¼€å‘äº†ä¸€ç§é’ˆå¯¹é¢†åŸŸä¸“å®¶çš„æ–‡æœ¬åŸºç¡€è§£é‡Šæ–¹æ³•ï¼Œæ»¡è¶³äº†åœ¨çŸ¥è¯†å¯†é›†å‹ç¯å¢ƒä¸­å¯¹å¯è§£é‡Šæ€§çš„éœ€æ±‚ã€‚</span>
                    </li>
                    
                </ul>
            </div>
            
        </div>

        <div class="footer">
            <p>ç”Ÿæˆæ—¶é—´: 2025-11-07 19:47:25</p>
            <p>æ•°æ®æ¥æº: arXiv AI è®ºæ–‡æ¨èç³»ç»Ÿ</p>
        </div>
    </div>
</body>
</html>
